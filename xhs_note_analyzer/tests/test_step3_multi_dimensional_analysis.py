#!/usr/bin/env python
"""
æµ‹è¯•è„šæœ¬ - Step3: å¤šç»´åº¦å†…å®¹åˆ†æ
é€‰æ‹©3ä¸ªnoteè¿›è¡Œåˆ†æä»¥æé«˜æµ‹è¯•æ•ˆç‡
"""

import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from xhs_note_analyzer.crews.content_analyzer_crew import create_content_analyzer
from xhs_note_analyzer.main import NoteContentData, NoteData

# é…ç½®æµ‹è¯•æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test_step3_multi_dimensional_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_step2_results(step2_output_dir: str = "tests/output/step2") -> List[NoteContentData]:
    """ä»Step2çš„ç»“æœä¸­åŠ è½½ç¬”è®°å†…å®¹æ•°æ®"""
    try:
        # å°è¯•ä»step2_content_results.jsonåŠ è½½
        result_file = Path(step2_output_dir) / "step2_content_results.json"
        if result_file.exists():
            with open(result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if "detailed_notes" in data:
                    detailed_notes = []
                    for note_data in data["detailed_notes"]:
                        # é‡å»ºNoteContentDataå¯¹è±¡
                        basic_info = NoteData(**note_data["basic_info"])
                        note = NoteContentData(
                            note_id=note_data["note_id"],
                            title=note_data["title"],
                            basic_info=basic_info,
                            content=note_data["content"],
                            images=note_data.get("images", []),
                            video_url=note_data.get("video_url", ""),
                            author_info=note_data.get("author_info", {}),
                            tags=note_data.get("tags", []),
                            create_time=note_data.get("create_time", "")
                        )
                        detailed_notes.append(note)
                    return detailed_notes
        
        logger.warning("æœªæ‰¾åˆ°Step2çš„ç»“æœæ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        return create_mock_detailed_notes()
        
    except Exception as e:
        logger.error(f"åŠ è½½Step2ç»“æœå¤±è´¥: {e}")
        return create_mock_detailed_notes()

def create_mock_detailed_notes() -> List[NoteContentData]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„è¯¦ç»†ç¬”è®°æ•°æ®ç”¨äºæµ‹è¯•"""
    mock_notes = []
    
    # ç¬”è®°1ï¼šæ±‚èŒæ”»ç•¥
    basic_info_1 = NoteData(
        note_id="676a4d0a000000001f00c58a",
        note_title="å›½ä¼æ±‚èŒæ”»ç•¥åˆ†äº«",
        note_url="https://www.xiaohongshu.com/explore/676a4d0a000000001f00c58a",
        impression=50000, click=8000, like=1200, collect=800, comment=150, engage=2150
    )
    
    note_1 = NoteContentData(
        note_id="676a4d0a000000001f00c58a",
        title="å›½ä¼æ±‚èŒæ”»ç•¥åˆ†äº«",
        basic_info=basic_info_1,
        content="""ğŸ”¥å›½ä¼æ±‚èŒå…¨æ”»ç•¥ï½œä»0åˆ°offerçš„å®Œæ•´è·¯å¾„

ğŸ“Œç—›ç‚¹åˆ†æï¼š
å¾ˆå¤šå°ä¼™ä¼´è§‰å¾—å›½ä¼é—¨æ§›é«˜ã€ç«äº‰æ¿€çƒˆï¼Œä¸çŸ¥é“ä»ä½•å…¥æ‰‹

âœ¨æ ¸å¿ƒç­–ç•¥ï¼š
1ï¸âƒ£ç®€å†åŒ…è£…ï¼šçªå‡ºç¨³å®šæ€§å’Œå›¢é˜Ÿåˆä½œèƒ½åŠ›
2ï¸âƒ£ç¬”è¯•å‡†å¤‡ï¼šè¡Œæµ‹+ä¸“ä¸šçŸ¥è¯†åŒç®¡é½ä¸‹  
3ï¸âƒ£é¢è¯•æŠ€å·§ï¼šå±•ç°ä»·å€¼è§‚åŒ¹é…åº¦
4ï¸âƒ£å†…æ¨æ¸ é“ï¼šå­¦ä¼šåˆ©ç”¨æ ¡å‹èµ„æº

ğŸ’¡å®ç”¨tipsï¼š
â€¢ å…³æ³¨å¤®ä¼å®˜ç½‘æ‹›è˜ä¿¡æ¯
â€¢ å‡†å¤‡æ ‡å‡†åŒ–ç®€å†æ¨¡æ¿
â€¢ æ¨¡æ‹Ÿé¢è¯•ç»ƒä¹ è¡¨è¾¾èƒ½åŠ›

æƒ³äº†è§£æ›´å¤šæ±‚èŒå¹²è´§ï¼Œå…³æ³¨æˆ‘ï¼æ¯å¤©åˆ†äº«èŒåœºæˆé•¿ç§˜ç±ï½""",
        images=[
            "https://example.com/career-guide-1.jpg",
            "https://example.com/career-tips-2.jpg", 
            "https://example.com/interview-skills-3.jpg"
        ],
        author_info={
            "name": "èŒåœºå¯¼å¸ˆå°ç‹",
            "followers": 15000,
            "user_id": "career_mentor_wang"
        },
        tags=["å›½ä¼æ±‚èŒ", "é¢è¯•æŠ€å·§", "èŒåœºæ”»ç•¥", "æ±‚èŒæŒ‡å¯¼", "ç®€å†ä¼˜åŒ–"],
        create_time="2024-01-15 14:30:00"
    )
    mock_notes.append(note_1)
    
    # ç¬”è®°2ï¼šé¢è¯•æŠ€å·§
    basic_info_2 = NoteData(
        note_id="676a4d0a000000001f00c58b",
        note_title="å¤®ä¼é¢è¯•æŠ€å·§å¤§å…¨",
        note_url="https://www.xiaohongshu.com/explore/676a4d0a000000001f00c58b",
        impression=30000, click=5000, like=800, collect=500, comment=100, engage=1400
    )
    
    note_2 = NoteContentData(
        note_id="676a4d0a000000001f00c58b",
        title="å¤®ä¼é¢è¯•æŠ€å·§å¤§å…¨",
        basic_info=basic_info_2,
        content="""å¤®ä¼é¢è¯•é€šå…³ç§˜ç±ï½œè®©é¢è¯•å®˜çœ¼å‰ä¸€äº®çš„æŠ€å·§

ğŸ¯é¢è¯•ç—›ç‚¹ï¼š
â€¢ ç´§å¼ åˆ°è¯´ä¸å‡ºè¯
â€¢ ä¸çŸ¥é“å¦‚ä½•å±•ç¤ºè‡ªå·±
â€¢ æ‹…å¿ƒå›ç­”ä¸å¤Ÿä¸“ä¸š

ğŸ’ªè§£å†³æ–¹æ¡ˆï¼š
ã€è‡ªæˆ‘ä»‹ç»ç¯‡ã€‘
30ç§’é»„é‡‘æ³•åˆ™ï¼šåŸºæœ¬ä¿¡æ¯+æ ¸å¿ƒä¼˜åŠ¿+åŒ¹é…åº¦

ã€ä¸“ä¸šé—®é¢˜ç¯‡ã€‘
STARæ³•åˆ™ï¼šæƒ…å¢ƒ+ä»»åŠ¡+è¡ŒåŠ¨+ç»“æœ

ã€å‹åŠ›é¢è¯•ç¯‡ã€‘
ä¿æŒå†·é™ï¼Œé€æ­¥åˆ†æé—®é¢˜

ğŸ”¥å®æˆ˜æ¼”ç»ƒï¼š
é—®ï¼šä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸ï¼Ÿ
ç­”ï¼šè´µå…¬å¸çš„ä¼ä¸šæ–‡åŒ–ä¸æˆ‘çš„ä»·å€¼è§‚é«˜åº¦åŒ¹é…ï¼Œæˆ‘å¸Œæœ›åœ¨è¿™é‡Œ...

è®°ä½ï¼šé¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œå±•ç°çœŸå®çš„è‡ªå·±ï¼""",
        images=[
            "https://example.com/interview-tips-1.jpg",
            "https://example.com/star-method-2.jpg"
        ],
        author_info={
            "name": "HRå°æ",
            "followers": 8000,
            "user_id": "hr_expert_li"
        },
        tags=["å¤®ä¼é¢è¯•", "é¢è¯•å‡†å¤‡", "STARæ³•åˆ™", "è‡ªæˆ‘ä»‹ç»", "èŒåœºæŠ€èƒ½"],
        create_time="2024-01-20 16:45:00"
    )
    mock_notes.append(note_2)
    
    # ç¬”è®°3ï¼šç®€å†æ¨¡æ¿
    basic_info_3 = NoteData(
        note_id="676a4d0a000000001f00c58c",
        note_title="æ±‚èŒç®€å†æ¨¡æ¿åˆ†äº«",
        note_url="https://www.xiaohongshu.com/explore/676a4d0a000000001f00c58c",
        impression=40000, click=6500, like=1000, collect=600, comment=120, engage=1720
    )
    
    note_3 = NoteContentData(
        note_id="676a4d0a000000001f00c58c",
        title="æ±‚èŒç®€å†æ¨¡æ¿åˆ†äº«",
        basic_info=basic_info_3,
        content="""ğŸ“„è¶…å®ç”¨ç®€å†æ¨¡æ¿å…è´¹é€ï½œHRæœ€çˆ±çš„ç®€å†é•¿è¿™æ ·

âš¡å¸¸è§ç®€å†é—®é¢˜ï¼š
âŒå†…å®¹å†—é•¿ï¼Œé‡ç‚¹ä¸çªå‡º
âŒæ ¼å¼æ··ä¹±ï¼Œç¼ºä¹é€»è¾‘
âŒåƒç¯‡ä¸€å¾‹ï¼Œæ²¡æœ‰äº®ç‚¹

âœ…ä¼˜åŒ–åçš„ç®€å†æ¨¡æ¿ï¼š
ã€åŸºæœ¬ä¿¡æ¯åŒºã€‘
å§“åã€è”ç³»æ–¹å¼ã€æ±‚èŒæ„å‘

ã€æ•™è‚²èƒŒæ™¯ã€‘
å­¦å†+GPA+æ ¸å¿ƒè¯¾ç¨‹+è·å¥–æƒ…å†µ

ã€é¡¹ç›®ç»å†ã€‘ 
é¡¹ç›®åç§°+è§’è‰²+æˆæœ+æŠ€èƒ½

ã€å®ä¹ ç»å†ã€‘
å…¬å¸+å²—ä½+ä¸šç»©+æ”¶è·

ğŸ“‹æ¨¡æ¿ç‰¹è‰²ï¼š
ğŸ¨ç®€çº¦å¤§æ°”çš„è®¾è®¡é£æ ¼
ğŸ“Šæ¸…æ™°çš„ä¿¡æ¯å±‚çº§ç»“æ„
â­çªå‡ºä¸ªäººæ ¸å¿ƒç«äº‰åŠ›

ğŸ’¬è¯„è®ºåŒºå›å¤"ç®€å†"å³å¯è·å–æ¨¡æ¿
ä¸€èµ·åŠ©åŠ›æ±‚èŒæˆåŠŸï¼""",
        images=[
            "https://example.com/resume-template-1.jpg",
            "https://example.com/resume-example-2.jpg",
            "https://example.com/resume-tips-3.jpg"
        ],
        author_info={
            "name": "æ±‚èŒåŠ©æ‰‹",
            "followers": 12000,
            "user_id": "job_helper"
        },
        tags=["ç®€å†æ¨¡æ¿", "ç®€å†åˆ¶ä½œ", "æ±‚èŒå‡†å¤‡", "èŒåœºå·¥å…·", "å…è´¹èµ„æº"],
        create_time="2024-01-18 10:15:00"
    )
    mock_notes.append(note_3)
    
    return mock_notes

def test_content_analyzer_creation():
    """æµ‹è¯•å†…å®¹åˆ†æå™¨åˆ›å»º"""
    print("ğŸ”§ æµ‹è¯•å†…å®¹åˆ†æå™¨åˆ›å»º...")
    
    try:
        analyzer = create_content_analyzer()
        print("âœ… ContentAnalyzerCrew åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥LLMé…ç½®
        if hasattr(analyzer, 'llm'):
            print(f"âœ… LLMé…ç½®æ­£å¸¸: {analyzer.llm.model_name}")
        else:
            print("âš ï¸ æ— æ³•æ£€æŸ¥LLMé…ç½®")
            
        return True, analyzer
        
    except Exception as e:
        logger.error(f"ContentAnalyzeråˆ›å»ºå¤±è´¥: {e}")
        print(f"âŒ åˆ›å»ºå¤±è´¥: {e}")
        return False, None

async def test_single_note_analysis(analyzer, note_data: NoteContentData):
    """æµ‹è¯•å•ä¸ªç¬”è®°åˆ†æ"""
    print(f"\nğŸ” æµ‹è¯•å•ä¸ªç¬”è®°åˆ†æ: {note_data.title}")
    
    try:
        # æ‰§è¡Œåˆ†æ
        analysis_result = analyzer.analyze_single_note(note_data)
        
        print("âœ… å•ç¬”è®°åˆ†æå®Œæˆ")
        print(f"  ç»¼åˆè¯„åˆ†: {analysis_result.overall_score:.1f}/100")
        print(f"  å¯å¤åˆ¶æ€§: {analysis_result.replicability_score:.1f}/100")
        print(f"  æˆåŠŸè¦ç´ : {len(analysis_result.success_factors)} ä¸ª")
        
        # æ˜¾ç¤ºå„ç»´åº¦åˆ†æç»“æœ
        print("  ğŸ“ å†…å®¹ç»“æ„åˆ†æ:")
        sa = analysis_result.structure_analysis
        if sa.title_pattern:
            print(f"    æ ‡é¢˜æ¨¡å¼: {sa.title_pattern}")
        if sa.opening_strategy:
            print(f"    å¼€å¤´ç­–ç•¥: {sa.opening_strategy}")
        
        print("  ğŸ’ æƒ…æ„Ÿä»·å€¼åˆ†æ:")
        ea = analysis_result.emotional_analysis
        if ea.pain_points:
            print(f"    ç—›ç‚¹æŒ–æ˜: {', '.join(ea.pain_points[:2])}...")
        if ea.value_propositions:
            print(f"    ä»·å€¼ä¸»å¼ : {', '.join(ea.value_propositions[:2])}...")
        
        print("  ğŸ¨ è§†è§‰å…ƒç´ åˆ†æ:")
        va = analysis_result.visual_analysis
        if va.image_style:
            print(f"    å›¾ç‰‡é£æ ¼: {va.image_style}")
        if va.color_scheme:
            print(f"    è‰²å½©æ–¹æ¡ˆ: {va.color_scheme}")
        
        return True, analysis_result
        
    except Exception as e:
        logger.warning(f"å•ç¬”è®°åˆ†æå¤±è´¥: {e}")
        print(f"  âŒ åˆ†æå¤±è´¥: {e}")
        return False, None

async def test_step3_multi_dimensional_analysis():
    """æµ‹è¯•Step3ï¼šå¤šç»´åº¦å†…å®¹åˆ†æ"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯• Step3: å¤šç»´åº¦å†…å®¹åˆ†æ")
    print("=" * 60)
    
    try:
        # åŠ è½½Step2çš„ç»“æœï¼Œé™åˆ¶ä¸º3ä¸ªç¬”è®°
        print("ğŸ“¥ åŠ è½½ Step2 ç»“æœæ•°æ®...")
        detailed_notes = load_step2_results()
        
        # é™åˆ¶åªåˆ†æå‰3ä¸ªç¬”è®°
        if len(detailed_notes) > 3:
            detailed_notes = detailed_notes[:3]
            print(f"âœ‚ï¸ é™åˆ¶åˆ†ææ•°é‡ä¸º3ä¸ªç¬”è®°")
        
        print(f"åŠ è½½åˆ° {len(detailed_notes)} æ¡è¯¦ç»†ç¬”è®°æ•°æ®")
        
        if not detailed_notes:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„è¯¦ç»†ç¬”è®°æ•°æ®")
            return False
        
        # æ˜¾ç¤ºå°†è¦åˆ†æçš„ç¬”è®°
        print("\nğŸ“‹ å¾…åˆ†æçš„ç¬”è®°:")
        for i, note in enumerate(detailed_notes, 1):
            print(f"  {i}. {note.title}")
            print(f"     å†…å®¹é•¿åº¦: {len(note.content)} å­—ç¬¦")
            print(f"     å›¾ç‰‡æ•°é‡: {len(note.images)} å¼ ")
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer_ok, analyzer = test_content_analyzer_creation()
        if not analyzer_ok:
            print("âŒ åˆ†æå™¨åˆ›å»ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return False
        
        output_dir = "tests/output/step3"
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # æ‰§è¡Œæ‰¹é‡åˆ†æ
        print(f"\nğŸ§  å¼€å§‹å¤šç»´åº¦å†…å®¹åˆ†æ...")
        
        try:
            # ä½¿ç”¨æ‰¹é‡åˆ†ææ–¹æ³•
            analysis_report = analyzer.analyze_multiple_notes(detailed_notes)
            
            print("âœ… æ‰¹é‡åˆ†æå®Œæˆ")
            print(f"ğŸ“Š åˆ†ææ‘˜è¦:")
            print(f"  åˆ†æç¬”è®°æ•°: {analysis_report.total_notes}")
            print(f"  å¹³å‡è¯„åˆ†: {analysis_report.average_score:.1f}/100")
            print(f"  è¯†åˆ«æˆåŠŸå…¬å¼: {len(analysis_report.success_formulas)}")
            print(f"  æå–å…±åŒæ¨¡å¼: {len(analysis_report.common_patterns)}")
            
            # æ˜¾ç¤ºæˆåŠŸå…¬å¼
            if analysis_report.success_formulas:
                print(f"\nğŸ¯ è¯†åˆ«çš„æˆåŠŸå…¬å¼:")
                for i, formula in enumerate(analysis_report.success_formulas[:3], 1):
                    print(f"  {i}. {formula}")
            
            # æ˜¾ç¤ºå…±åŒæ¨¡å¼
            if analysis_report.common_patterns:
                print(f"\nğŸ” å‘ç°çš„å…±åŒæ¨¡å¼:")
                for pattern_type, patterns in analysis_report.common_patterns.items():
                    if patterns:
                        print(f"  {pattern_type}: {', '.join(patterns[:2])}...")
            
            # ä¿å­˜åˆ†æç»“æœ
            print(f"\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
            analyzer.save_analysis_results(analysis_report, output_dir)
            
            # é¢å¤–ä¿å­˜æµ‹è¯•ä¸“ç”¨çš„ç»“æœæ–‡ä»¶
            test_result_file = Path(output_dir) / "step3_analysis_test_results.json"
            with open(test_result_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "test_timestamp": str(asyncio.get_event_loop().time()),
                    "test_status": "success",
                    "analysis_summary": {
                        "total_notes": analysis_report.total_notes,
                        "average_score": analysis_report.average_score,
                        "success_formulas_count": len(analysis_report.success_formulas),
                        "common_patterns_count": len(analysis_report.common_patterns)
                    },
                    "detailed_results": analysis_report.model_dump()
                }, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_result_file}")
            
            return True
            
        except Exception as analysis_error:
            logger.error(f"æ‰¹é‡åˆ†æå¤±è´¥: {analysis_error}")
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {analysis_error}")
            
            # å°è¯•å•ä¸ªåˆ†æä½œä¸ºfallback
            print("ğŸ”„ å°è¯•å•ä¸ªç¬”è®°åˆ†æ...")
            successful_analyses = 0
            
            for note in detailed_notes:
                success, result = await test_single_note_analysis(analyzer, note)
                if success:
                    successful_analyses += 1
            
            print(f"å•ä¸ªåˆ†æç»“æœ: {successful_analyses}/{len(detailed_notes)} æˆåŠŸ")
            return successful_analyses > 0
        
    except Exception as e:
        logger.error(f"âŒ Step3 æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def validate_step3_output(output_dir: str):
    """éªŒè¯Step3çš„è¾“å‡ºæ–‡ä»¶"""
    print("\nğŸ” éªŒè¯ Step3 è¾“å‡ºæ–‡ä»¶...")
    
    output_path = Path(output_dir)
    expected_files = [
        "content_analysis_results.json",  # ContentAnalyzerä¿å­˜çš„æ–‡ä»¶
        "content_analysis_report.md",
        "content_analysis_summary.txt",
        "step3_analysis_test_results.json"  # æµ‹è¯•ä¸“ç”¨ç»“æœæ–‡ä»¶
    ]
    
    found_files = []
    missing_files = []
    
    for file_name in expected_files:
        file_path = output_path / file_name
        if file_path.exists():
            found_files.append(file_name)
            file_size = file_path.stat().st_size
            print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path} ({file_size} bytes)")
        else:
            missing_files.append(file_name)
    
    if missing_files:
        print(f"âš ï¸ ç¼ºå¤±æ–‡ä»¶: {missing_files}")
    else:
        print("âœ… æ‰€æœ‰é¢„æœŸæ–‡ä»¶éƒ½å·²ç”Ÿæˆ")
    
    # æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶çš„å†…å®¹
    core_file = output_path / "step3_analysis_test_results.json"
    if core_file.exists():
        try:
            with open(core_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if data.get("test_status") == "success":
                    print("âœ… æµ‹è¯•ç»“æœæ–‡ä»¶å†…å®¹éªŒè¯é€šè¿‡")
                else:
                    print("âš ï¸ æµ‹è¯•ç»“æœæ–‡ä»¶æ˜¾ç¤ºæµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–æµ‹è¯•ç»“æœæ–‡ä»¶: {e}")
    
    return len(found_files) >= 2  # è‡³å°‘è¦æœ‰2ä¸ªå…³é”®æ–‡ä»¶

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Step3 å¤šç»´åº¦å†…å®¹åˆ†æ - æµ‹è¯•è„šæœ¬")
    print("=" * 80)
    
    # æ‰§è¡Œä¸»è¦æµ‹è¯•
    success1 = await test_step3_multi_dimensional_analysis()
    
    # éªŒè¯è¾“å‡º
    success2 = validate_step3_output("tests/output/step3")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š Step3 æµ‹è¯•æ€»ç»“:")
    print(f"å¤šç»´åº¦åˆ†ææµ‹è¯•: {'âœ… é€šè¿‡' if success1 else 'âŒ å¤±è´¥'}")
    print(f"è¾“å‡ºéªŒè¯æµ‹è¯•: {'âœ… é€šè¿‡' if success2 else 'âŒ å¤±è´¥'}")
    
    overall_success = success1 and success2
    print(f"\nğŸ¯ æ•´ä½“æµ‹è¯•ç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if overall_success else 'âŒ å­˜åœ¨å¤±è´¥'}")
    
    if overall_success:
        print("\nâœ¨ Step3 æµ‹è¯•å®Œæˆï¼Œå¯ä»¥ç»§ç»­æ‰§è¡Œ Step4 æµ‹è¯•")
        print("ğŸ’¡ æç¤º: Step3 çš„åˆ†æç»“æœå°†è¢« Step4 ç”¨äºç­–ç•¥åˆ¶å®š")
        print("ğŸ” åˆ†æç»´åº¦åŒ…æ‹¬:")
        print("  1ï¸âƒ£ å†…å®¹ç»“æ„åˆ†æ (æ ‡é¢˜-å¼€å¤´-æ­£æ–‡-ç»“å°¾)")
        print("  2ï¸âƒ£ æƒ…æ„Ÿä»·å€¼åˆ†æ (ç—›ç‚¹æŒ–æ˜-ä»·å€¼ä¸»å¼ )")  
        print("  3ï¸âƒ£ è§†è§‰å…ƒç´ åˆ†æ (é…å›¾é£æ ¼-æ’ç‰ˆç‰¹ç‚¹)")
    else:
        print("\nâš ï¸ è¯·æ£€æŸ¥å¹¶ä¿®å¤å¤±è´¥çš„æµ‹è¯•é¡¹")
        print("ğŸ”§ å¸¸è§é—®é¢˜:")
        print("  - æ£€æŸ¥OPENROUTER_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
        print("  - ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("  - æ£€æŸ¥Step2çš„è¾“å‡ºæ•°æ®æ˜¯å¦å­˜åœ¨")
    
    return overall_success

if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    import os
    if not os.getenv("OPENROUTER_API_KEY"):
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        print("Step3 éœ€è¦ OpenRouter API æ¥è¿›è¡Œå¤šç»´åº¦åˆ†æ")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export OPENROUTER_API_KEY='your_api_key'")
        sys.exit(1)
    else:
        print(f"âœ… OpenRouter API Key å·²é…ç½®")
    
    print()
    
    # è¿è¡Œæµ‹è¯•
    result = asyncio.run(main())
    
    # é€€å‡ºç 
    sys.exit(0 if result else 1)