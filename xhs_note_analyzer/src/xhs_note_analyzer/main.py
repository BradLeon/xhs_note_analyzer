#!/usr/bin/env python
import asyncio
import json
import logging
from typing import List, Dict, Any
from pathlib import Path
from pydantic import BaseModel

from crewai.flow import Flow, listen, start

# é…ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç°æœ‰ç»„ä»¶
from xhs_note_analyzer.tools.hot_note_finder_tool import find_hot_notes
from xhs_note_analyzer.crews.content_analyzer_crew import create_content_analyzer, ContentAnalysisReport
from xhs_note_analyzer.crews.strategy_maker_crew import create_strategy_maker, StrategyReport
from xhs_note_analyzer.tools.mediacrawler_client import MediaCrawlerClient


class NoteData(BaseModel):
    """ç¬”è®°åŸºç¡€æ•°æ®æ¨¡å‹"""
    note_id: str = ""    # ç¬”è®°ID
    note_title: str
    note_url: str
    impression: int = 0  # æ€»æ›å…‰é‡
    click: int = 0       # æ€»é˜…è¯»é‡
    like: int = 0        # æ€»ç‚¹èµé‡
    collect: int = 0     # æ€»æ”¶è—é‡
    comment: int = 0     # æ€»è¯„è®ºé‡
    engage: int = 0      # æ€»äº’åŠ¨é‡


class NoteContentData(BaseModel):
    """ç¬”è®°è¯¦ç»†å†…å®¹æ•°æ®æ¨¡å‹"""
    note_id: str = ""        # ç¬”è®°IDï¼ˆç”¨äºå…³è”ï¼‰
    title: str = ""          # ç¬”è®°æ ‡é¢˜
    basic_info: NoteData
    content: str = ""        # ç¬”è®°æ–‡å­—å†…å®¹
    images: List[str] = []   # å›¾ç‰‡URLåˆ—è¡¨
    video_url: str = ""      # è§†é¢‘URL
    author_info: Dict[str, Any] = {}  # ä½œè€…ä¿¡æ¯
    tags: List[str] = []     # æ ‡ç­¾åˆ—è¡¨
    create_time: str = ""    # åˆ›å»ºæ—¶é—´


class ContentAdvice(BaseModel):
    """å†…å®¹åˆ¶ä½œå»ºè®®æ¨¡å‹"""
    topic_suggestions: List[str] = []      # é€‰é¢˜å»ºè®®
    copywriting_advice: List[str] = []     # æ–‡æ¡ˆå»ºè®®
    creative_ideas: List[str] = []         # åˆ›æ„å»ºè®®
    video_script: str = ""                 # è§†é¢‘è„šæœ¬
    image_suggestions: List[str] = []      # é…å›¾å»ºè®®
    target_audience: str = ""              # ç›®æ ‡å—ä¼—
    content_strategy: str = ""             # å†…å®¹ç­–ç•¥


class XHSContentAnalysisState(BaseModel):
    """æµç¨‹çŠ¶æ€ç®¡ç†"""
    # è¾“å…¥å‚æ•°
    promotion_target: str = "å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº"
    business_context: str = ""
    business_goals: Dict[str, Any] = {}  # æ–°å¢ï¼šä¸šåŠ¡ç›®æ ‡å’Œçº¦æŸæ¡ä»¶
    
    # ç¬¬ä¸€æ­¥ï¼šç¬”è®°æŸ¥æ‰¾ç»“æœ
    found_notes: List[NoteData] = []
    notes_search_completed: bool = False
    
    # ç¬¬äºŒæ­¥ï¼šå†…å®¹è·å–ç»“æœ
    detailed_notes: List[NoteContentData] = []
    content_fetch_completed: bool = False
    
    # ç¬¬ä¸‰æ­¥ï¼šå†…å®¹åˆ†æç»“æœ
    content_analysis: List[ContentAdvice] = []
    content_analysis_report: ContentAnalysisReport = None
    analysis_completed: bool = False
    
    # ç¬¬å››æ­¥ï¼šç­–ç•¥åˆ¶å®šç»“æœ
    strategy_report: StrategyReport = None
    strategy_completed: bool = False
    
    # æœ€ç»ˆè¾“å‡º
    final_recommendations: Dict[str, Any] = {}


class XHSContentAnalysisFlow(Flow[XHSContentAnalysisState]):
    """å°çº¢ä¹¦å†…å®¹åˆ†ææµç¨‹
    
    ä¸²è¡Œæ‰§è¡Œå››ä¸ªæ­¥éª¤ï¼š
    1. ç¬”è®°æŸ¥æ‰¾ - ä½¿ç”¨browser_use agentæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°
    2. å†…å®¹è·å– - é€šè¿‡MediaCrawler APIè·å–è¯¦ç»†å†…å®¹
    3. å†…å®¹åˆ†æ - ä½¿ç”¨LLMåˆ†æå¹¶ç»™å‡ºåˆ¶ä½œå»ºè®®
    4. ç­–ç•¥åˆ¶å®š - åŸºäºåˆ†æç»“æœåˆ¶å®šå®æˆ˜ç­–ç•¥ï¼ˆé€‰é¢˜ã€TAã€åˆ›ä½œæŒ‡å¯¼ï¼‰
    """

    @start()
    def initialize_analysis(self):
        """åˆå§‹åŒ–åˆ†ææµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å°çº¢ä¹¦å†…å®¹åˆ†ææµç¨‹")
        print(f"ğŸ“Œ æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}")
        
        # è®¾ç½®é»˜è®¤ä¸šåŠ¡ä¸Šä¸‹æ–‡
        if not self.state.business_context:
            self.state.business_context = f"""
            æˆ‘ä»¬æ˜¯ä¸€å®¶ä¸“æ³¨äº{self.state.promotion_target}çš„æ•™è‚²æœåŠ¡æœºæ„ã€‚
            ä¸»è¦æä¾›æ±‚èŒæŒ‡å¯¼ã€é¢è¯•åŸ¹è®­ã€ç®€å†ä¼˜åŒ–ç­‰æœåŠ¡ã€‚
            ç›®æ ‡ç”¨æˆ·æ˜¯å‡†å¤‡è¿›å…¥å›½ä¼å¤®ä¼å·¥ä½œçš„æ±‚èŒè€…ã€‚
            """
        
        print("âœ… æµç¨‹åˆå§‹åŒ–å®Œæˆ")

    @listen(initialize_analysis)
    async def step1_find_hot_notes(self):
        """ç¬¬ä¸€æ­¥ï¼šæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°"""
        print("\nğŸ“ === ç¬¬ä¸€æ­¥ï¼šæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®° ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step1ï¼Œç›®æ ‡ï¼š{self.state.promotion_target}")
        
        try:
            # ä½¿ç”¨æ–°çš„find_hot_noteså·¥å…·å‡½æ•°
            print("ğŸ” å¯åŠ¨find_hot_noteså·¥å…·æŸ¥æ‰¾ä¼˜è´¨ç¬”è®°...")
            print(f"ğŸ¯ æŸ¥æ‰¾ç›®æ ‡: {self.state.promotion_target}")
            
            # è°ƒç”¨find_hot_noteså‡½æ•°
            result = await find_hot_notes(
                promotion_target=self.state.promotion_target, 
                max_pages=5,
                output_dir="output"
            )
            
            if result.success and result.data.note_data_list:
                logger.info(f"ğŸ” DEBUG: find_hot_notesè¿”å›æˆåŠŸï¼Œç¬”è®°æ•°ï¼š{len(result.data.note_data_list)}")
                # è½¬æ¢ç»“æœä¸ºNoteDataå¯¹è±¡
                found_notes = []
                for note_data in result.data.note_data_list:
                    # ä»URLæå–note_id
                    client = MediaCrawlerClient()
                    note_id = client.extract_note_id_from_url(note_data.note_url) or ""
                    
                    note = NoteData(
                        note_id=note_id,
                        note_title=note_data.note_title,
                        note_url=note_data.note_url,
                        impression=note_data.impression,
                        click=note_data.click,
                        like=note_data.like,
                        collect=note_data.collect,
                        comment=note_data.comment,
                        engage=note_data.engage
                    )
                    found_notes.append(note)
                
                self.state.found_notes = found_notes
                self.state.notes_search_completed = True
                
                print(f"âœ… find_hot_notesæˆåŠŸæ‰¾åˆ° {len(self.state.found_notes)} æ¡ç›¸å…³ç¬”è®°")
                for i, note in enumerate(self.state.found_notes, 1):
                    print(f"   {i}. {note.note_title} (ç‚¹èµ: {note.like:,}, æ”¶è—: {note.collect:,})")
                
                print(f"ğŸ“„ {result.message}")
                
            else:
                # å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
                print(f"âš ï¸ find_hot_notesæ‰§è¡Œå¤±è´¥: {result.message}")
                print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®...")
                self.state.found_notes = self._mock_find_notes()
                self.state.notes_search_completed = True
                
                print(f"âœ… ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œæ‰¾åˆ° {len(self.state.found_notes)} æ¡ç¬”è®°")
                for i, note in enumerate(self.state.found_notes, 1):
                    print(f"   {i}. {note.note_title} (ç‚¹èµ: {note.like:,})")
                
        except Exception as e:
            print(f"âŒ ç¬”è®°æŸ¥æ‰¾å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®...")
            # å³ä½¿å‡ºé”™ä¹Ÿæä¾›æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æµç¨‹èƒ½ç»§ç»­
            self.state.found_notes = self._mock_find_notes()
            self.state.notes_search_completed = True

    @listen(step1_find_hot_notes)
    def step2_fetch_note_content(self):
        """ç¬¬äºŒæ­¥ï¼šè·å–ç¬”è®°è¯¦ç»†å†…å®¹"""
        print("\nğŸ“ === ç¬¬äºŒæ­¥ï¼šè·å–ç¬”è®°è¯¦ç»†å†…å®¹ ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step2ï¼Œå¾…å¤„ç†ç¬”è®°æ•°ï¼š{len(self.state.found_notes) if self.state.found_notes else 0}")
        
        if not self.state.notes_search_completed or not self.state.found_notes:
            logger.warning("ğŸ” DEBUG: Step2è·³è¿‡ï¼ŒåŸå› ï¼šæ— ç¬”è®°æ•°æ®")
            print("âš ï¸ è·³è¿‡å†…å®¹è·å–ï¼šæœªæ‰¾åˆ°ç¬”è®°æ•°æ®")
            return
        
        try:
            print("ğŸ”„ é€šè¿‡MediaCrawler APIè·å–ç¬”è®°è¯¦ç»†å†…å®¹...")
            print(f"ğŸ“Š å¾…å¤„ç†ç¬”è®°æ•°é‡: {len(self.state.found_notes)}")
            
            # åˆ›å»ºMediaCrawlerå®¢æˆ·ç«¯å¹¶æ£€æŸ¥æœåŠ¡çŠ¶æ€
            client = MediaCrawlerClient()
            
            # æ£€æŸ¥APIæœåŠ¡å™¨å¥åº·çŠ¶æ€
            if client.health_check():
                print("âœ… MediaCrawler APIæœåŠ¡å™¨è¿æ¥æ­£å¸¸")
                
                # å°è¯•æ‰¹é‡è·å–å†…å®¹ï¼ˆæ›´é«˜æ•ˆï¼‰
                note_urls = [note.note_url for note in self.state.found_notes]
                print(f"ğŸš€ å¼€å§‹æ‰¹é‡è·å– {len(note_urls)} æ¡ç¬”è®°å†…å®¹...")
                
                batch_results = client.batch_crawl_notes(note_urls, fetch_comments=False)
                
                # å¤„ç†æ‰¹é‡ç»“æœ
                for i, (note, api_result) in enumerate(zip(self.state.found_notes, batch_results)):
                    print(f"ğŸ“¥ å¤„ç†ç¬”è®° {i+1}/{len(self.state.found_notes)}: {note.note_title}")
                    
                    if api_result.get("success", False):
                        # ä½¿ç”¨APIè¿”å›çš„çœŸå®æ•°æ®
                        detailed_content = self._convert_api_result_to_note_content(note, api_result)
                    else:
                        # APIå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                        print(f"  âš ï¸ APIè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {api_result.get('error', 'Unknown error')}")
                        detailed_content = self._create_mock_note_content(note)
                    
                    self.state.detailed_notes.append(detailed_content)
                
            else:
                print("âš ï¸ MediaCrawler APIæœåŠ¡å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                # æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œä¸ºæ‰€æœ‰ç¬”è®°åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
                for note in self.state.found_notes:
                    print(f"ğŸ“¥ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®: {note.note_title}")
                    detailed_content = self._create_mock_note_content(note)
                    self.state.detailed_notes.append(detailed_content)
            
            self.state.content_fetch_completed = True
            success_count = len([n for n in self.state.detailed_notes if n.content])
            print(f"âœ… å†…å®¹è·å–å®Œæˆ: æˆåŠŸ {success_count}/{len(self.state.detailed_notes)} æ¡")
            
        except Exception as e:
            print(f"âŒ å†…å®¹è·å–å¤±è´¥: {e}")
            # å³ä½¿å‡ºé”™ä¹Ÿåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æµç¨‹èƒ½ç»§ç»­
            print("ğŸ”„ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ä»¥ç¡®ä¿æµç¨‹ç»§ç»­...")
            for note in self.state.found_notes:
                if not any(d.basic_info.note_url == note.note_url for d in self.state.detailed_notes):
                    detailed_content = self._create_mock_note_content(note)
                    self.state.detailed_notes.append(detailed_content)
            
            self.state.content_fetch_completed = True

    @listen(step2_fetch_note_content)
    def step3_multi_dimensional_analysis(self):
        """ç¬¬ä¸‰æ­¥ï¼šå¤šç»´åº¦å†…å®¹åˆ†æ"""
        print("\nğŸ“ === ç¬¬ä¸‰æ­¥ï¼šå¤šç»´åº¦å†…å®¹åˆ†æ ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step3ï¼Œå¾…åˆ†æç¬”è®°æ•°ï¼š{len(self.state.detailed_notes) if self.state.detailed_notes else 0}")
        
        if not self.state.content_fetch_completed or not self.state.detailed_notes:
            logger.warning("ğŸ” DEBUG: Step3è·³è¿‡ï¼ŒåŸå› ï¼šæ— è¯¦ç»†å†…å®¹")
            print("âš ï¸ è·³è¿‡å†…å®¹åˆ†æï¼šæœªè·å–åˆ°è¯¦ç»†å†…å®¹")
            return
        
        try:
            print("ğŸ§  å¯åŠ¨ä¸‰ç»´åº¦æ·±åº¦å†…å®¹åˆ†æ...")
            print(f"ğŸ“Š å¾…åˆ†æç¬”è®°æ•°é‡: {len(self.state.detailed_notes)}")
            
            # åˆ›å»ºå†…å®¹åˆ†æå™¨
            content_analyzer = create_content_analyzer()
            
            # æ‰§è¡Œå¤šç»´åº¦åˆ†æ
            print("ğŸ” æ‰§è¡Œåˆ†æç»´åº¦:")
            print("   1ï¸âƒ£ å†…å®¹ç»“æ„åˆ†æ (æ ‡é¢˜-å¼€å¤´-æ­£æ–‡-ç»“å°¾)")
            print("   2ï¸âƒ£ æƒ…æ„Ÿä»·å€¼åˆ†æ (ç—›ç‚¹æŒ–æ˜-ä»·å€¼ä¸»å¼ )")  
            print("   3ï¸âƒ£ è§†è§‰å…ƒç´ åˆ†æ (é…å›¾é£æ ¼-æ’ç‰ˆç‰¹ç‚¹)")
            
            # æ‰¹é‡åˆ†ææ‰€æœ‰ç¬”è®°
            analysis_report = content_analyzer.analyze_multiple_notes(self.state.detailed_notes)
            
            # ä¿å­˜åˆ†æç»“æœ
            self.state.content_analysis_report = analysis_report
            self.state.analysis_completed = True
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            content_analyzer.save_analysis_results(analysis_report, "output")
            
            # æ˜¾ç¤ºåˆ†ææ‘˜è¦
            print(f"âœ… å¤šç»´åº¦åˆ†æå®Œæˆ!")
            print(f"ğŸ“ˆ åˆ†æç»“æœæ‘˜è¦:")
            print(f"   â€¢ åˆ†æç¬”è®°æ•°: {analysis_report.total_notes}")
            print(f"   â€¢ å¹³å‡è¯„åˆ†: {analysis_report.average_score:.1f}/100")
            print(f"   â€¢ è¯†åˆ«æˆåŠŸå…¬å¼: {len(analysis_report.success_formulas)}")
            print(f"   â€¢ æå–å…±åŒæ¨¡å¼: {len(analysis_report.common_patterns)}")
            
            # æ¸…ç©ºæ—§çš„å…¼å®¹æ€§æ•°æ®ï¼Œä½¿ç”¨æ–°çš„æŠ¥å‘Šæ ¼å¼
            self.state.content_analysis = []
            
            # ç”Ÿæˆæœ€ç»ˆå»ºè®®
            self.state.final_recommendations = self._generate_final_recommendations_from_analysis()
            
        except Exception as e:
            print(f"âŒ å¤šç»´åº¦åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # å›é€€åˆ°ç®€å•åˆ†æ
            print("ğŸ”„ å›é€€åˆ°åŸºç¡€åˆ†ææ¨¡å¼...")
            self._fallback_basic_analysis()
            self.state.analysis_completed = True

    @listen(step3_multi_dimensional_analysis)
    def step4_strategy_making(self):
        """ç¬¬å››æ­¥ï¼šå®æˆ˜ç­–ç•¥åˆ¶å®š"""
        print("\nğŸ“ === ç¬¬å››æ­¥ï¼šå®æˆ˜ç­–ç•¥åˆ¶å®š ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step4ï¼Œåˆ†ææŠ¥å‘ŠçŠ¶æ€ï¼š{self.state.analysis_completed}")
        
        if not self.state.analysis_completed or not self.state.content_analysis_report:
            logger.warning("ğŸ” DEBUG: Step4è·³è¿‡ï¼ŒåŸå› ï¼šå†…å®¹åˆ†ææœªå®Œæˆ")
            print("âš ï¸ è·³è¿‡ç­–ç•¥åˆ¶å®šï¼šå†…å®¹åˆ†ææœªå®Œæˆ")
            return
        
        try:
            print("ğŸ§  åŸºäºåˆ†æç»“æœåˆ¶å®šå®æˆ˜ç­–ç•¥...")
            print("ğŸ¯ ç­–ç•¥åˆ¶å®šç»´åº¦:")
            print("   1ï¸âƒ£ é€‰é¢˜ç­–ç•¥ - çƒ­é—¨é€‰é¢˜æŒ–æ˜ã€å…³é”®è¯é›†ç¾¤ã€ç«äº‰åˆ†æ")
            print("   2ï¸âƒ£ TAç­–ç•¥ - ç”¨æˆ·ç”»åƒã€éœ€æ±‚åˆ†æã€è§¦è¾¾ç­–ç•¥")  
            print("   3ï¸âƒ£ å†…å®¹åˆ›ä½œæŒ‡å¯¼ - æ–‡æ¡ˆæŒ‡å—ã€é…å›¾æŒ‡å—ã€è§†é¢‘è„šæœ¬")
            
            # åˆ›å»ºç­–ç•¥åˆ¶å®šå™¨
            strategy_maker = create_strategy_maker()
            
            # æ‰§è¡Œç­–ç•¥åˆ¶å®š
            strategy_report = strategy_maker.make_strategy(
                business_context=self.state.business_context,
                target_product=self.state.promotion_target,
                content_analysis_report=self.state.content_analysis_report,
                business_goals=self.state.business_goals
            )
            
            # ä¿å­˜ç­–ç•¥ç»“æœ
            self.state.strategy_report = strategy_report
            self.state.strategy_completed = True
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            strategy_maker.save_strategy_results(strategy_report, "output")
            
            # æ˜¾ç¤ºç­–ç•¥æ‘˜è¦
            print(f"âœ… å®æˆ˜ç­–ç•¥åˆ¶å®šå®Œæˆ!")
            print(f"ğŸ“ˆ ç­–ç•¥æ‘˜è¦:")
            print(f"   â€¢ é€‰é¢˜å»ºè®®: {len(strategy_report.topic_strategy.trending_topics)}ä¸ª")
            print(f"   â€¢ æ ¸å¿ƒå»ºè®®: {len(strategy_report.key_recommendations)}æ¡")
            print(f"   â€¢ æˆåŠŸè¦ç´ : {len(strategy_report.success_factors)}ä¸ªå…³é”®è¦ç´ ")
            print(f"   â€¢ å·®å¼‚åŒ–è¦ç‚¹: {len(strategy_report.differentiation_points)}ä¸ª")
            
            # æ›´æ–°æœ€ç»ˆå»ºè®®
            self.state.final_recommendations.update({
                "strategy_summary": strategy_report.report_summary,
                "key_strategies": strategy_report.key_recommendations,
                "success_factors": strategy_report.success_factors,
                "differentiation_points": strategy_report.differentiation_points
            })
            
        except Exception as e:
            print(f"âŒ ç­–ç•¥åˆ¶å®šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # è®¾ç½®åŸºç¡€ç­–ç•¥ç»“æœ
            self.state.strategy_completed = False
            print("ğŸ”„ å°†ä½¿ç”¨åŸºç¡€åˆ†æç»“æœç»§ç»­æµç¨‹...")

    @listen(step4_strategy_making)
    def finalize_and_output(self):
        """è¾“å‡ºæœ€ç»ˆç»“æœ"""
        print("\nğŸ“ === è¾“å‡ºæœ€ç»ˆç»“æœ ===")
        
        if not self.state.analysis_completed:
            print("âš ï¸ åˆ†ææœªå®Œæˆï¼Œè¾“å‡ºéƒ¨åˆ†ç»“æœ")
        
        if not self.state.strategy_completed:
            print("âš ï¸ ç­–ç•¥åˆ¶å®šæœªå®Œæˆï¼Œä»…è¾“å‡ºåˆ†æç»“æœ")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        self._save_analysis_results()
        
        # æ˜¾ç¤ºæ‘˜è¦
        self._display_analysis_summary()
        
        print("ğŸ‰ å°çº¢ä¹¦å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹å®Œæˆï¼")

    def _mock_find_notes(self) -> List[NoteData]:
        """æ¨¡æ‹Ÿç¬”è®°æŸ¥æ‰¾ç»“æœï¼ˆå ä½ç¬¦å‡½æ•°ï¼‰"""
        # TODO: æ›¿æ¢ä¸ºçœŸå®çš„browser_useè°ƒç”¨
        return [
            NoteData(
                note_id="676a4d0a000000001f00c58a",
                note_title="è€ƒå…¬ä¸Šå²¸æ”»ç•¥åˆ†äº«",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58a",
                impression=50000, click=8000, like=1200, collect=800, comment=150, engage=2150
            ),
            NoteData(
                note_id="676a4d0a000000001f00c58b",
                note_title="å›½ä¼é¢è¯•æŠ€å·§å¤§å…¨",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58b", 
                impression=30000, click=5000, like=800, collect=500, comment=100, engage=1400
            ),
            NoteData(
                note_id="676a4d0a000000001f00c58c",
                note_title="å¤®ä¼æ±‚èŒç®€å†æ¨¡æ¿",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58c",
                impression=40000, click=6500, like=1000, collect=600, comment=120, engage=1720
            )
        ]

    
    def _convert_api_result_to_note_content(self, note: NoteData, api_result: Dict[str, Any]) -> NoteContentData:
        """å°†APIè¿”å›ç»“æœè½¬æ¢ä¸ºNoteContentDataæ ¼å¼"""
        raw_data = api_result.get("data", {})
        
        # å¤„ç†å›¾ç‰‡URLåˆ—è¡¨
        images = []
        if raw_data.get("images"):
            images = raw_data["images"] if isinstance(raw_data["images"], list) else [raw_data["images"]]
        
        # å¤„ç†ä½œè€…ä¿¡æ¯
        author_info = {}
        if raw_data.get("user_name"):
            author_info["name"] = raw_data["user_name"]
        if raw_data.get("user_id"):
            author_info["user_id"] = raw_data["user_id"]
        if raw_data.get("followers_count"):
            author_info["followers"] = raw_data["followers_count"]
        
        # å¤„ç†æ ‡ç­¾
        tags = []
        if raw_data.get("tags"):
            tags = raw_data["tags"] if isinstance(raw_data["tags"], list) else [raw_data["tags"]]
        elif raw_data.get("tag_list"):
            tags = raw_data["tag_list"]
        
        # æ›´æ–°åŸºç¡€æ•°æ®ç»Ÿè®¡
        note.like = raw_data.get("liked_count", note.like)
        note.collect = raw_data.get("collected_count", note.collect)
        note.comment = raw_data.get("comments_count", note.comment)
        note.click = raw_data.get("view_count", note.click)
        
        return NoteContentData(
            note_id=note.note_id,
            title=raw_data.get("title", note.note_title),
            basic_info=note,
            content=raw_data.get("desc", raw_data.get("content", f"è¿™æ˜¯{note.note_title}çš„è¯¦ç»†å†…å®¹...")),
            images=images,
            video_url=raw_data.get("video_url", ""),
            author_info=author_info,
            tags=tags,
            create_time=raw_data.get("publish_time", raw_data.get("create_time", ""))
        )

    def _create_mock_note_content(self, note: NoteData) -> NoteContentData:
        """åˆ›å»ºæ¨¡æ‹Ÿç¬”è®°å†…å®¹æ•°æ®"""
        return NoteContentData(
            note_id=note.note_id,
            title=note.note_title,
            basic_info=note,
            content=f"è¿™æ˜¯{note.note_title}çš„è¯¦ç»†å†…å®¹ï¼ŒåŒ…å«æ±‚èŒæŒ‡å¯¼ã€é¢è¯•æŠ€å·§å’ŒèŒåœºå»ºè®®ç­‰ç›¸å…³ä¿¡æ¯ã€‚",
            images=["https://example.com/image1.jpg", "https://example.com/image2.jpg"],
            author_info={"name": "æ±‚èŒå¯¼å¸ˆ", "followers": 10000, "user_id": "mock_user"},
            tags=["æ±‚èŒ", "å›½ä¼", "é¢è¯•", "èŒåœº", "æŒ‡å¯¼"],
            create_time="2024-01-01 12:00:00"
        )


    def _generate_final_recommendations_from_analysis(self) -> Dict[str, Any]:
        """åŸºäºå¤šç»´åº¦åˆ†æç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        if not self.state.content_analysis_report:
            return self._generate_final_recommendations()
        
        report = self.state.content_analysis_report
        
        return {
            "analysis_summary": f"å®Œæˆå¯¹{report.total_notes}ç¯‡ä¼˜è´¨ç¬”è®°çš„ä¸‰ç»´åº¦æ·±åº¦åˆ†æ",
            "average_score": f"{report.average_score:.1f}/100",
            "success_formulas": report.success_formulas,
            "common_patterns": report.common_patterns,
            "top_recommendations": [
                "å¤åˆ¶é«˜åˆ†ç¬”è®°çš„æˆåŠŸè¦ç´ ",
                "å…³æ³¨å…±åŒæ¨¡å¼ä¸­çš„å…³é”®å…ƒç´ ", 
                "é‡ç‚¹ä¼˜åŒ–è¯„åˆ†è¾ƒä½çš„ç»´åº¦",
                "å»ºç«‹æ ‡å‡†åŒ–çš„å†…å®¹åˆ›ä½œæµç¨‹"
            ],
            "implementation_plan": {
                "çŸ­æœŸç›®æ ‡": "åº”ç”¨è¯†åˆ«å‡ºçš„æˆåŠŸå…¬å¼",
                "ä¸­æœŸç›®æ ‡": "å»ºç«‹ä¸ªäººå†…å®¹åˆ›ä½œä½“ç³»",
                "é•¿æœŸç›®æ ‡": "å½¢æˆå¯å¤åˆ¶çš„çˆ†æ¬¾å†…å®¹æ¨¡æ¿"
            }
        }

    def _generate_final_recommendations(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»¼åˆå»ºè®®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
        return {
            "summary": f"åŸºäº{len(self.state.detailed_notes)}æ¡ä¼˜è´¨ç¬”è®°çš„åˆ†æ",
            "top_topics": ["çƒ­é—¨é€‰é¢˜1", "çƒ­é—¨é€‰é¢˜2", "çƒ­é—¨é€‰é¢˜3"],
            "content_strategy": "å†…å®¹ç­–ç•¥å»ºè®®...",
            "implementation_plan": "å®æ–½è®¡åˆ’..."
        }

    def _fallback_basic_analysis(self):
        """å›é€€åŸºç¡€åˆ†ææ¨¡å¼"""
        print("ğŸ“ æ‰§è¡ŒåŸºç¡€å†…å®¹åˆ†æ...")
        
        for detailed_note in self.state.detailed_notes:
            print(f"ğŸ” åŸºç¡€åˆ†æ: {detailed_note.basic_info.note_title}")
            
            # ç®€å•çš„å†…å®¹åˆ†æ
            advice = ContentAdvice(
                topic_suggestions=[f"åŸºäº{detailed_note.basic_info.note_title}çš„é€‰é¢˜å»ºè®®"],
                copywriting_advice=["æ ‡é¢˜ä¼˜åŒ–", "å¼€å¤´æ”¹è¿›", "ç»“å°¾å¼ºåŒ–"],
                creative_ideas=["è§†è§‰ä¼˜åŒ–", "äº’åŠ¨è®¾è®¡"],
                content_strategy=f"åŸºç¡€åˆ†æ - ç‚¹èµæ•°: {detailed_note.basic_info.like}"
            )
            self.state.content_analysis.append(advice)
        
        # ç”ŸæˆåŸºç¡€å»ºè®®
        self.state.final_recommendations = self._generate_final_recommendations()
        
        print(f"âœ… åŸºç¡€åˆ†æå®Œæˆ: {len(self.state.content_analysis)} æ¡")

    def _save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        try:
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            result_file = output_dir / "xhs_content_analysis_result.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(self.state.model_dump(), f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜: {result_file}")
            
            # ä¿å­˜å¯è¯»æ ¼å¼çš„æ‘˜è¦
            summary_file = output_dir / "analysis_summary.txt"
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("å°çº¢ä¹¦å†…å®¹åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}\n")
                f.write(f"åˆ†æç¬”è®°æ•°: {len(self.state.found_notes)}\n")
                f.write(f"è¯¦ç»†å†…å®¹æ•°: {len(self.state.detailed_notes)}\n")
                analysis_count = len(self.state.content_analysis_report.analysis_results) if self.state.content_analysis_report else len(self.state.content_analysis)
                f.write(f"åˆ†æå»ºè®®æ•°: {analysis_count}\n\n")
                
                if self.state.final_recommendations:
                    f.write("ç»¼åˆå»ºè®®:\n")
                    f.write(json.dumps(self.state.final_recommendations, ensure_ascii=False, indent=2))
            
            print(f"ğŸ“‹ åˆ†ææ‘˜è¦å·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _display_analysis_summary(self):
        """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š å®Œæ•´åˆ†æä¸ç­–ç•¥æ‘˜è¦")
        print("="*70)
        print(f"ğŸ¯ æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}")
        print(f"ğŸ“ˆ æ‰¾åˆ°ç¬”è®°: {len(self.state.found_notes)} æ¡")
        print(f"ğŸ“„ è¯¦ç»†å†…å®¹: {len(self.state.detailed_notes)} æ¡")
        analysis_count = len(self.state.content_analysis_report.analysis_results) if self.state.content_analysis_report else len(self.state.content_analysis)
        print(f"ğŸ’¡ åˆ†æå»ºè®®: {analysis_count} æ¡")
        
        # å†…å®¹åˆ†æç»“æœ
        if self.state.content_analysis_report:
            print(f"ğŸ“‹ åˆ†ææŠ¥å‘Š: å¹³å‡è¯„åˆ† {self.state.content_analysis_report.average_score:.1f}/100")
        
        # ç­–ç•¥åˆ¶å®šç»“æœ
        if self.state.strategy_completed and self.state.strategy_report:
            print(f"ğŸš€ ç­–ç•¥åˆ¶å®š: å·²å®Œæˆ")
            print(f"   â€¢ é€‰é¢˜å»ºè®®: {len(self.state.strategy_report.topic_strategy.trending_topics)}ä¸ª")
            print(f"   â€¢ æ ¸å¿ƒå»ºè®®: {len(self.state.strategy_report.key_recommendations)}æ¡")
            print(f"   â€¢ æˆåŠŸè¦ç´ : {len(self.state.strategy_report.success_factors)}ä¸ª")
        else:
            print(f"ğŸš€ ç­–ç•¥åˆ¶å®š: æœªå®Œæˆ")
        
        # æ ¸å¿ƒå»ºè®®å±•ç¤º
        if self.state.final_recommendations:
            print(f"\nğŸ¯ æ ¸å¿ƒå»ºè®®æ€»ç»“:")
            for key, value in self.state.final_recommendations.items():
                if isinstance(value, list):
                    print(f"   {key}: {len(value)}é¡¹å»ºè®®")
                else:
                    print(f"   {key}: {value}")
        
        print("="*70)


async def kickoff_content_analysis(promotion_target: str = "å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº", 
                                  business_context: str = "",
                                  business_goals: Dict[str, Any] = None):
    """å¯åŠ¨å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹"""
    print("ğŸš€ å¯åŠ¨å°çº¢ä¹¦å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹...")
    
    # åˆ›å»ºæµç¨‹å®ä¾‹
    flow = XHSContentAnalysisFlow()
    
    # è®¾ç½®åˆå§‹çŠ¶æ€
    flow.state.promotion_target = promotion_target
    if business_context:
        flow.state.business_context = business_context
    if business_goals:
        flow.state.business_goals = business_goals
    
    # æ‰§è¡Œæµç¨‹
    await flow.kickoff()
    
    return flow.state


def plot_content_analysis_flow():
    """ç»˜åˆ¶æµç¨‹å›¾"""
    flow = XHSContentAnalysisFlow()
    flow.plot()


if __name__ == "__main__":
    # æ‰§è¡Œå†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹
    business_goals = {
        "target_audience": "25-35å²å‡†å¤‡è¿›å…¥å›½ä¼å¤®ä¼çš„æ±‚èŒè€…",
        "content_volume": "æ¯å‘¨å‘å¸ƒ3-5ç¯‡å†…å®¹",
        "conversion_goal": "å°ç¨‹åºæ³¨å†Œç”¨æˆ·æ•°æå‡50%",
        "time_frame": "3ä¸ªæœˆå†…å®Œæˆç­–ç•¥å®æ–½",
        "budget_constraint": "ä¸­ç­‰é¢„ç®—ï¼Œæ³¨é‡ROI"
    }
    
    result = asyncio.run(kickoff_content_analysis(
        promotion_target="å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº",
        business_context="ä¸“æ³¨äºå›½ä¼å¤®ä¼æ±‚èŒåŸ¹è®­çš„æ•™è‚²æœºæ„",
        business_goals=business_goals
    ))
    
    print("\nğŸ‰ æµç¨‹æ‰§è¡Œå®Œæˆï¼")
