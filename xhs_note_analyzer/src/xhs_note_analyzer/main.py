#!/usr/bin/env python
import asyncio
import json
import logging
from typing import List, Dict, Any
from pathlib import Path

from crewai.flow import Flow, listen, start

# é…ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥å…¬å…±æ•°æ®æ¨¡å‹
from xhs_note_analyzer.models import (
    NoteData, 
    NoteContentData, 
    ContentAdvice, 
    XHSContentAnalysisState
)

# å¯¼å…¥ç°æœ‰ç»„ä»¶
from xhs_note_analyzer.tools.hot_note_finder_tool import find_hot_notes
from xhs_note_analyzer.crews.content_analyzer_crew import create_content_analyzer
from xhs_note_analyzer.crews.strategy_maker_crew import create_strategy_maker, StrategyReport
from xhs_note_analyzer.tools.mediacrawler_client import MediaCrawlerClient

# ä»å…¬å…±æ¨¡å‹å¯¼å…¥
from xhs_note_analyzer.models import ContentAnalysisReport


class XHSContentAnalysisFlow(Flow[XHSContentAnalysisState]):
    """å°çº¢ä¹¦å†…å®¹åˆ†ææµç¨‹
    
    ä¸²è¡Œæ‰§è¡Œå››ä¸ªæ­¥éª¤ï¼š
    1. ç¬”è®°æŸ¥æ‰¾ - ä½¿ç”¨browser_use agentæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°
    2. å†…å®¹è·å– - é€šè¿‡MediaCrawler APIè·å–è¯¦ç»†å†…å®¹
    3. å†…å®¹åˆ†æ - ä½¿ç”¨LLMåˆ†æå¹¶ç»™å‡ºåˆ¶ä½œå»ºè®®
    4. ç­–ç•¥åˆ¶å®š - åŸºäºåˆ†æç»“æœåˆ¶å®šå®æˆ˜ç­–ç•¥ï¼ˆé€‰é¢˜ã€TAã€åˆ›ä½œæŒ‡å¯¼ï¼‰
    """

    @start()
    def initialize_analysis(self):
        """åˆå§‹åŒ–åˆ†ææµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å°çº¢ä¹¦å†…å®¹åˆ†ææµç¨‹")
        print(f"ğŸ“Œ æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}")
        
        # è®¾ç½®é»˜è®¤ä¸šåŠ¡ä¸Šä¸‹æ–‡
        if not self.state.business_context:
            self.state.business_context = f"""
            æˆ‘ä»¬æ˜¯ä¸€å®¶ä¸“æ³¨äº{self.state.promotion_target}çš„æ•™è‚²æœåŠ¡æœºæ„ã€‚
            ä¸»è¦æä¾›æ±‚èŒæŒ‡å¯¼ã€é¢è¯•åŸ¹è®­ã€ç®€å†ä¼˜åŒ–ç­‰æœåŠ¡ã€‚
            ç›®æ ‡ç”¨æˆ·æ˜¯å‡†å¤‡è¿›å…¥å›½ä¼å¤®ä¼å·¥ä½œçš„æ±‚èŒè€…ã€‚
            """
        
        print("âœ… æµç¨‹åˆå§‹åŒ–å®Œæˆ")

    @listen(initialize_analysis)
    async def step1_find_hot_notes(self):
        """ç¬¬ä¸€æ­¥ï¼šæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°"""
        print("\nğŸ“ === ç¬¬ä¸€æ­¥ï¼šæŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®° ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step1ï¼Œç›®æ ‡ï¼š{self.state.promotion_target}")
        
        try:
            # ä½¿ç”¨æ–°çš„find_hot_noteså·¥å…·å‡½æ•°
            print("ğŸ” å¯åŠ¨find_hot_noteså·¥å…·æŸ¥æ‰¾ä¼˜è´¨ç¬”è®°...")
            print(f"ğŸ¯ æŸ¥æ‰¾ç›®æ ‡: {self.state.promotion_target}")
            
            # è°ƒç”¨find_hot_noteså‡½æ•°
            result = await find_hot_notes(
                promotion_target=self.state.promotion_target, 
                max_pages=5,
                output_dir="output"
            )
            
            if result.success and result.data.note_data_list:
                logger.info(f"ğŸ” DEBUG: find_hot_notesè¿”å›æˆåŠŸï¼Œç¬”è®°æ•°ï¼š{len(result.data.note_data_list)}")
                # è½¬æ¢ç»“æœä¸ºNoteDataå¯¹è±¡
                found_notes = []
                for note_data in result.data.note_data_list:
                    # ä»URLæå–note_id
                    client = MediaCrawlerClient()
                    note_id = client.extract_note_id_from_url(note_data.note_url) or ""
                    
                    note = NoteData(
                        note_id=note_id,
                        note_title=note_data.note_title,
                        note_url=note_data.note_url,
                        impression=note_data.impression,
                        click=note_data.click,
                        like=note_data.like,
                        collect=note_data.collect,
                        comment=note_data.comment,
                        engage=note_data.engage
                    )
                    found_notes.append(note)
                
                self.state.found_notes = found_notes
                self.state.notes_search_completed = True
                
                print(f"âœ… find_hot_notesæˆåŠŸæ‰¾åˆ° {len(self.state.found_notes)} æ¡ç›¸å…³ç¬”è®°")
                for i, note in enumerate(self.state.found_notes, 1):
                    print(f"   {i}. {note.note_title} (ç‚¹èµ: {note.like:,}, æ”¶è—: {note.collect:,})")
                
                print(f"ğŸ“„ {result.message}")
                
            else:
                # å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
                print(f"âš ï¸ find_hot_notesæ‰§è¡Œå¤±è´¥: {result.message}")
                print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®...")
                self.state.found_notes = self._mock_find_notes()
                self.state.notes_search_completed = True
                
                print(f"âœ… ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œæ‰¾åˆ° {len(self.state.found_notes)} æ¡ç¬”è®°")
                for i, note in enumerate(self.state.found_notes, 1):
                    print(f"   {i}. {note.note_title} (ç‚¹èµ: {note.like:,})")
                
        except Exception as e:
            print(f"âŒ ç¬”è®°æŸ¥æ‰¾å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®...")
            # å³ä½¿å‡ºé”™ä¹Ÿæä¾›æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æµç¨‹èƒ½ç»§ç»­
            self.state.found_notes = self._mock_find_notes()
            self.state.notes_search_completed = True

    @listen(step1_find_hot_notes)
    def step2_fetch_note_content(self):
        """ç¬¬äºŒæ­¥ï¼šè·å–ç¬”è®°è¯¦ç»†å†…å®¹"""
        print("\nğŸ“ === ç¬¬äºŒæ­¥ï¼šè·å–ç¬”è®°è¯¦ç»†å†…å®¹ ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step2ï¼Œå¾…å¤„ç†ç¬”è®°æ•°ï¼š{len(self.state.found_notes) if self.state.found_notes else 0}")
        
        if not self.state.notes_search_completed or not self.state.found_notes:
            logger.warning("ğŸ” DEBUG: Step2è·³è¿‡ï¼ŒåŸå› ï¼šæ— ç¬”è®°æ•°æ®")
            print("âš ï¸ è·³è¿‡å†…å®¹è·å–ï¼šæœªæ‰¾åˆ°ç¬”è®°æ•°æ®")
            return
        
        try:
            print("ğŸ”„ é€šè¿‡MediaCrawler APIè·å–ç¬”è®°è¯¦ç»†å†…å®¹...")
            print(f"ğŸ“Š å¾…å¤„ç†ç¬”è®°æ•°é‡: {len(self.state.found_notes)}")
            
            # åˆ›å»ºMediaCrawlerå®¢æˆ·ç«¯å¹¶æ£€æŸ¥æœåŠ¡çŠ¶æ€
            client = MediaCrawlerClient()
            
            # æ£€æŸ¥APIæœåŠ¡å™¨å¥åº·çŠ¶æ€
            if client.health_check():
                print("âœ… MediaCrawler APIæœåŠ¡å™¨è¿æ¥æ­£å¸¸")
                
                # å°è¯•æ‰¹é‡è·å–å†…å®¹ï¼ˆæ›´é«˜æ•ˆï¼‰
                note_urls = [note.note_url for note in self.state.found_notes]
                print(f"ğŸš€ å¼€å§‹æ‰¹é‡è·å– {len(note_urls)} æ¡ç¬”è®°å†…å®¹...")
                
                batch_results = client.batch_crawl_notes(note_urls, fetch_comments=False)
                
                # å¤„ç†æ‰¹é‡ç»“æœ
                for i, (note, api_result) in enumerate(zip(self.state.found_notes, batch_results)):
                    print(f"ğŸ“¥ å¤„ç†ç¬”è®° {i+1}/{len(self.state.found_notes)}: {note.note_title}")
                    
                    if api_result.get("success", False):
                        # ä½¿ç”¨APIè¿”å›çš„çœŸå®æ•°æ®
                        detailed_content = self._convert_api_result_to_note_content(note, api_result)
                    else:
                        # APIå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                        print(f"  âš ï¸ APIè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {api_result.get('error', 'Unknown error')}")
                        detailed_content = self._create_mock_note_content(note)
                    
                    self.state.detailed_notes.append(detailed_content)
                
            else:
                print("âš ï¸ MediaCrawler APIæœåŠ¡å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                # æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œä¸ºæ‰€æœ‰ç¬”è®°åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
                for note in self.state.found_notes:
                    print(f"ğŸ“¥ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®: {note.note_title}")
                    detailed_content = self._create_mock_note_content(note)
                    self.state.detailed_notes.append(detailed_content)
            
            self.state.content_fetch_completed = True
            success_count = len([n for n in self.state.detailed_notes if n.content])
            print(f"âœ… å†…å®¹è·å–å®Œæˆ: æˆåŠŸ {success_count}/{len(self.state.detailed_notes)} æ¡")
            
        except Exception as e:
            print(f"âŒ å†…å®¹è·å–å¤±è´¥: {e}")
            # å³ä½¿å‡ºé”™ä¹Ÿåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æµç¨‹èƒ½ç»§ç»­
            print("ğŸ”„ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ä»¥ç¡®ä¿æµç¨‹ç»§ç»­...")
            for note in self.state.found_notes:
                if not any(d.basic_info.note_url == note.note_url for d in self.state.detailed_notes):
                    detailed_content = self._create_mock_note_content(note)
                    self.state.detailed_notes.append(detailed_content)
            
            self.state.content_fetch_completed = True

    @listen(step2_fetch_note_content)
    def step3_multi_dimensional_analysis(self):
        """ç¬¬ä¸‰æ­¥ï¼šå¤šç»´åº¦å†…å®¹åˆ†æ"""
        print("\nğŸ“ === ç¬¬ä¸‰æ­¥ï¼šå¤šç»´åº¦å†…å®¹åˆ†æ ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step3ï¼Œå¾…åˆ†æç¬”è®°æ•°ï¼š{len(self.state.detailed_notes) if self.state.detailed_notes else 0}")
        
        if not self.state.content_fetch_completed or not self.state.detailed_notes:
            logger.warning("ğŸ” DEBUG: Step3è·³è¿‡ï¼ŒåŸå› ï¼šæ— è¯¦ç»†å†…å®¹")
            print("âš ï¸ è·³è¿‡å†…å®¹åˆ†æï¼šæœªè·å–åˆ°è¯¦ç»†å†…å®¹")
            return
        
        try:
            print("ğŸ§  å¯åŠ¨ä¸‰ç»´åº¦æ·±åº¦å†…å®¹åˆ†æ...")
            print(f"ğŸ“Š å¾…åˆ†æç¬”è®°æ•°é‡: {len(self.state.detailed_notes)}")
            
            # é™åˆ¶åªåˆ†æå‰3ä¸ªç¬”è®°ä»¥æé«˜æ•ˆç‡
            analysis_notes = self.state.detailed_notes[:3] if len(self.state.detailed_notes) > 3 else self.state.detailed_notes
            if len(self.state.detailed_notes) > 3:
                print(f"âœ‚ï¸ é™åˆ¶åˆ†ææ•°é‡ä¸º3ä¸ªç¬”è®°")
            
            # åˆ›å»ºå†…å®¹åˆ†æå™¨
            content_analyzer = create_content_analyzer()
            
            # æ‰§è¡Œå¤šç»´åº¦åˆ†æ
            print("ğŸ” æ‰§è¡Œåˆ†æç»´åº¦:")
            print("   1ï¸âƒ£ å†…å®¹ç»“æ„åˆ†æ (æ ‡é¢˜-å¼€å¤´-æ­£æ–‡-ç»“å°¾)")
            print("   2ï¸âƒ£ æƒ…æ„Ÿä»·å€¼åˆ†æ (ç—›ç‚¹æŒ–æ˜-ä»·å€¼ä¸»å¼ )")  
            print("   3ï¸âƒ£ è§†è§‰å…ƒç´ åˆ†æ (é…å›¾é£æ ¼-æ’ç‰ˆç‰¹ç‚¹)")
            
            # æ‰¹é‡åˆ†ææ‰€æœ‰ç¬”è®°
            analysis_report = content_analyzer.analyze_multiple_notes(analysis_notes)
            
            # ä¿å­˜åˆ†æç»“æœ
            self.state.content_analysis_report = analysis_report
            self.state.analysis_completed = True
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            content_analyzer.save_analysis_results(analysis_report, "output")
            
            # æ˜¾ç¤ºåˆ†ææ‘˜è¦
            print(f"âœ… å¤šç»´åº¦åˆ†æå®Œæˆ!")
            print(f"ğŸ“ˆ åˆ†æç»“æœæ‘˜è¦:")
            print(f"   â€¢ åˆ†æç¬”è®°æ•°: {analysis_report.total_notes}")
            print(f"   â€¢ å¹³å‡è¯„åˆ†: {analysis_report.average_score:.1f}/100")
            print(f"   â€¢ è¯†åˆ«æˆåŠŸå…¬å¼: {len(analysis_report.success_formulas)}")
            print(f"   â€¢ æå–å…±åŒæ¨¡å¼: {len(analysis_report.common_patterns)}")
            
            # æ˜¾ç¤ºæˆåŠŸå…¬å¼
            if analysis_report.success_formulas:
                print(f"\nğŸ¯ è¯†åˆ«çš„æˆåŠŸå…¬å¼:")
                for i, formula in enumerate(analysis_report.success_formulas[:3], 1):
                    print(f"  {i}. {formula}")
            
            # æ˜¾ç¤ºå…±åŒæ¨¡å¼
            if analysis_report.common_patterns:
                print(f"\nğŸ” å‘ç°çš„å…±åŒæ¨¡å¼:")
                for pattern_type, patterns in analysis_report.common_patterns.items():
                    if patterns:
                        print(f"  {pattern_type}: {', '.join(patterns[:2])}...")
            
            # æ¸…ç©ºæ—§çš„å…¼å®¹æ€§æ•°æ®ï¼Œä½¿ç”¨æ–°çš„æŠ¥å‘Šæ ¼å¼
            self.state.content_analysis = []
            
            # ç”Ÿæˆæœ€ç»ˆå»ºè®®
            self.state.final_recommendations = self._generate_final_recommendations_from_analysis()
            
        except Exception as e:
            print(f"âŒ å¤šç»´åº¦åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # å›é€€åˆ°ç®€å•åˆ†æ
            print("ğŸ”„ å›é€€åˆ°åŸºç¡€åˆ†ææ¨¡å¼...")
            self._fallback_basic_analysis()
            self.state.analysis_completed = True

    @listen(step3_multi_dimensional_analysis)
    def step4_strategy_making(self):
        """ç¬¬å››æ­¥ï¼šå®æˆ˜ç­–ç•¥åˆ¶å®š"""
        print("\nğŸ“ === ç¬¬å››æ­¥ï¼šå®æˆ˜ç­–ç•¥åˆ¶å®š ===")
        logger.info(f"ğŸ” DEBUG: å¼€å§‹Step4ï¼Œåˆ†ææŠ¥å‘ŠçŠ¶æ€ï¼š{self.state.analysis_completed}")
        
        if not self.state.analysis_completed or not self.state.content_analysis_report:
            logger.warning("ğŸ” DEBUG: Step4è·³è¿‡ï¼ŒåŸå› ï¼šå†…å®¹åˆ†ææœªå®Œæˆ")
            print("âš ï¸ è·³è¿‡ç­–ç•¥åˆ¶å®šï¼šå†…å®¹åˆ†ææœªå®Œæˆ")
            return
        
        try:
            print("ğŸ§  åŸºäºåˆ†æç»“æœåˆ¶å®šå®æˆ˜ç­–ç•¥...")
            print("ğŸ¯ ç­–ç•¥åˆ¶å®šç»´åº¦:")
            print("   1ï¸âƒ£ é€‰é¢˜ç­–ç•¥ - çƒ­é—¨é€‰é¢˜æŒ–æ˜ã€å…³é”®è¯é›†ç¾¤ã€ç«äº‰åˆ†æ")
            print("   2ï¸âƒ£ TAç­–ç•¥ - ç”¨æˆ·ç”»åƒã€éœ€æ±‚åˆ†æã€è§¦è¾¾ç­–ç•¥")  
            print("   3ï¸âƒ£ å†…å®¹åˆ›ä½œæŒ‡å¯¼ - æ–‡æ¡ˆæŒ‡å—ã€é…å›¾æŒ‡å—ã€è§†é¢‘è„šæœ¬")
            
            # åˆ›å»ºç­–ç•¥åˆ¶å®šå™¨
            strategy_maker = create_strategy_maker()
            
            # æ‰§è¡Œç­–ç•¥åˆ¶å®š
            strategy_report = strategy_maker.make_strategy(
                business_context=self.state.business_context,
                target_product=self.state.promotion_target,
                content_analysis_report=self.state.content_analysis_report,
                business_goals=self.state.business_goals
            )
            
            # ä¿å­˜ç­–ç•¥ç»“æœ
            self.state.strategy_report = strategy_report
            self.state.strategy_completed = True
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            strategy_maker.save_strategy_results(strategy_report, "output")
            
            # æ˜¾ç¤ºç­–ç•¥æ‘˜è¦
            print(f"âœ… å®æˆ˜ç­–ç•¥åˆ¶å®šå®Œæˆ!")
            print(f"ğŸ“ˆ ç­–ç•¥æ‘˜è¦:")
            print(f"   â€¢ ç­–ç•¥ç‰ˆæœ¬: {strategy_report.strategy_version}")
            print(f"   â€¢ æœ‰æ•ˆæœŸ: {strategy_report.validity_period}")
            print(f"   â€¢ æ ¸å¿ƒå»ºè®®: {len(strategy_report.key_recommendations)}æ¡")
            print(f"   â€¢ æˆåŠŸè¦ç´ : {len(strategy_report.success_factors)}ä¸ªå…³é”®è¦ç´ ")
            print(f"   â€¢ å·®å¼‚åŒ–è¦ç‚¹: {len(strategy_report.differentiation_points)}ä¸ª")
            
            # æ˜¾ç¤ºæ ¸å¿ƒå»ºè®®
            if strategy_report.key_recommendations:
                print(f"\nğŸ¯ æ ¸å¿ƒå»ºè®®:")
                for i, rec in enumerate(strategy_report.key_recommendations[:3], 1):
                    print(f"  {i}. {rec}")
            
            # æ˜¾ç¤ºé€‰é¢˜ç­–ç•¥
            if strategy_report.topic_strategy.recommended_topics:
                print(f"\nğŸ“ é€‰é¢˜ç­–ç•¥:")
                print(f"  ç²¾é€‰é€‰é¢˜æ•°: {len(strategy_report.topic_strategy.recommended_topics)}")
                for i, topic in enumerate(strategy_report.topic_strategy.recommended_topics[:3], 1):
                    print(f"    {i}. {topic.title} (ä¼˜å…ˆçº§: {topic.priority_score}/10)")
            
            # æ˜¾ç¤ºTAç­–ç•¥
            if strategy_report.target_audience_strategy.primary_persona:
                print(f"\nğŸ‘¥ ç›®æ ‡ç”¨æˆ·ç”»åƒ:")
                persona = strategy_report.target_audience_strategy.primary_persona
                for key, value in list(persona.items())[:3]:
                    print(f"    {key}: {value}")
            
            # æ˜¾ç¤ºåˆ›ä½œæŒ‡å—
            print(f"\nğŸ¨ å†…å®¹åˆ›ä½œæŒ‡å—:")
            guide = strategy_report.content_creation_guide
            if guide.topic_content_packages:
                print(f"  é€‰é¢˜å†…å®¹åŒ…: {len(guide.topic_content_packages)} ä¸ª")
                for i, package in enumerate(guide.topic_content_packages[:2], 1):
                    print(f"    {i}. {package.topic_title}")
            
            # æ›´æ–°æœ€ç»ˆå»ºè®®
            self.state.final_recommendations.update({
                "strategy_summary": strategy_report.report_summary,
                "key_strategies": strategy_report.key_recommendations,
                "success_factors": strategy_report.success_factors,
                "differentiation_points": strategy_report.differentiation_points
            })
            
        except Exception as e:
            print(f"âŒ ç­–ç•¥åˆ¶å®šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # è®¾ç½®åŸºç¡€ç­–ç•¥ç»“æœ
            self.state.strategy_completed = False
            print("ğŸ”„ å°†ä½¿ç”¨åŸºç¡€åˆ†æç»“æœç»§ç»­æµç¨‹...")

    @listen(step4_strategy_making)
    def finalize_and_output(self):
        """è¾“å‡ºæœ€ç»ˆç»“æœ"""
        print("\nğŸ“ === è¾“å‡ºæœ€ç»ˆç»“æœ ===")
        
        if not self.state.analysis_completed:
            print("âš ï¸ åˆ†ææœªå®Œæˆï¼Œè¾“å‡ºéƒ¨åˆ†ç»“æœ")
        
        if not self.state.strategy_completed:
            print("âš ï¸ ç­–ç•¥åˆ¶å®šæœªå®Œæˆï¼Œä»…è¾“å‡ºåˆ†æç»“æœ")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        self._save_analysis_results()
        
        # æ˜¾ç¤ºæ‘˜è¦
        self._display_analysis_summary()
        
        print("ğŸ‰ å°çº¢ä¹¦å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹å®Œæˆï¼")

    def _mock_find_notes(self) -> List[NoteData]:
        """æ¨¡æ‹Ÿç¬”è®°æŸ¥æ‰¾ç»“æœï¼ˆå ä½ç¬¦å‡½æ•°ï¼‰"""
        # TODO: æ›¿æ¢ä¸ºçœŸå®çš„browser_useè°ƒç”¨
        return [
            NoteData(
                note_id="676a4d0a000000001f00c58a",
                note_title="è€ƒå…¬ä¸Šå²¸æ”»ç•¥åˆ†äº«",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58a",
                impression=50000, click=8000, like=1200, collect=800, comment=150, engage=2150
            ),
            NoteData(
                note_id="676a4d0a000000001f00c58b",
                note_title="å›½ä¼é¢è¯•æŠ€å·§å¤§å…¨",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58b", 
                impression=30000, click=5000, like=800, collect=500, comment=100, engage=1400
            ),
            NoteData(
                note_id="676a4d0a000000001f00c58c",
                note_title="å¤®ä¼æ±‚èŒç®€å†æ¨¡æ¿",
                note_url="https://xiaohongshu.com/note/676a4d0a000000001f00c58c",
                impression=40000, click=6500, like=1000, collect=600, comment=120, engage=1720
            )
        ]

    
    def _convert_api_result_to_note_content(self, note: NoteData, api_result: Dict[str, Any]) -> NoteContentData:
        """å°†APIè¿”å›ç»“æœè½¬æ¢ä¸ºNoteContentDataæ ¼å¼ï¼Œé€‚é…æ–°çš„APIå“åº”æ ¼å¼"""
        raw_data = api_result.get("data", {})
        
        # å¤„ç†å›¾ç‰‡URLåˆ—è¡¨
        images = []
        if raw_data.get("images"):
            images = raw_data["images"] if isinstance(raw_data["images"], list) else [raw_data["images"]]
        elif raw_data.get("image_list"):
            images = raw_data["image_list"] if isinstance(raw_data["image_list"], list) else [raw_data["image_list"]]
        
        # å¤„ç†ä½œè€…ä¿¡æ¯ - é€‚é…å¤šç§å­—æ®µå
        author_info = {}
        if raw_data.get("nickname"):
            author_info["name"] = raw_data["nickname"] 
        elif raw_data.get("user_name"):
            author_info["name"] = raw_data["user_name"]
        
        if raw_data.get("user_id"):
            author_info["user_id"] = raw_data["user_id"]
        if raw_data.get("follower_count"):
            author_info["followers"] = raw_data["follower_count"]
        
        # å¤„ç†æ ‡ç­¾
        tags = []
        if raw_data.get("tags"):
            tags = raw_data["tags"] if isinstance(raw_data["tags"], list) else [raw_data["tags"]]
        elif raw_data.get("note_tag_list"):
            # ä»note_tag_listæå–æ ‡ç­¾å
            tag_list = raw_data["note_tag_list"]
            if isinstance(tag_list, list):
                tags = [tag.get("name", str(tag)) for tag in tag_list if tag]
        
        # å¤„ç†è§†é¢‘URL
        video_url = ""
        if raw_data.get("video_url"):
            video_url = raw_data["video_url"]
        elif raw_data.get("video") and isinstance(raw_data["video"], dict):
            video_url = raw_data["video"].get("url", "")
        
        # å¤„ç†å‘å¸ƒæ—¶é—´
        create_time = ""
        if raw_data.get("last_update_time"):
            create_time = raw_data["last_update_time"]
        elif raw_data.get("publish_time"):
            create_time = raw_data["publish_time"]
        elif raw_data.get("create_time"):
            create_time = raw_data["create_time"]
        
        return NoteContentData(
            note_id=raw_data.get("note_id"),
            title=raw_data.get("title"),
            basic_info=note,
            content=raw_data.get("desc", raw_data.get("content", f"è¿™æ˜¯{note.note_title}çš„è¯¦ç»†å†…å®¹...")),
            images=images,
            video_url=video_url,
            author_info=author_info,
            tags=tags,
            create_time=create_time
        )

    def _create_mock_note_content(self, note: NoteData) -> NoteContentData:
        """åˆ›å»ºæ¨¡æ‹Ÿç¬”è®°å†…å®¹æ•°æ®ï¼Œä½¿ç”¨ä¸°å¯Œçš„æµ‹è¯•å†…å®¹"""
        # æ ¹æ®ç¬”è®°ç±»å‹ç”Ÿæˆä¸åŒçš„æ¨¡æ‹Ÿå†…å®¹
        if "æ”»ç•¥" in note.note_title or "æ±‚èŒ" in note.note_title:
            content = """ğŸ”¥å›½ä¼æ±‚èŒå…¨æ”»ç•¥ï½œä»0åˆ°offerçš„å®Œæ•´è·¯å¾„

ğŸ“Œç—›ç‚¹åˆ†æï¼š
å¾ˆå¤šå°ä¼™ä¼´è§‰å¾—å›½ä¼é—¨æ§›é«˜ã€ç«äº‰æ¿€çƒˆï¼Œä¸çŸ¥é“ä»ä½•å…¥æ‰‹

âœ¨æ ¸å¿ƒç­–ç•¥ï¼š
1ï¸âƒ£ç®€å†åŒ…è£…ï¼šçªå‡ºç¨³å®šæ€§å’Œå›¢é˜Ÿåˆä½œèƒ½åŠ›
2ï¸âƒ£ç¬”è¯•å‡†å¤‡ï¼šè¡Œæµ‹+ä¸“ä¸šçŸ¥è¯†åŒç®¡é½ä¸‹  
3ï¸âƒ£é¢è¯•æŠ€å·§ï¼šå±•ç°ä»·å€¼è§‚åŒ¹é…åº¦
4ï¸âƒ£å†…æ¨æ¸ é“ï¼šå­¦ä¼šåˆ©ç”¨æ ¡å‹èµ„æº

ğŸ’¡å®ç”¨tipsï¼š
â€¢ å…³æ³¨å¤®ä¼å®˜ç½‘æ‹›è˜ä¿¡æ¯
â€¢ å‡†å¤‡æ ‡å‡†åŒ–ç®€å†æ¨¡æ¿
â€¢ æ¨¡æ‹Ÿé¢è¯•ç»ƒä¹ è¡¨è¾¾èƒ½åŠ›

æƒ³äº†è§£æ›´å¤šæ±‚èŒå¹²è´§ï¼Œå…³æ³¨æˆ‘ï¼æ¯å¤©åˆ†äº«èŒåœºæˆé•¿ç§˜ç±ï½"""
        elif "é¢è¯•" in note.note_title:
            content = """å¤®ä¼é¢è¯•é€šå…³ç§˜ç±ï½œè®©é¢è¯•å®˜çœ¼å‰ä¸€äº®çš„æŠ€å·§

ğŸ¯é¢è¯•ç—›ç‚¹ï¼š
â€¢ ç´§å¼ åˆ°è¯´ä¸å‡ºè¯
â€¢ ä¸çŸ¥é“å¦‚ä½•å±•ç¤ºè‡ªå·±
â€¢ æ‹…å¿ƒå›ç­”ä¸å¤Ÿä¸“ä¸š

ğŸ’ªè§£å†³æ–¹æ¡ˆï¼š
ã€è‡ªæˆ‘ä»‹ç»ç¯‡ã€‘
30ç§’é»„é‡‘æ³•åˆ™ï¼šåŸºæœ¬ä¿¡æ¯+æ ¸å¿ƒä¼˜åŠ¿+åŒ¹é…åº¦

ã€ä¸“ä¸šé—®é¢˜ç¯‡ã€‘
STARæ³•åˆ™ï¼šæƒ…å¢ƒ+ä»»åŠ¡+è¡ŒåŠ¨+ç»“æœ

ã€å‹åŠ›é¢è¯•ç¯‡ã€‘
ä¿æŒå†·é™ï¼Œé€æ­¥åˆ†æé—®é¢˜

ğŸ”¥å®æˆ˜æ¼”ç»ƒï¼š
é—®ï¼šä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸ï¼Ÿ
ç­”ï¼šè´µå…¬å¸çš„ä¼ä¸šæ–‡åŒ–ä¸æˆ‘çš„ä»·å€¼è§‚é«˜åº¦åŒ¹é…ï¼Œæˆ‘å¸Œæœ›åœ¨è¿™é‡Œ...

è®°ä½ï¼šé¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œå±•ç°çœŸå®çš„è‡ªå·±ï¼"""
        elif "ç®€å†" in note.note_title or "æ¨¡æ¿" in note.note_title:
            content = """ğŸ“„è¶…å®ç”¨ç®€å†æ¨¡æ¿å…è´¹é€ï½œHRæœ€çˆ±çš„ç®€å†é•¿è¿™æ ·

âš¡å¸¸è§ç®€å†é—®é¢˜ï¼š
âŒå†…å®¹å†—é•¿ï¼Œé‡ç‚¹ä¸çªå‡º
âŒæ ¼å¼æ··ä¹±ï¼Œç¼ºä¹é€»è¾‘
âŒåƒç¯‡ä¸€å¾‹ï¼Œæ²¡æœ‰äº®ç‚¹

âœ…ä¼˜åŒ–åçš„ç®€å†æ¨¡æ¿ï¼š
ã€åŸºæœ¬ä¿¡æ¯åŒºã€‘
å§“åã€è”ç³»æ–¹å¼ã€æ±‚èŒæ„å‘

ã€æ•™è‚²èƒŒæ™¯ã€‘
å­¦å†+GPA+æ ¸å¿ƒè¯¾ç¨‹+è·å¥–æƒ…å†µ

ã€é¡¹ç›®ç»å†ã€‘ 
é¡¹ç›®åç§°+è§’è‰²+æˆæœ+æŠ€èƒ½

ã€å®ä¹ ç»å†ã€‘
å…¬å¸+å²—ä½+ä¸šç»©+æ”¶è·

ğŸ“‹æ¨¡æ¿ç‰¹è‰²ï¼š
ğŸ¨ç®€çº¦å¤§æ°”çš„è®¾è®¡é£æ ¼
ğŸ“Šæ¸…æ™°çš„ä¿¡æ¯å±‚çº§ç»“æ„
â­çªå‡ºä¸ªäººæ ¸å¿ƒç«äº‰åŠ›

ğŸ’¬è¯„è®ºåŒºå›å¤"ç®€å†"å³å¯è·å–æ¨¡æ¿
ä¸€èµ·åŠ©åŠ›æ±‚èŒæˆåŠŸï¼"""
        else:
            content = f"è¿™æ˜¯{note.note_title}çš„è¯¦ç»†å†…å®¹ï¼ŒåŒ…å«æ±‚èŒæŒ‡å¯¼ã€é¢è¯•æŠ€å·§å’ŒèŒåœºå»ºè®®ç­‰ç›¸å…³ä¿¡æ¯ã€‚"
        
        return NoteContentData(
            note_id=note.note_id,
            title=note.note_title,
            basic_info=note,
            content=content,
            images=[
                "https://example.com/career-guide-1.jpg",
                "https://example.com/career-tips-2.jpg", 
                "https://example.com/interview-skills-3.jpg"
            ],
            author_info={"name": "èŒåœºå¯¼å¸ˆå°ç‹", "followers": 15000, "user_id": "career_mentor_wang"},
            tags=["å›½ä¼æ±‚èŒ", "é¢è¯•æŠ€å·§", "èŒåœºæ”»ç•¥", "æ±‚èŒæŒ‡å¯¼", "ç®€å†ä¼˜åŒ–"],
            create_time="2024-01-15 14:30:00"
        )


    def _generate_final_recommendations_from_analysis(self) -> Dict[str, Any]:
        """åŸºäºå¤šç»´åº¦åˆ†æç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        if not self.state.content_analysis_report:
            return self._generate_final_recommendations()
        
        report = self.state.content_analysis_report
        
        return {
            "analysis_summary": f"å®Œæˆå¯¹{report.total_notes}ç¯‡ä¼˜è´¨ç¬”è®°çš„ä¸‰ç»´åº¦æ·±åº¦åˆ†æ",
            "average_score": f"{report.average_score:.1f}/100",
            "success_formulas": report.success_formulas,
            "common_patterns": report.common_patterns,
            "top_recommendations": [
                "å¤åˆ¶é«˜åˆ†ç¬”è®°çš„æˆåŠŸè¦ç´ ",
                "å…³æ³¨å…±åŒæ¨¡å¼ä¸­çš„å…³é”®å…ƒç´ ", 
                "é‡ç‚¹ä¼˜åŒ–è¯„åˆ†è¾ƒä½çš„ç»´åº¦",
                "å»ºç«‹æ ‡å‡†åŒ–çš„å†…å®¹åˆ›ä½œæµç¨‹"
            ],
            "implementation_plan": {
                "çŸ­æœŸç›®æ ‡": "åº”ç”¨è¯†åˆ«å‡ºçš„æˆåŠŸå…¬å¼",
                "ä¸­æœŸç›®æ ‡": "å»ºç«‹ä¸ªäººå†…å®¹åˆ›ä½œä½“ç³»",
                "é•¿æœŸç›®æ ‡": "å½¢æˆå¯å¤åˆ¶çš„çˆ†æ¬¾å†…å®¹æ¨¡æ¿"
            }
        }

    def _generate_final_recommendations(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆç»¼åˆå»ºè®®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
        return {
            "summary": f"åŸºäº{len(self.state.detailed_notes)}æ¡ä¼˜è´¨ç¬”è®°çš„åˆ†æ",
            "top_topics": ["çƒ­é—¨é€‰é¢˜1", "çƒ­é—¨é€‰é¢˜2", "çƒ­é—¨é€‰é¢˜3"],
            "content_strategy": "å†…å®¹ç­–ç•¥å»ºè®®...",
            "implementation_plan": "å®æ–½è®¡åˆ’..."
        }

    def _fallback_basic_analysis(self):
        """å›é€€åŸºç¡€åˆ†ææ¨¡å¼"""
        print("ğŸ“ æ‰§è¡ŒåŸºç¡€å†…å®¹åˆ†æ...")
        
        for detailed_note in self.state.detailed_notes:
            print(f"ğŸ” åŸºç¡€åˆ†æ: {detailed_note.basic_info.note_title}")
            
            # ç®€å•çš„å†…å®¹åˆ†æ
            advice = ContentAdvice(
                topic_suggestions=[f"åŸºäº{detailed_note.basic_info.note_title}çš„é€‰é¢˜å»ºè®®"],
                copywriting_advice=["æ ‡é¢˜ä¼˜åŒ–", "å¼€å¤´æ”¹è¿›", "ç»“å°¾å¼ºåŒ–"],
                creative_ideas=["è§†è§‰ä¼˜åŒ–", "äº’åŠ¨è®¾è®¡"],
                content_strategy=f"åŸºç¡€åˆ†æ - ç‚¹èµæ•°: {detailed_note.basic_info.like}"
            )
            self.state.content_analysis.append(advice)
        
        # ç”ŸæˆåŸºç¡€å»ºè®®
        self.state.final_recommendations = self._generate_final_recommendations()
        
        print(f"âœ… åŸºç¡€åˆ†æå®Œæˆ: {len(self.state.content_analysis)} æ¡")

    def _save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        try:
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            result_file = output_dir / "xhs_content_analysis_result.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(self.state.model_dump(), f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜: {result_file}")
            
            # ä¿å­˜å¯è¯»æ ¼å¼çš„æ‘˜è¦
            summary_file = output_dir / "analysis_summary.txt"
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("å°çº¢ä¹¦å†…å®¹åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}\n")
                f.write(f"åˆ†æç¬”è®°æ•°: {len(self.state.found_notes)}\n")
                f.write(f"è¯¦ç»†å†…å®¹æ•°: {len(self.state.detailed_notes)}\n")
                analysis_count = len(self.state.content_analysis_report.analysis_results) if self.state.content_analysis_report else len(self.state.content_analysis)
                f.write(f"åˆ†æå»ºè®®æ•°: {analysis_count}\n\n")
                
                if self.state.final_recommendations:
                    f.write("ç»¼åˆå»ºè®®:\n")
                    f.write(json.dumps(self.state.final_recommendations, ensure_ascii=False, indent=2))
            
            print(f"ğŸ“‹ åˆ†ææ‘˜è¦å·²ä¿å­˜: {summary_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _display_analysis_summary(self):
        """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š å®Œæ•´åˆ†æä¸ç­–ç•¥æ‘˜è¦")
        print("="*70)
        print(f"ğŸ¯ æ¨å¹¿ç›®æ ‡: {self.state.promotion_target}")
        print(f"ğŸ“ˆ æ‰¾åˆ°ç¬”è®°: {len(self.state.found_notes)} æ¡")
        print(f"ğŸ“„ è¯¦ç»†å†…å®¹: {len(self.state.detailed_notes)} æ¡")
        analysis_count = len(self.state.content_analysis_report.analysis_results) if self.state.content_analysis_report else len(self.state.content_analysis)
        print(f"ğŸ’¡ åˆ†æå»ºè®®: {analysis_count} æ¡")
        
        # å†…å®¹åˆ†æç»“æœ
        if self.state.content_analysis_report:
            print(f"ğŸ“‹ åˆ†ææŠ¥å‘Š: å¹³å‡è¯„åˆ† {self.state.content_analysis_report.average_score:.1f}/100")
        
        # ç­–ç•¥åˆ¶å®šç»“æœ
        if self.state.strategy_completed and self.state.strategy_report:
            print(f"ğŸš€ ç­–ç•¥åˆ¶å®š: å·²å®Œæˆ")
            print(f"   â€¢ é€‰é¢˜å»ºè®®: {len(self.state.strategy_report.topic_strategy.recommended_topics)}ä¸ª")
            print(f"   â€¢ æ ¸å¿ƒå»ºè®®: {len(self.state.strategy_report.key_recommendations)}æ¡")
            print(f"   â€¢ æˆåŠŸè¦ç´ : {len(self.state.strategy_report.success_factors)}ä¸ª")
        else:
            print(f"ğŸš€ ç­–ç•¥åˆ¶å®š: æœªå®Œæˆ")
        
        # æ ¸å¿ƒå»ºè®®å±•ç¤º
        if self.state.final_recommendations:
            print(f"\nğŸ¯ æ ¸å¿ƒå»ºè®®æ€»ç»“:")
            for key, value in self.state.final_recommendations.items():
                if isinstance(value, list):
                    print(f"   {key}: {len(value)}é¡¹å»ºè®®")
                else:
                    print(f"   {key}: {value}")
        
        print("="*70)


async def kickoff_content_analysis(promotion_target: str = "å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº", 
                                  business_context: str = "",
                                  business_goals: Dict[str, Any] = None):
    """å¯åŠ¨å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹"""
    print("ğŸš€ å¯åŠ¨å°çº¢ä¹¦å†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹...")
    
    # åˆ›å»ºæµç¨‹å®ä¾‹
    flow = XHSContentAnalysisFlow()
    
    # è®¾ç½®åˆå§‹çŠ¶æ€
    flow.state.promotion_target = promotion_target
    if business_context:
        flow.state.business_context = business_context
    if business_goals:
        flow.state.business_goals = business_goals
    
    # æ‰§è¡Œæµç¨‹
    await flow.kickoff()
    
    return flow.state


def plot_content_analysis_flow():
    """ç»˜åˆ¶æµç¨‹å›¾"""
    flow = XHSContentAnalysisFlow()
    flow.plot()


if __name__ == "__main__":
    # æ‰§è¡Œå†…å®¹åˆ†æä¸ç­–ç•¥åˆ¶å®šæµç¨‹
    business_goals = {
        "target_audience": "25-35å²å‡†å¤‡è¿›å…¥å›½ä¼å¤®ä¼çš„æ±‚èŒè€…",
        "content_volume": "æ¯å‘¨å‘å¸ƒ3-5ç¯‡å†…å®¹",
        "conversion_goal": "å°ç¨‹åºæ³¨å†Œç”¨æˆ·æ•°æå‡50%",
        "time_frame": "3ä¸ªæœˆå†…å®Œæˆç­–ç•¥å®æ–½",
        "budget_constraint": "ä¸­ç­‰é¢„ç®—ï¼Œæ³¨é‡ROI"
    }
    
    result = asyncio.run(kickoff_content_analysis(
        promotion_target="å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº",
        business_context="ä¸“æ³¨äºå›½ä¼å¤®ä¼æ±‚èŒåŸ¹è®­çš„æ•™è‚²æœºæ„",
        business_goals=business_goals
    ))
    
    print("\nğŸ‰ æµç¨‹æ‰§è¡Œå®Œæˆï¼")
