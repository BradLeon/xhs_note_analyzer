import asyncio
import json
import os
import logging
import pyperclip
import psutil
from pathlib import Path
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from browser_use import Agent, Controller, ActionResult
from browser_use.browser import BrowserSession, BrowserProfile
from langchain_openai import ChatOpenAI
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.prompts import PromptTemplate
from playwright.async_api import Page
from crewai.tools import BaseTool
import re


# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hot_note_finder_tool.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# å°è¯•å¯¼å…¥EventBusç”¨äºå†…å­˜ç›‘æµ‹
try:
    from bubus.service import EventBus
    EVENTBUS_AVAILABLE = True
except ImportError:
    EVENTBUS_AVAILABLE = False
    logger.warning("âš ï¸ æ— æ³•å¯¼å…¥EventBusï¼Œå†…å­˜ç›‘æµ‹åŠŸèƒ½å°†å—é™")


async def monitor_eventbus_memory(interval: int = 30) -> None:
    """
    å®šæ—¶ç›‘æµ‹EventBuså†…å­˜ä½¿ç”¨æƒ…å†µ
    
    Args:
        interval: ç›‘æµ‹é—´éš”ï¼Œå•ä½ç§’ï¼Œé»˜è®¤30ç§’
    """
    if not EVENTBUS_AVAILABLE:
        logger.warning("âš ï¸ EventBusä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜ç›‘æµ‹")
        return
        
    monitor_count = 0
    try:
        logger.info(f"ğŸ“Š å¼€å§‹å†…å­˜ç›‘æµ‹ï¼Œé—´éš”{interval}ç§’")
        
        while True:
            try:
                monitor_count += 1
                
                # è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨æƒ…å†µ
                current_process = psutil.Process()
                process_memory_mb = current_process.memory_info().rss / 1024 / 1024
                
                # å°è¯•è·å–EventBusçš„å†…å­˜ä½¿ç”¨æƒ…å†µ
                eventbus_memory_mb = 0
                active_instances = 0
                
                if hasattr(EventBus, '_instances') and EventBus._instances:
                    active_instances = len([ref for ref in EventBus._instances if ref() is not None])
                    # ç®€å•ä¼°ç®—EventBuså†…å­˜ä½¿ç”¨
                    eventbus_memory_mb = active_instances * 10  # ç²—ç•¥ä¼°ç®—æ¯ä¸ªå®ä¾‹10MB
                
                logger.info(f"ğŸ“Š å†…å­˜ç›‘æµ‹#{monitor_count} - è¿›ç¨‹æ€»å†…å­˜: {process_memory_mb:.1f}MB, EventBuså®ä¾‹: {active_instances}, ä¼°ç®—EventBuså†…å­˜: {eventbus_memory_mb:.1f}MB")
                
                # å†…å­˜è­¦å‘Šé˜ˆå€¼
                if process_memory_mb > 500:  # è¿›ç¨‹å†…å­˜è¶…è¿‡500MB
                    logger.warning(f"âš ï¸ è¿›ç¨‹å†…å­˜ä½¿ç”¨è¿‡é«˜: {process_memory_mb:.1f}MB")
                    
                if eventbus_memory_mb > 50:  # EventBuså†…å­˜è¶…è¿‡50MB
                    logger.warning(f"âš ï¸ EventBuså†…å­˜ä½¿ç”¨è¿‡é«˜: {eventbus_memory_mb:.1f}MBï¼Œå»ºè®®æ¸…ç†")
                    
            except Exception as e:
                logger.error(f"âŒ å†…å­˜ç›‘æµ‹å¤±è´¥: {e}")
                
            await asyncio.sleep(interval)
            
    except asyncio.CancelledError:
        logger.info("ğŸ›‘ å†…å­˜ç›‘æµ‹ä»»åŠ¡å·²å–æ¶ˆ")
        raise
    except Exception as e:
        logger.error(f"âŒ å†…å­˜ç›‘æµ‹å¼‚å¸¸é€€å‡º: {e}")

async def cleanup_eventbus(agent: Agent = None) -> None:
    """
    æ¸…ç†EventBuså†…å­˜
    
    Args:
        agent: éœ€è¦æ¸…ç†çš„Agentå®ä¾‹
    """
    try:
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†EventBuså†…å­˜...")
        
        # æ¸…ç†Agentç›¸å…³çš„EventBus
        if agent and hasattr(agent, '_eventbus'):
            if hasattr(agent._eventbus, 'stop'):
                await agent._eventbus.stop(clear=True)
                logger.info("âœ… Agent EventBuså·²æ¸…ç†")
        
        # å°è¯•æ¸…ç†å…¨å±€EventBuså®ä¾‹
        if EVENTBUS_AVAILABLE and hasattr(EventBus, '_instances'):
            cleaned_count = 0
            for ref in list(EventBus._instances):
                instance = ref()
                if instance is not None:
                    try:
                        if hasattr(instance, 'stop'):
                            await instance.stop(clear=True)
                        elif hasattr(instance, 'clear'):
                            instance.clear()
                        cleaned_count += 1
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ¸…ç†EventBuså®ä¾‹å¤±è´¥: {e}")
            
            if cleaned_count > 0:
                logger.info(f"âœ… å·²æ¸…ç† {cleaned_count} ä¸ªEventBuså®ä¾‹")
        
        logger.info("ğŸ§¹ EventBuså†…å­˜æ¸…ç†å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ EventBusæ¸…ç†å¤±è´¥: {e}")

class NoteData(BaseModel):
    """ç¬”è®°æ•°æ®æ¨¡å‹"""
    note_id: str = Field(default="", description="ç¬”è®°ID")
    note_title: str = Field(description="ç¬”è®°æ ‡é¢˜")
    note_url: str = Field(description="ç¬”è®°URL")
    impression: int = Field(default=0, description="æ€»æ›å…‰é‡")
    click: int = Field(default=0, description="æ€»é˜…è¯»é‡")
    like: int = Field(default=0, description="æ€»ç‚¹èµé‡")
    collect: int = Field(default=0, description="æ€»æ”¶è—é‡")
    comment: int = Field(default=0, description="æ€»è¯„è®ºé‡")
    engage: int = Field(default=0, description="æ€»äº’åŠ¨é‡")

class NoteDataList(BaseModel):
    """ç¬”è®°æ•°æ®åˆ—è¡¨æ¨¡å‹"""
    note_data_list: List[NoteData] = Field(default_factory=list, description="ç¬”è®°æ•°æ®åˆ—è¡¨")
    total_count: int = Field(default=0, description="æ€»ç¬”è®°æ•°é‡")
    collection_method: str = Field(default="browser_automation", description="é‡‡é›†æ–¹æ³•")

class ToolExecutionResult(BaseModel):
    """å·¥å…·æ‰§è¡Œç»“æœæ¨¡å‹"""
    success: bool = Field(description="æ‰§è¡Œæ˜¯å¦æˆåŠŸ")
    data: NoteDataList = Field(description="é‡‡é›†åˆ°çš„ç¬”è®°æ•°æ®")
    message: str = Field(description="æ‰§è¡Œç»“æœæ¶ˆæ¯")
    debug_info: Dict[str, Any] = Field(default_factory=dict, description="è°ƒè¯•ä¿¡æ¯")

class ActionStateManager:
    """Actionä¹‹é—´çš„çŠ¶æ€ç®¡ç†å™¨ï¼Œè§£å†³å‚æ•°ä¼ é€’é—®é¢˜ - å•ä¾‹æ¨¡å¼"""
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not ActionStateManager._initialized:
            self.state = {}
            self.execution_log = []
            self.note_detail_parsed = {}
            ActionStateManager._initialized = True
    
    def set_data(self, key: str, value: Any, description: str = ""):
        """è®¾ç½®çŠ¶æ€æ•°æ®"""
        self.state[key] = value
        self.execution_log.append({
            "action": "set",
            "key": key,
            "description": description,
            "timestamp": asyncio.get_event_loop().time()
        })
        logger.info(f"ğŸ› DEBUG: è®¾ç½®çŠ¶æ€ {key} = '{value}', å®ä¾‹ID: {id(self)}, æè¿°: {description}")
    
    def get_data(self, key: str, default=None):
        """è·å–çŠ¶æ€æ•°æ®"""
        value = self.state.get(key, default)
        logger.info(f"ğŸ› DEBUG: è·å–çŠ¶æ€ {key} = '{value}', å®ä¾‹ID: {id(self)}, å½“å‰çŠ¶æ€keys: {list(self.state.keys())}")
        return value
    
    def set_note_detail_parsed(self, key: str, value: bool):
        """è®¾ç½®çŠ¶æ€æ•°æ®"""
        self.note_detail_parsed[key] = value
        logger.info(f"ğŸ—„ï¸ ç¬”è®°è¯¦æƒ…é¡µè§£æçŠ¶æ€è®¾ç½®: {key} = {type(value)} ({value})")
    
    def get_note_detail_parsed(self, key: str, default=False):
        """è·å–çŠ¶æ€æ•°æ®"""
        value = self.note_detail_parsed.get(key, default)
        logger.info(f"ğŸ” ç¬”è®°è¯¦æƒ…é¡µè§£æçŠ¶æ€è·å–: {key} = {type(value)}")
        return value

    def clear_data(self, key: str = None):
        """æ¸…é™¤çŠ¶æ€æ•°æ®"""
        if key:
            self.state.pop(key, None)
            logger.info(f"ğŸ—‘ï¸ æ¸…é™¤çŠ¶æ€: {key}")
        else:
            self.state.clear()
            logger.info("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰çŠ¶æ€")
    
    def get_execution_summary(self):
        """è·å–æ‰§è¡Œæ‘˜è¦"""
        return {
            "total_actions": len(self.execution_log),
            "current_state_keys": list(self.state.keys()),
            "execution_log": self.execution_log[-5:]  # æœ€è¿‘5æ¡è®°å½•
        }

# åˆ›å»ºå…¨å±€çŠ¶æ€ç®¡ç†å™¨ï¼ˆå‘åå…¼å®¹ï¼‰
action_state = ActionStateManager()

def ensure_auth_file_exists(auth_file_path: Path) -> bool:
    """
    ç¡®ä¿è®¤è¯æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
    
    Args:
        auth_file_path: è®¤è¯æ–‡ä»¶è·¯å¾„
    
    Returns:
        bool: æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    """
    try:
        if not auth_file_path.exists():
            logger.info(f"è®¤è¯æ–‡ä»¶ä¸å­˜åœ¨: {auth_file_path}")
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = auth_file_path.stat().st_size
        if file_size == 0:
            logger.warning(f"è®¤è¯æ–‡ä»¶ä¸ºç©º: {auth_file_path}")
            return False
        
        # å°è¯•è§£æJSON
        with open(auth_file_path, 'r', encoding='utf-8') as f:
            auth_data = json.load(f)
        
        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        if not isinstance(auth_data, dict):
            logger.warning(f"è®¤è¯æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä¸æ˜¯å­—å…¸ç±»å‹: {type(auth_data)}")
            return False
        
        # æ£€æŸ¥cookieså­—æ®µ
        cookies = auth_data.get('cookies', [])
        if not isinstance(cookies, list):
            logger.warning(f"cookieså­—æ®µæ ¼å¼é”™è¯¯: {type(cookies)}")
            return False
        
        logger.info(f"è®¤è¯æ–‡ä»¶éªŒè¯é€šè¿‡: {auth_file_path} (åŒ…å« {len(cookies)} ä¸ªcookies)")
        return True
        
    except json.JSONDecodeError as e:
        logger.error(f"è®¤è¯æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(f"éªŒè¯è®¤è¯æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def create_precision_controller() -> Controller:
    """åˆ›å»ºç²¾ç¡®æ§åˆ¶å™¨ï¼ŒåŒ…å«è‡ªå®šä¹‰action"""
    controller = Controller()
    logger.info("ğŸ¯ å¼€å§‹æ³¨å†Œç²¾ç¡®æ§åˆ¶å™¨çš„è‡ªå®šä¹‰action")
    
    @controller.action('navigate and login xiaohongshu ad platform', domains=['ad.xiaohongshu.com'])
    async def navigate_and_login_xiaohongshu_ad_platform(xhs_ad_email: str, xhs_ad_password: str, browser_session: BrowserSession) -> ActionResult:
        """å¯¼èˆªåˆ°å°çº¢ä¹¦å¹¿å‘Šå¹³å°å¹¶æ£€æµ‹ç™»å½•çŠ¶æ€ï¼Œå¿…è¦æ—¶è¿›è¡Œç™»å½•"""
        logger.info("ğŸ¯ å¼€å§‹å¯¼èˆªåˆ°å°çº¢ä¹¦å¹¿å‘Šå¹³å°å¹¶æ£€æµ‹ç™»å½•çŠ¶æ€")
        
        try:
            page = await browser_session.get_current_page()
            
            # æ­¥éª¤1: å¯¼èˆªåˆ°å°çº¢ä¹¦å¹¿å‘Šå¹³å°
            logger.info("ğŸ“ æ­£åœ¨å¯¼èˆªåˆ°å°çº¢ä¹¦å¹¿å‘Šå¹³å°...")
            await page.goto("https://ad.xiaohongshu.com/")
            await page.wait_for_load_state('networkidle')
            logger.info("âœ… æˆåŠŸå¯¼èˆªåˆ°å°çº¢ä¹¦å¹¿å‘Šå¹³å°")
            
            # æ­¥éª¤2: æ£€æµ‹ç™»å½•çŠ¶æ€
            logger.info("ğŸ” æ£€æµ‹å½“å‰ç™»å½•çŠ¶æ€...")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨"è´¦å·ç™»å½•"æŒ‰é’®ï¼Œå¦‚æœå­˜åœ¨è¯´æ˜æœªç™»å½•
            login_button_exists = await page.locator("div").filter(has_text=re.compile(r"^è´¦å·ç™»å½•$")).count() > 0
            
            if not login_button_exists:
                # å¦‚æœæ²¡æœ‰"è´¦å·ç™»å½•"æŒ‰é’®ï¼Œè¯´æ˜å·²ç»ç™»å½•
                logger.info("âœ… æ£€æµ‹åˆ°å·²ç™»å½•çŠ¶æ€ï¼ˆé€šè¿‡cookiesï¼‰ï¼Œè·³è¿‡ç™»å½•æ­¥éª¤")
                return ActionResult(extracted_content="Already logged in to XiaoHongShu Ad Platform via cookies")
            
            # æ­¥éª¤3: æ‰§è¡Œç™»å½•æµç¨‹
            logger.info("ğŸ” æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€ï¼Œå¼€å§‹æ‰§è¡Œç™»å½•æµç¨‹...")
            
            # ä½¿ç”¨åŸä»£ç ä¸­çš„ç²¾å‡†å®šä½å™¨æ‰§è¡Œç™»å½•
            await page.locator("div").filter(has_text=re.compile(r"^è´¦å·ç™»å½•$")).first.click()
            await page.get_by_role("textbox", name="é‚®ç®±").fill(xhs_ad_email)
            await page.get_by_role("textbox", name="å¯†ç ").fill(xhs_ad_password)
            await page.locator(".d-checkbox-indicator").first.click()
            await page.get_by_role("button", name="ç™» å½•").click()
            
            # ç­‰å¾…ç™»å½•å®Œæˆ
            await asyncio.sleep(3)
            
            # æ‰‹åŠ¨ä¿å­˜cookiesçŠ¶æ€
            try:
                auth_file = Path.cwd().absolute() / 'xiaohongshu_auth.json'
                logger.info(f"ğŸ’¾ ä¿å­˜è®¤è¯çŠ¶æ€åˆ°: {auth_file}")
                await browser_session.save_storage_state(str(auth_file))
                logger.info("âœ… è®¤è¯çŠ¶æ€ä¿å­˜æˆåŠŸ")
            except Exception as save_error:
                logger.warning(f"âš ï¸ ä¿å­˜è®¤è¯çŠ¶æ€å¤±è´¥: {save_error}")
            
            logger.info("âœ… æˆåŠŸå®Œæˆç™»å½•æ“ä½œ")
            return ActionResult(extracted_content="Successfully navigated and logged in to XiaoHongShu Ad Platform")
            
        except Exception as e:
            logger.error(f"âŒ å¯¼èˆªå’Œç™»å½•è¿‡ç¨‹å¤±è´¥: {str(e)}")
            return ActionResult(extracted_content=f"Failed to navigate and login: {str(e)}")

    @controller.action('navigate to content inspiration page', domains=['ad.xiaohongshu.com'])
    async def navigate_to_content_inspiration(browser_session: BrowserSession) -> ActionResult:
        """å¯¼èˆªåˆ°å†…å®¹çµæ„Ÿé¡µé¢"""
        logger.info("ğŸ¯ å¼€å§‹å¯¼èˆªåˆ°å†…å®¹çµæ„Ÿé¡µé¢")
        try:
            page = await browser_session.get_current_page()
            await page.goto("https://ad.xiaohongshu.com/microapp/traffic-guide/contentInspiration/")
            # ä¸‹åˆ’é¡µé¢åˆ°æŒ‡å®šæ¨¡å—
            await page.get_by_role("heading", name="æ ¸å¿ƒç¬”è®°").scroll_into_view_if_needed()
            await page.get_by_role("heading", name="æ ¸å¿ƒç¬”è®°").click()
            return ActionResult(extracted_content="Successfully navigated to content inspiration page")
        except Exception as e:
            logger.error(f"âŒ å¯¼èˆªåˆ°å†…å®¹çµæ„Ÿé¡µé¢å¤±è´¥: {str(e)}")
            return ActionResult(extracted_content=f"Failed to navigate to content inspiration page: {str(e)}")
    
    @controller.action('get_core_note_titles', domains=['ad.xiaohongshu.com'])
    async def get_core_note_titles(browser_session: BrowserSession) -> ActionResult:
        """è·å–æ ¸å¿ƒç¬”è®°çš„titleåˆ—è¡¨"""
        logger.info("ğŸ¯ å¼€å§‹è·å–æ ¸å¿ƒç¬”è®°çš„titleåˆ—è¡¨")
        try:
            # ç­‰å¾…æ ¸å¿ƒç¬”è®°åŒºåŸŸåŠ è½½
            page = await browser_session.get_current_page()
            logger.info(f"ğŸ” DEBUG: å½“å‰é¡µé¢URL: {page.url}")

            # ç­‰å¾…åˆ—è¡¨åŠ è½½
            await page.wait_for_selector('.grid-card')
            
            # è·å–æ‰€æœ‰é¡¹ç›®
            items = await page.locator('[class*="d-grid-item"][style*="grid-area: span 1 / span 4"]').all()
            
            titles = []
            for item in items:
                # åœ¨æ¯ä¸ª d-grid-item ä¸­æŸ¥æ‰¾ title
                title_text = await item.locator('.title').text_content()
                if title_text:
                    titles.append(title_text.strip())
                    print(f"è·å–åˆ°ç¬”è®°æ ‡é¢˜: {title_text}")
            
            logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(titles)} ä¸ªæ ‡é¢˜")
            
            # â­ å…³é”®æ”¹è¿›ï¼šå°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ç®¡ç†å™¨
            state_manager = ActionStateManager()
            current_page = state_manager.get_data('current_page', 1)
            state_manager.set_data("all_titles", titles, f"ç¬¬{current_page}é¡µçš„æ‰€æœ‰ç¬”è®°æ ‡é¢˜")
            state_manager.set_data("titles_count", len(titles), "å½“å‰é¡µæ ‡é¢˜æ•°é‡")
            
            logger.info(f"ğŸ” DEBUG: çŠ¶æ€ç®¡ç†å™¨å·²ä¿å­˜ {len(titles)} ä¸ªæ ‡é¢˜åˆ°ç¬¬{current_page}é¡µ")
            
            return ActionResult(extracted_content=json.dumps(titles, ensure_ascii=False))
        except Exception as e:
            logger.error(f"âŒ è·å–æ ¸å¿ƒç¬”è®°çš„titleåˆ—è¡¨å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"âŒ DEBUG: è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return ActionResult(extracted_content=f"Failed to get core note titles: {str(e)}")

    @controller.action('click next page', domains=['ad.xiaohongshu.com'])
    async def click_next_page(browser_session: BrowserSession) -> ActionResult:
        """ç‚¹å‡»ä¸‹ä¸€é¡µ"""
        logger.info("ğŸ¯ å¼€å§‹ç‚¹å‡»ä¸‹ä¸€é¡µ")
        try:
            page = await browser_session.get_current_page()
            logger.info(f"ğŸ” DEBUG: ç‚¹å‡»ä¸‹ä¸€é¡µå‰ï¼Œå½“å‰URL: {page.url}")
            
            # æ›´æ–°é¡µç çŠ¶æ€
            state_manager = ActionStateManager()
            current_page = state_manager.get_data("current_page", 1)
            max_pages = state_manager.get_data("max_pages", 3)  # è·å–æœ€å¤§é¡µæ•°é™åˆ¶
            next_page = current_page + 1
            
            # â­ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥é¡µé¢æ•°é‡é™åˆ¶
            if current_page >= max_pages:
                logger.info(f"ğŸ›‘ å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶: {current_page}/{max_pages}")
                return ActionResult(extracted_content=f"Reached maximum pages limit: {current_page}/{max_pages}")
            
            logger.info(f"ğŸ” DEBUG: å‡†å¤‡ä»ç¬¬{current_page}é¡µè·³è½¬åˆ°ç¬¬{next_page}é¡µ (æœ€å¤§é¡µæ•°: {max_pages})")
            
            # ä½¿ç”¨åŸæœ‰XPathä½œä¸ºå¤‡ç”¨
            try:
                logger.info("ğŸ” å°è¯•ç­–ç•¥1b: ä½¿ç”¨åŸæœ‰XPathå®šä½")
                xpath_button = page.locator('//*[@id="content-core-notes"]/div[3]/div[2]/div[2]/div[1]/div[9]')
                if await xpath_button.count() > 0:
                    await xpath_button.click()
                    logger.info("âœ… ç­–ç•¥1æˆåŠŸ: XPathç‚¹å‡»æˆåŠŸ")
                    
                    # æ›´æ–°é¡µç çŠ¶æ€
                    state_manager.set_data("current_page", next_page, f"å·²è·³è½¬åˆ°ç¬¬{next_page}é¡µ")
                    logger.info(f"ğŸ” DEBUG: é¡µç çŠ¶æ€å·²æ›´æ–°ä¸ºç¬¬{next_page}é¡µ")
                    
                    return ActionResult(extracted_content="Successfully clicked next page using XPath")
            except Exception as e:
                logger.warning(f"âš ï¸ ç­–ç•¥1bå¤±è´¥: {e}")
            
            # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥
            logger.error("âŒ æ‰€æœ‰ä¸‹ä¸€é¡µç‚¹å‡»ç­–ç•¥éƒ½å¤±è´¥")
            return ActionResult(extracted_content="Failed to click next page: All strategies failed")
            
        except Exception as e:
            logger.error(f"âŒ ç‚¹å‡»ä¸‹ä¸€é¡µå¤±è´¥: {str(e)}")
            return ActionResult(extracted_content=f"Failed to click next page: {str(e)}")

    @controller.action('extract_related_titles', domains=['ad.xiaohongshu.com'])
    async def extract_related_titles() -> ActionResult:
        """æå–ç›¸å…³æ ‡é¢˜ - åŸºäºè¯­ä¹‰å’Œè¡Œä¸šç›¸å…³æ€§è€Œéå­—é¢é‡åŒ¹é…"""
        logger.info(f"ğŸ¯ å¼€å§‹æå–ç›¸å…³æ ‡é¢˜")
        
        # â­ å•ä¾‹æ¨¡å¼ï¼šç›´æ¥è·å–çŠ¶æ€ç®¡ç†å™¨å®ä¾‹
        state_manager = ActionStateManager()
        logger.info(f"ğŸ› DEBUG: extract_related_titlesä¸­è·å–çŠ¶æ€ç®¡ç†å™¨")
        logger.info(f"ğŸ› DEBUG: extract_related_titlesä¸­ActionStateManagerå®ä¾‹ID: {id(state_manager)}")
        logger.info(f"ğŸ› DEBUG: extract_related_titlesä¸­å½“å‰å®Œæ•´çŠ¶æ€: {dict(state_manager.state)}")
        
        # ä»çŠ¶æ€ç®¡ç†å™¨è·å–æ ‡é¢˜åˆ—è¡¨
        title_list = state_manager.get_data("all_titles", [])
        logger.info(f"ğŸ” DEBUG: ä»çŠ¶æ€ç®¡ç†å™¨è·å–æ ‡é¢˜åˆ—è¡¨ï¼Œç±»å‹: {type(title_list)}, é•¿åº¦: {len(title_list) if title_list else 'None'}")
        
        if not title_list:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ ‡é¢˜åˆ—è¡¨ï¼Œå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œ get_core_note_titles")
            return ActionResult(extracted_content='{"related_titles": [], "error": "æœªæ‰¾åˆ°æ ‡é¢˜æ•°æ®"}')
        
        promotion_target = state_manager.get_data("promotion_target", "")
        logger.info(f"ğŸ” DEBUG: ä»çŠ¶æ€ç®¡ç†å™¨è·å–æ¨å¹¿æ ‡çš„: '{promotion_target}' (ç±»å‹: {type(promotion_target)})")
        logger.info(f"ğŸ› DEBUG: æ¨å¹¿æ ‡çš„è·å–åçš„å®Œæ•´çŠ¶æ€æ£€æŸ¥: {dict(state_manager.state)}")
        
        if not promotion_target:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¨å¹¿æ ‡çš„ï¼Œå¯èƒ½éœ€è¦å…ˆæ‰§è¡Œ set_promotion_target")
            return ActionResult(extracted_content='{"related_titles": [], "error": "æœªæ‰¾åˆ°æ¨å¹¿æ ‡çš„"}')
        
        logger.info(f"ğŸ¯ æå–ç›¸å…³æ ‡é¢˜, æ¨å¹¿æ ‡çš„: {promotion_target}, æ ‡é¢˜åˆ—è¡¨é•¿åº¦: {len(title_list)}")
        logger.info(f"ğŸ” DEBUG: æ ‡é¢˜åˆ—è¡¨å†…å®¹: {title_list[:5] if len(title_list) > 5 else title_list}")  # åªæ˜¾ç¤ºå‰5ä¸ª
      
        try:
            extraction_llm = ChatOpenAI(
                base_url='https://openrouter.ai/api/v1',
                model='qwen/qwen3-235b-a22b-2507',
                api_key=os.environ['OPENROUTER_API_KEY'],
                temperature=0.1
            )

            logger.info("âœ… DEBUG: LLMå®ä¾‹åˆ›å»ºæˆåŠŸ")
        except Exception as llm_error:
            logger.error(f"âŒ DEBUG: LLMå®ä¾‹åˆ›å»ºå¤±è´¥: {llm_error}")
            return ActionResult(extracted_content='{"related_titles": [], "error": "LLMå®ä¾‹åˆ›å»ºå¤±è´¥"}')

        # æ”¹è¿›çš„ prompt - å¼ºè°ƒè¯­ä¹‰å’Œè¡Œä¸šç›¸å…³æ€§
        prompt = '''æ‚¨æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå¸ˆã€‚è¯·ä»ç»™å®šçš„æ ‡é¢˜åˆ—è¡¨ä¸­æ‰¾å‡ºä¸æ¨å¹¿ç›®æ ‡åœ¨è¯­ä¹‰ã€è¡Œä¸šæˆ–ç›®æ ‡ç”¨æˆ·ç¾¤ä½“ä¸Šç›¸å…³çš„æ ‡é¢˜ã€‚

æ¨å¹¿ç›®æ ‡: {promotion_target}

åˆ¤æ–­ç›¸å…³æ€§çš„æ ‡å‡†ï¼š
1. è¡Œä¸šç›¸å…³æ€§ï¼šå±äºåŒä¸€ä¸ªè¡Œä¸šé¢†åŸŸï¼ˆå¦‚æ•™è‚²åŸ¹è®­ã€æ±‚èŒå°±ä¸šã€è€ƒè¯•å¤‡è€ƒç­‰ï¼‰
2. ç›®æ ‡ç”¨æˆ·ç¾¤ä½“ç›¸å…³ï¼šé¢å‘ç›¸ä¼¼çš„ç”¨æˆ·ç¾¤ä½“ï¼ˆå¦‚æ±‚èŒè€…ã€å¤‡è€ƒäººå‘˜ã€èŒåœºæ–°äººç­‰ï¼‰
3. åŠŸèƒ½ç›¸å…³æ€§ï¼šæä¾›ç±»ä¼¼çš„æœåŠ¡æˆ–è§£å†³ç›¸ä¼¼çš„é—®é¢˜ï¼ˆå¦‚æŠ€èƒ½æå‡ã€èŒä¸šè§„åˆ’ã€è€ƒè¯•æŒ‡å¯¼ç­‰ï¼‰

ä¾‹å¦‚ï¼š
- "å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼" ä¸ "å…¬åŠ¡å‘˜è€ƒè¯•å¤‡è€ƒ"ã€"ç®€å†ä¼˜åŒ–æŒ‡å¯¼"ã€"é¢è¯•æŠ€å·§åˆ†äº«"ã€"èŒåœºæŠ€èƒ½æå‡" ç­‰éƒ½æ˜¯ç›¸å…³çš„
- "è€ƒå…¬ä¸Šå²¸ç»éªŒ"ã€"äº‹ä¸šç¼–åˆ¶å¤‡è€ƒ"ã€"Dream Offerè·å–" ç­‰ä¹Ÿéƒ½å±äºæ±‚èŒå°±ä¸šé¢†åŸŸ

æ ‡é¢˜åˆ—è¡¨: {title_list}

è¯·è¿”å›ç›¸å…³çš„æ ‡é¢˜åˆ—è¡¨ï¼Œæ ¼å¼ä¸ºç®€å•çš„JSONæ•°ç»„ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šï¼š
["ç›¸å…³æ ‡é¢˜1", "ç›¸å…³æ ‡é¢˜2", ...]

å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ ‡é¢˜ï¼Œè¿”å›ç©ºæ•°ç»„ï¼š[]'''

        template = PromptTemplate(input_variables=['title_list', 'promotion_target'], template=prompt)

        try:
                logger.info("ğŸ” DEBUG: å¼€å§‹è°ƒç”¨LLMè¿›è¡Œæ ‡é¢˜æå–...")
                output = await extraction_llm.ainvoke(template.format(title_list=title_list, promotion_target=promotion_target))
                logger.info(f"ğŸ” DEBUG: LLMè°ƒç”¨æˆåŠŸï¼Œè¾“å‡ºç±»å‹: {type(output)}")
                
                # å°è¯•è§£æä¸ºJSON
                import json
                try:
                    # æå–JSONå†…å®¹
                    response_content = output.content.strip()
                    logger.info(f"ğŸ” DEBUG: LLMåŸå§‹å“åº”å†…å®¹: {response_content[:200]}...")  # åªæ˜¾ç¤ºå‰200å­—ç¬¦
                    
                    # å¦‚æœåŒ…å«ä»£ç å—ï¼Œæå–JSONéƒ¨åˆ†
                    if '```' in response_content:
                        start_idx = response_content.find('[')
                        end_idx = response_content.rfind(']') + 1
                        if start_idx != -1 and end_idx != 0:
                            response_content = response_content[start_idx:end_idx]
                            logger.info(f"ğŸ” DEBUG: æå–JSONéƒ¨åˆ†: {response_content}")
                    
                    related_titles = json.loads(response_content)
                    logger.info(f"ğŸ” DEBUG: JSONè§£ææˆåŠŸï¼Œç›¸å…³æ ‡é¢˜ç±»å‹: {type(related_titles)}, é•¿åº¦: {len(related_titles)}")
                    
                    logger.info(f"âœ… æˆåŠŸæå–åˆ° {len(related_titles)} ä¸ªç›¸å…³æ ‡é¢˜")
                    logger.info(f"ğŸ“‹ ç›¸å…³æ ‡é¢˜: {related_titles}")
                    
                    # â­ å…³é”®æ”¹è¿›ï¼šå°†ç›¸å…³æ ‡é¢˜ä¿å­˜åˆ°çŠ¶æ€ç®¡ç†å™¨
                    state_manager.set_data("related_titles", related_titles, f"ä¸{promotion_target}ç›¸å…³çš„æ ‡é¢˜")
                    state_manager.set_data("related_count", len(related_titles), "ç›¸å…³æ ‡é¢˜æ•°é‡")
                    state_manager.set_data("processed_note_index", 0, "å½“å‰å¤„ç†çš„ç¬”è®°ç´¢å¼•")
                    
                    logger.info(f"ğŸ” DEBUG: çŠ¶æ€ç®¡ç†å™¨å·²ä¿å­˜ç›¸å…³æ ‡é¢˜æ•°æ®")
                    
                    # è¿”å›JSONæ ¼å¼çš„ç»“æœ
                    result = {
                        "related_titles": related_titles,
                        "total_count": len(related_titles),
                        "original_count": len(title_list)
                    }
                    
                    return ActionResult(extracted_content=json.dumps(result, ensure_ascii=False), include_in_memory=True)
                    
                except json.JSONDecodeError as je:
                    logger.warning(f"âš ï¸ DEBUG: JSONè§£æå¤±è´¥: {je}")
                    logger.warning(f"âš ï¸ DEBUG: åŸå§‹å†…å®¹: {response_content}")
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–
                    response_content = output.content.strip()
                    return ActionResult(extracted_content=response_content, include_in_memory=True)
                    
        except Exception as e:
            logger.error(f'âŒ æå–ç›¸å…³æ ‡é¢˜æ—¶å‡ºé”™: {e}')
            import traceback
            logger.error(f"âŒ DEBUG: è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return ActionResult(extracted_content='{"related_titles": [], "error": "æå–å¤±è´¥"}', include_in_memory=False)

    @controller.action('process_all_related_notes', domains=['ad.xiaohongshu.com'])
    async def process_all_related_notes(browser_session: BrowserSession) -> ActionResult:
        """å¾ªç¯å¤„ç†æ‰€æœ‰ç›¸å…³æ ‡é¢˜ï¼šæ‰“å¼€è¯¦æƒ…é¡µ -> æå–æ•°æ® -> å…³é—­è¯¦æƒ…é¡µ"""
        logger.info("ğŸ”„ å¼€å§‹å¾ªç¯å¤„ç†æ‰€æœ‰ç›¸å…³æ ‡é¢˜çš„ç¬”è®°è¯¦æƒ…")
        
        try:
            # ä»çŠ¶æ€ç®¡ç†å™¨è·å–ç›¸å…³æ ‡é¢˜åˆ—è¡¨
            state_manager = ActionStateManager()
            related_titles = state_manager.get_data("related_titles", [])
            logger.info(f"ğŸ” DEBUG: è·å–ç›¸å…³æ ‡é¢˜åˆ—è¡¨ï¼Œç±»å‹: {type(related_titles)}, å†…å®¹: {related_titles}")
            
            if not related_titles:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ ‡é¢˜åˆ—è¡¨")
                return ActionResult(extracted_content='{"success": false, "error": "æœªæ‰¾åˆ°ç›¸å…³æ ‡é¢˜åˆ—è¡¨ï¼Œè¯·å…ˆæ‰§è¡Œextract_related_titles"}')
            
            # ç¡®ä¿related_titlesæ˜¯åˆ—è¡¨ç±»å‹
            if not isinstance(related_titles, list):
                logger.error(f"âŒ DEBUG: related_titlesä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(related_titles)}")
                return ActionResult(extracted_content='{"success": false, "error": "ç›¸å…³æ ‡é¢˜æ•°æ®æ ¼å¼é”™è¯¯"}')
            
            logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç† {len(related_titles)} ä¸ªç›¸å…³æ ‡é¢˜")
            
            page = await browser_session.get_current_page()
            processed_count = 0
            failed_count = 0
            processing_results = []
            
            for i, note_title in enumerate(related_titles):
                try:
                    logger.info(f"ğŸ”„ å¤„ç†ç¬¬ {i+1}/{len(related_titles)} ä¸ªæ ‡é¢˜: {note_title}")
                    logger.info(f"ğŸ” DEBUG: å½“å‰æ ‡é¢˜ç±»å‹: {type(note_title)}, å†…å®¹: {note_title}")
                    
                    # ç¡®ä¿note_titleæ˜¯å­—ç¬¦ä¸²
                    if not isinstance(note_title, str):
                        logger.error(f"âŒ DEBUG: æ ‡é¢˜ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(note_title)}")
                        processing_results.append({
                            "title": str(note_title),
                            "status": "failed",
                            "error": "æ ‡é¢˜ç±»å‹é”™è¯¯"
                        })
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»è§£æè¿‡è¯¥ç¬”è®°
                    is_parsed = state_manager.get_note_detail_parsed(note_title, False)
                    if is_parsed:
                        logger.info(f"â­ï¸ è·³è¿‡å·²è§£æçš„ç¬”è®°: {note_title}")
                        processing_results.append({
                            "title": note_title,
                            "status": "skipped",
                            "reason": "already_parsed"
                        })
                        continue
                    
                    # æ­¥éª¤a: æ‰“å¼€ç¬”è®°è¯¦æƒ…é¡µ
                    logger.info(f"ğŸ“– æ‰“å¼€ç¬”è®°è¯¦æƒ…é¡µ: {note_title}")
                    await page.get_by_role("heading", name="æ ¸å¿ƒç¬”è®°").click()
                    await asyncio.sleep(0.5)  # ç­‰å¾…é¡µé¢ç¨³å®š
                    
                    # å°è¯•ç‚¹å‡»æ ‡é¢˜
                    title_locator = page.locator("#content-core-notes").get_by_text(note_title)
                    await title_locator.click()
                    await asyncio.sleep(2)  # ç­‰å¾…å¼¹çª—åŠ è½½
                    
                    # æ­¥éª¤b: æå–ç¬”è®°æ•°æ®
                    logger.info(f"ğŸ“Š æå–ç¬”è®°æ•°æ®: {note_title}")
                    
                    # æ£€æŸ¥å¼¹çª—æ˜¯å¦æˆåŠŸæ‰“å¼€
                    modal_title = await page.locator(".interaction-title").text_content()
                    if not modal_title or modal_title.strip() != note_title:
                        logger.warning(f"âš ï¸ å¼¹çª—æ ‡é¢˜ä¸åŒ¹é…: æœŸæœ›'{note_title}', å®é™…'{modal_title}'")
                    
                    # å¤åˆ¶ç¬”è®°é“¾æ¥
                    await page.get_by_text("å¤åˆ¶å°çº¢ä¹¦ç¬”è®°é“¾æ¥").click()
                    await asyncio.sleep(0.5)
                    note_url = pyperclip.paste()
                    logger.info(f"ğŸ“ è·å–ç¬”è®°é“¾æ¥: {note_url}")
                    
                    # æå–æ•°æ®ç»Ÿè®¡
                    items = await page.locator('.interaction-card-item').all()
                    stats = {}
                    
                    for item in items:
                        label_text = await item.locator('.interaction-card-item-label text').text_content()
                        value_text = await item.locator('.interaction-card-item-value').text_content()
                        
                        # æ ¼å¼åŒ–æ•°æ® - ä½¿ç”¨ä¸extract_note_data_from_modalç›¸åŒçš„é€»è¾‘
                        if value_text:
                            value_text = value_text.strip()
                            try:
                                if "ä¸‡" in value_text:
                                    # å¤„ç† "36.3ä¸‡" æˆ– "3ä¸‡" æ ¼å¼
                                    numeric_part = value_text.replace("ä¸‡", "").strip()
                                    if numeric_part:
                                        value = int(float(numeric_part) * 10000)
                                    else:
                                        value = 0
                                elif "åƒ" in value_text:
                                    # å¤„ç† "3.5åƒ" æ ¼å¼
                                    numeric_part = value_text.replace("åƒ", "").strip()
                                    if numeric_part:
                                        value = int(float(numeric_part) * 1000)
                                    else:
                                        value = 0
                                elif value_text.replace(".", "").replace(",", "").isdigit():
                                    # å¤„ç†çº¯æ•°å­—æ ¼å¼ "1000" æˆ– "1,000"
                                    clean_text = value_text.replace(",", "")
                                    if "." in clean_text:
                                        value = int(float(clean_text))
                                    else:
                                        value = int(clean_text)
                                else:
                                    # å…¶ä»–æ ¼å¼è®¾ä¸º0
                                    value = 0
                            except (ValueError, TypeError) as e:
                                logger.warning(f"âš ï¸ æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥: '{value_text}' -> {e}")
                                value = 0
                        else:
                            value = 0
                        
                        label = label_text.strip() if label_text else ''
                        match label:
                            case "æ€»æ›å…‰é‡":
                                stats["impression"] = value
                            case "æ€»é˜…è¯»é‡":
                                stats["click"] = value
                            case "æ€»ç‚¹èµé‡":
                                stats["like"] = value
                            case "æ€»æ”¶è—é‡":
                                stats["collect"] = value
                            case "æ€»è¯„è®ºé‡":
                                stats["comment"] = value
                            case "æ€»äº’åŠ¨é‡":
                                stats["engage"] = value
                        
                        logger.info(f"ğŸ“Š æ•°æ®è§£æ: {label} = '{value_text}' -> {value}")
                    
                    # æ„é€ ç¬”è®°æ•°æ®
                    note_data = {
                        "note_title": note_title,
                        "note_url": note_url or f"https://xiaohongshu.com/note/unknown_{i}",
                        "impression": stats.get("impression", 0),
                        "click": stats.get("click", 0),
                        "like": stats.get("like", 0),
                        "collect": stats.get("collect", 0),
                        "comment": stats.get("comment", 0),
                        "engage": stats.get("engage", 0)
                    }
                    
                    # ä¿å­˜åˆ°çŠ¶æ€ç®¡ç†å™¨
                    collected_notes = state_manager.get_data("collected_notes", [])
                    collected_notes.append(note_data)
                    state_manager.set_data("collected_notes", collected_notes, f"å·²é‡‡é›†{len(collected_notes)}æ¡ç¬”è®°æ•°æ®")
                    state_manager.set_note_detail_parsed(note_title, True)
                    
                    # æ­¥éª¤c: å…³é—­ç¬”è®°è¯¦æƒ…é¡µ
                    logger.info(f"âŒ å…³é—­ç¬”è®°è¯¦æƒ…é¡µ: {note_title}")
                    close_button = page.locator("div").filter(has_text=re.compile(r"^ç¬”è®°è¯¦æƒ…$")).get_by_role("img")
                    await close_button.click()
                    await asyncio.sleep(1)  # ç­‰å¾…å¼¹çª—å…³é—­
                    
                    processed_count += 1
                    processing_results.append({
                        "title": note_title,
                        "status": "success",
                        "data": note_data
                    })
                    
                    logger.info(f"âœ… æˆåŠŸå¤„ç†: {note_title} ({i+1}/{len(related_titles)})")
                    
                except Exception as e:
                    failed_count += 1
                    error_msg = str(e)
                    logger.error(f"âŒ å¤„ç†å¤±è´¥: {note_title} - {error_msg}")
                    
                    # å°è¯•å…³é—­æ‰“å¼€çš„å¼¹çª—
                    try:
                        close_button = page.locator("div").filter(has_text=re.compile(r"^ç¬”è®°è¯¦æƒ…$")).get_by_role("img")
                        if await close_button.is_visible():
                            await close_button.click()
                            await asyncio.sleep(0.5)
                    except:
                        pass
                    
                    processing_results.append({
                        "title": note_title,
                        "status": "failed",
                        "error": error_msg
                    })
                    
                    # å¦‚æœè¿ç»­å¤±è´¥å¤ªå¤šï¼Œæå‰ç»“æŸ
                    if failed_count >= 3:
                        logger.warning("âš ï¸ è¿ç»­å¤±è´¥è¿‡å¤šï¼Œæå‰ç»“æŸå¤„ç†")
                        break
            
            # æ±‡æ€»ç»“æœ
            total_collected = len(state_manager.get_data("collected_notes", []))
            result = {
                "success": True,
                "summary": {
                    "total_related_titles": len(related_titles),
                    "processed_count": processed_count,
                    "failed_count": failed_count,
                    "skipped_count": len([r for r in processing_results if r["status"] == "skipped"]),
                    "total_collected_notes": total_collected
                },
                "processing_results": processing_results,
                "message": f"å¾ªç¯å¤„ç†å®Œæˆ: æˆåŠŸ{processed_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª, æ€»é‡‡é›†{total_collected}æ¡ç¬”è®°"
            }
            
            logger.info(f"ğŸ‰ å¾ªç¯å¤„ç†å®Œæˆ: {result['summary']}")
            return ActionResult(extracted_content=json.dumps(result, ensure_ascii=False))
            
        except Exception as e:
            logger.error(f"âŒ å¾ªç¯å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return ActionResult(extracted_content=f"å¾ªç¯å¤„ç†å¤±è´¥: {str(e)}")

    @controller.action('get_collection_status')
    async def get_collection_status() -> ActionResult:
        """è·å–å½“å‰é‡‡é›†è¿›åº¦å’ŒçŠ¶æ€"""
        logger.info("ğŸ¯ è·å–å½“å‰é‡‡é›†è¿›åº¦")
        
        state_manager = ActionStateManager()
        status = {
            "execution_summary": state_manager.get_execution_summary(),
            "data_summary": {
                "all_titles_count": len(state_manager.get_data("all_titles", [])),
                "related_titles_count": state_manager.get_data("related_count", 0),
                "processed_index": state_manager.get_data("processed_note_index", 0),
                "collected_notes_count": len(state_manager.get_data("collected_notes", [])),
                "current_page": state_manager.get_data("current_page", 1),
                "parsed_notes_count": len(state_manager.note_detail_parsed)
            },
            "current_state": dict(state_manager.state)
        }
        
        logger.info(f"ğŸ“Š å½“å‰è¿›åº¦: {status['data_summary']}")
        return ActionResult(extracted_content=json.dumps(status, ensure_ascii=False))

    logger.info(f"âœ… æ§åˆ¶å™¨åˆ›å»ºå®Œæˆ")
    return controller

def create_hot_note_finder_agent(promotion_target: str = 'å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº', max_pages: int = 3) -> Agent:
    """åˆ›å»ºä½¿ç”¨Controller Actionçš„ä»£ç†"""
    
    # é…ç½®LLM
    llm = ChatOpenAI(
        base_url='https://openrouter.ai/api/v1',
        model='google/gemini-2.5-flash-lite-preview-06-17',
        api_key=os.environ['OPENROUTER_API_KEY'],
        temperature=0.1
    )

    planner_llm = ChatOpenAI(
        base_url='https://openrouter.ai/api/v1',
        model='google/gemini-2.5-flash-lite-preview-06-17',
        api_key=os.environ['OPENROUTER_API_KEY'],
        temperature=0.1
    )

    # ä½¿ç”¨ç»å¯¹è·¯å¾„é…ç½®è®¤è¯æ–‡ä»¶
    auth_file = Path.cwd().absolute() / 'xiaohongshu_auth.json'
    browser_data_dir = Path.cwd().absolute() / 'browser_data' / 'xiaohongshu'
    
    # ç¡®ä¿æµè§ˆå™¨æ•°æ®ç›®å½•å­˜åœ¨
    browser_data_dir.mkdir(parents=True, exist_ok=True)
    
    # éªŒè¯è®¤è¯æ–‡ä»¶
    auth_file_valid = ensure_auth_file_exists(auth_file)
    logger.info(f"ğŸ” è®¤è¯æ–‡ä»¶çŠ¶æ€: {auth_file} -> {'æœ‰æ•ˆ' if auth_file_valid else 'æ— æ•ˆæˆ–ä¸å­˜åœ¨'}")
    
    # åˆ›å»ºæµè§ˆå™¨ä¼šè¯ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
    browser_profile = BrowserProfile(
        executable_path=Path('/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'),
        user_data_dir=str(browser_data_dir),  # ä½¿ç”¨æŒä¹…åŒ–æ•°æ®ç›®å½•
    )

    browser_session = BrowserSession(
        allowed_domains=['https://*.xiaohongshu.com'],
        storage_state=str(auth_file) if auth_file_valid else None,  # ä½¿ç”¨ç»å¯¹è·¯å¾„
        save_storage_state=str(auth_file),  # è®¾ç½®ä¿å­˜è·¯å¾„
        browser_profile=browser_profile,
        headless=False,
    )

     # æ•æ„Ÿæ•°æ®é…ç½®
    sensitive_data = {
        'https://ad.xiaohongshu.com/': {
            'xhs_ad_email': '1696249664@qq.com',
            'xhs_ad_password': 'Abcd1234',
        }
    }
    
    # åˆ›å»ºç²¾ç¡®æ§åˆ¶å™¨
    controller = create_precision_controller()
  # ä½¿ç”¨Controller Actionçš„ä»»åŠ¡æè¿°ï¼Œé›†æˆç²¾ç¡®é€‰æ‹©å™¨

    task = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°çº¢ä¹¦æ•°æ®é‡‡é›†åŠ©æ‰‹ï¼Œå…·å¤‡ç²¾ç¡®çš„å…ƒç´ å®šä½èƒ½åŠ›ã€‚ä½ çš„ä»»åŠ¡æ˜¯é‡‡é›†ä¸"{promotion_target}"ç›¸å…³çš„ä¼˜è´¨çƒ­é—¨ç¬”è®°æ•°æ®ã€‚

**é‡è¦æç¤ºï¼šç›¸å…³æ€§åˆ¤æ–­æ ‡å‡†**
ä¸è¦åªè¿›è¡Œå­—é¢é‡åŒ¹é…ï¼è¦æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­ç›¸å…³æ€§ï¼š
1. è¡Œä¸šç›¸å…³æ€§ï¼šå±äºåŒä¸€ä¸ªè¡Œä¸šé¢†åŸŸï¼ˆæ•™è‚²åŸ¹è®­ã€æ±‚èŒå°±ä¸šã€è€ƒè¯•å¤‡è€ƒç­‰ï¼‰
2. ç›®æ ‡ç”¨æˆ·ç¾¤ä½“ï¼šé¢å‘ç›¸ä¼¼çš„ç”¨æˆ·ç¾¤ä½“ï¼ˆæ±‚èŒè€…ã€å¤‡è€ƒäººå‘˜ã€èŒåœºæ–°äººç­‰ï¼‰  
3. åŠŸèƒ½ç›¸å…³æ€§ï¼šæä¾›ç±»ä¼¼çš„æœåŠ¡æˆ–è§£å†³ç›¸ä¼¼çš„é—®é¢˜ï¼ˆæŠ€èƒ½æå‡ã€èŒä¸šè§„åˆ’ã€è€ƒè¯•æŒ‡å¯¼ç­‰ï¼‰

**ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼š**
é‡‡é›†ä¸"{promotion_target}"ç›¸å…³çš„ä¼˜è´¨çƒ­é—¨ç¬”è®°æ•°æ®ã€‚

**ğŸ“‹ ç›¸å…³æ€§åˆ¤æ–­æ ‡å‡†ï¼š**
ä¸è¦åªè¿›è¡Œå­—é¢é‡åŒ¹é…ï¼è¦æ ¹æ®è¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­ï¼š
- è¡Œä¸šç›¸å…³ï¼šæ•™è‚²åŸ¹è®­ã€æ±‚èŒå°±ä¸šã€è€ƒè¯•å¤‡è€ƒç­‰
- ç”¨æˆ·ç¾¤ä½“ï¼šæ±‚èŒè€…ã€å¤‡è€ƒäººå‘˜ã€èŒåœºæ–°äººç­‰  
- åŠŸèƒ½ç›¸å…³ï¼šæŠ€èƒ½æå‡ã€èŒä¸šè§„åˆ’ã€è€ƒè¯•æŒ‡å¯¼ç­‰

**ğŸ” æ‰§è¡Œæ­¥éª¤ï¼š**
1. Go to https://ad.xiaohongshu.com/
2. å¯¼èˆªåˆ°: æ•°æ® -> ç¬”è®° -> å†…å®¹çµæ„Ÿé¡µé¢, ä½¿ç”¨ navigate_to_content_inspiration tool
3. è·å–å½“å‰é¡µé¢æ ¸å¿ƒç¬”è®°çš„æ‰€æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨ get_core_note_titles tool
4. ä»å½“å‰é¡µé¢æ‰€æœ‰æ ¸å¿ƒç¬”è®°çš„æ ‡é¢˜ä¸­æå–æœ‰ç›¸å…³æ€§çš„æ ‡é¢˜ï¼Œä½¿ç”¨ extract_related_titles tool
5. ä½¿ç”¨ process_all_related_notes tool æ‰¹é‡å¤„ç†æ‰€æœ‰ç›¸å…³æ ‡é¢˜çš„ç¬”è®°è¯¦æƒ…ï¼Œæ¯ä¸ªç¬”è®°æ‰§è¡Œï¼šæ‰“å¼€è¯¦æƒ…é¡µ -> æå–æ•°æ® -> å…³é—­è¯¦æƒ…é¡µçš„æ“ä½œ
6. ä½¿ç”¨ get_collection_status tool æŸ¥çœ‹å½“å‰é‡‡é›†è¿›åº¦å’ŒçŠ¶æ€
7. ç‚¹å‡»ä¸‹ä¸€é¡µï¼Œä½¿ç”¨ click_next_page toolï¼Œé‡å¤æ­¥éª¤3-6ï¼Œæœ€å¤šå¤„ç†{max_pages}é¡µ
8. **é‡è¦**ï¼šå¦‚æœ click_next_page è¿”å› "Reached maximum pages limit"ï¼Œç«‹å³åœæ­¢å¤„ç†å¹¶ä½¿ç”¨ get_collection_status è·å–æœ€ç»ˆç»“æœ
9. æœ€ç»ˆä½¿ç”¨ get_collection_status tool è·å–å®Œæ•´çš„é‡‡é›†ç»“æœ

**âš ï¸ é‡è¦çº¦æŸï¼š**
- ä¸¥æ ¼éµå®ˆ {max_pages} é¡µçš„å¤„ç†é™åˆ¶ï¼Œä¸å¾—è¶…è¿‡æ­¤æ•°é‡
- å¦‚æœ click_next_page æç¤ºè¾¾åˆ°é¡µé¢é™åˆ¶ï¼Œå¿…é¡»ç«‹å³åœæ­¢å¹¶è¾“å‡ºç»“æœ
- å¦‚æœæŸä¸ªactionè¿ç»­å¤±è´¥ï¼Œè¯·ç«‹å³ä½¿ç”¨ get_collection_status è·å–å·²é‡‡é›†çš„æ•°æ®å¹¶è¾“å‡ºç»“æœ
- ä¸è¦æ— é™é‡è¯•å¤±è´¥çš„æ“ä½œï¼Œä¼˜å…ˆä¿è¯å·²é‡‡é›†æ•°æ®çš„å®Œæ•´æ€§
- å¦‚æœå‡ºç°æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç«‹å³ä½¿ç”¨ get_collection_status è¾“å‡ºå½“å‰å·²é‡‡é›†çš„æ•°æ®

**æœ€ç»ˆè¾“å‡ºæ ¼å¼ï¼š**
è¯·ä»¥ç»“æ„åŒ–çš„JSONæ ¼å¼è¾“å‡ºç»“æœ:

{{
  "note_data_list": [
    {{
      "note_title": ç¬”è®°æ ‡é¢˜,
      "note_url": å®Œæ•´URL, 
      "impression": æ›å…‰é‡æ•°å­—,
      "click": é˜…è¯»é‡æ•°å­—,
      "like": ç‚¹èµé‡æ•°å­—,
      "collect": æ”¶è—é‡æ•°å­—,
      "comment": è¯„è®ºé‡æ•°å­—,
      "engage": äº’åŠ¨é‡æ•°å­—
    }}
  ]
}}
"""
    
    # å®˜æ–¹è°ƒè¯•åŠŸèƒ½
    debug_dir = Path("output/debug")
    debug_dir.mkdir(parents=True, exist_ok=True)
    
    # â­ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ¨å¹¿æ ‡çš„è¢«è®¾ç½®åˆ°çŠ¶æ€ç®¡ç†å™¨
    logger.info(f"ğŸ› DEBUG: åœ¨create_hot_note_finder_agentä¸­å‡†å¤‡è®¾ç½®æ¨å¹¿æ ‡çš„: '{promotion_target}'")
    logger.info(f"ğŸ› DEBUG: create_hot_note_finder_agentä¸­action_stateå®ä¾‹ID: {id(action_state)}")
    action_state.set_data("promotion_target", promotion_target, f"æ¨å¹¿æ ‡çš„: {promotion_target}")
    logger.info(f"ğŸ¯ æ¨å¹¿æ ‡çš„å·²è®¾ç½®åˆ°çŠ¶æ€ç®¡ç†å™¨: {promotion_target}")
    logger.info(f"ğŸ› DEBUG: è®¾ç½®åçš„å®Œæ•´çŠ¶æ€: {dict(action_state.state)}")
    
    # åˆ›å»ºä»£ç†
    agent = Agent(
        task=task,
        llm=llm,
        planner_llm=planner_llm,
        use_vision=True,  # ç»“åˆè§†è§‰è¯†åˆ«å’Œç²¾ç¡®æ§åˆ¶
        sensitive_data=sensitive_data,
        controller=controller,
        browser_session=browser_session,
        # å®˜æ–¹è°ƒè¯•é€‰é¡¹
        save_conversation_path=str(debug_dir / "conversation"),  # ä¿å­˜å®Œæ•´å¯¹è¯å†å²
        generate_gif=str(debug_dir / "debug_execution.gif"),  # ç”Ÿæˆæ‰§è¡Œè¿‡ç¨‹GIF
    )

    return agent

async def save_results_for_crewai_flows(note_data_list: List[NoteData], output_dir: str = "output") -> Dict[str, str]:
    """
    ä¼˜åŒ–çš„ä¿å­˜å‡½æ•°ï¼Œä¾¿äºCrewAI flowsä¸­å…¶ä»–agentè¯»å–ä¿¡æ¯
    
    Args:
        note_data_list: ç¬”è®°æ•°æ®åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        åŒ…å«å„ç§æ–‡ä»¶è·¯å¾„çš„å­—å…¸ï¼Œä¾¿äºå…¶ä»–agentå¼•ç”¨
    """
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        import time
        timestamp = int(time.time())
        
        # æ–‡ä»¶è·¯å¾„
        json_file = output_path / f"hot_notes_data_{timestamp}.json"
        summary_file = output_path / f"hot_notes_summary_{timestamp}.txt"
        csv_file = output_path / f"hot_notes_data_{timestamp}.csv"
        
        # 1. ä¿å­˜ç»“æ„åŒ–JSONæ•°æ®ï¼ˆä¾›å…¶ä»–agentç¨‹åºåŒ–è¯»å–ï¼‰
        structured_data = {
            "metadata": {
                "collection_time": timestamp,
                "total_notes": len(note_data_list),
                "collection_method": "browser_automation_tool",
                "data_version": "1.0"
            },
            "notes": [note.model_dump() for note in note_data_list],
            "statistics": {
                "total_impression": sum(note.impression for note in note_data_list),
                "total_click": sum(note.click for note in note_data_list),
                "total_like": sum(note.like for note in note_data_list),
                "total_collect": sum(note.collect for note in note_data_list),
                "total_comment": sum(note.comment for note in note_data_list),
                "total_engage": sum(note.engage for note in note_data_list),
                "avg_engagement_rate": sum(note.engage / max(note.impression, 1) for note in note_data_list) / len(note_data_list) if note_data_list else 0
            }
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(structured_data, f, ensure_ascii=False, indent=2)
        
        # 2. ä¿å­˜äººç±»å¯è¯»çš„æ‘˜è¦ï¼ˆä¾›human reviewå’Œå…¶ä»–agentç†è§£ï¼‰
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"å°çº¢ä¹¦çƒ­é—¨ç¬”è®°é‡‡é›†ç»“æœæ‘˜è¦\n")
            f.write(f"é‡‡é›†æ—¶é—´: {timestamp}\n")
            f.write(f"é‡‡é›†æ–¹æ³•: browser_automation_tool\n")
            f.write(f"æ€»è®¡ç¬”è®°æ•°: {len(note_data_list)}\n")
            f.write("=" * 80 + "\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            f.write("ğŸ“Š æ•°æ®ç»Ÿè®¡:\n")
            f.write(f"- æ€»æ›å…‰é‡: {structured_data['statistics']['total_impression']:,}\n")
            f.write(f"- æ€»é˜…è¯»é‡: {structured_data['statistics']['total_click']:,}\n")
            f.write(f"- æ€»ç‚¹èµé‡: {structured_data['statistics']['total_like']:,}\n")
            f.write(f"- æ€»æ”¶è—é‡: {structured_data['statistics']['total_collect']:,}\n")
            f.write(f"- æ€»è¯„è®ºé‡: {structured_data['statistics']['total_comment']:,}\n")
            f.write(f"- æ€»äº’åŠ¨é‡: {structured_data['statistics']['total_engage']:,}\n")
            f.write(f"- å¹³å‡äº’åŠ¨ç‡: {structured_data['statistics']['avg_engagement_rate']:.2%}\n\n")
            
            # ç¬”è®°è¯¦æƒ…
            f.write("ğŸ“ ç¬”è®°è¯¦æƒ…:\n")
            f.write("-" * 80 + "\n")
            
            for i, note in enumerate(note_data_list, 1):
                f.write(f"\n{i}. {note.note_title}\n")
                f.write(f"   é“¾æ¥: {note.note_url}\n")
                f.write(f"   æ•°æ®: æ›å…‰{note.impression:,} | é˜…è¯»{note.click:,} | ç‚¹èµ{note.like:,} | æ”¶è—{note.collect:,} | è¯„è®º{note.comment:,} | äº’åŠ¨{note.engage:,}\n")
                if note.impression > 0:
                    engagement_rate = note.engage / note.impression
                    f.write(f"   äº’åŠ¨ç‡: {engagement_rate:.2%}\n")
        
        # 3. ä¿å­˜CSVæ ¼å¼æ•°æ®ï¼ˆä¾›æ•°æ®åˆ†æå·¥å…·ä½¿ç”¨ï¼‰
        import csv
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['note_title', 'note_url', 'impression', 'click', 'like', 'collect', 'comment', 'engage', 'engagement_rate']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for note in note_data_list:
                engagement_rate = note.engage / note.impression if note.impression > 0 else 0
                writer.writerow({
                    'note_title': note.note_title,
                    'note_url': note.note_url,
                    'impression': note.impression,
                    'click': note.click,
                    'like': note.like,
                    'collect': note.collect,
                    'comment': note.comment,
                    'engage': note.engage,
                    'engagement_rate': f"{engagement_rate:.4f}"
                })
        
        # 4. åˆ›å»ºæœ€æ–°æ•°æ®çš„ç¬¦å·é“¾æ¥ï¼ˆä¾¿äºå…¶ä»–agentæ€»æ˜¯è¯»å–æœ€æ–°æ•°æ®ï¼‰
        latest_json = output_path / "latest_hot_notes.json"
        latest_summary = output_path / "latest_hot_notes_summary.txt"
        latest_csv = output_path / "latest_hot_notes.csv"
        
        # åˆ é™¤æ—§çš„ç¬¦å·é“¾æ¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        for latest_file in [latest_json, latest_summary, latest_csv]:
            if latest_file.exists():
                latest_file.unlink()
        
        # åˆ›å»ºæ–°çš„ç¬¦å·é“¾æ¥
        latest_json.symlink_to(json_file.name)
        latest_summary.symlink_to(summary_file.name)
        latest_csv.symlink_to(csv_file.name)
        
        logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°å¤šç§æ ¼å¼æ–‡ä»¶ï¼Œä¾¿äºCrewAI flowsè¯»å–")
        
        return {
            "json_file": str(json_file),
            "summary_file": str(summary_file),
            "csv_file": str(csv_file),
            "latest_json": str(latest_json),
            "latest_summary": str(latest_summary),
            "latest_csv": str(latest_csv),
            "total_notes": len(note_data_list)
        }
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return {"error": str(e)}

class HotNoteFinder:
    """
    å°çº¢ä¹¦çƒ­é—¨ç¬”è®°æŸ¥æ‰¾å·¥å…· - åŸºäºbrowser_useçš„CrewAIå·¥å…·
    """
    
    name: str = "hot_note_finder"
    description: str = """
    æŸ¥æ‰¾å°çº¢ä¹¦å¹³å°ä¸Šä¸æŒ‡å®šæ¨å¹¿ç›®æ ‡ç›¸å…³çš„çƒ­é—¨ç¬”è®°æ•°æ®ã€‚
    è¯¥å·¥å…·ä½¿ç”¨browser_useè‡ªåŠ¨åŒ–æµè§ˆå™¨æ“ä½œï¼Œç™»å½•å°çº¢ä¹¦å¹¿å‘Šå¹³å°ï¼Œ
    é‡‡é›†ä¸ç›®æ ‡ç›¸å…³çš„ä¼˜è´¨ç¬”è®°çš„è¯¦ç»†æ•°æ®ï¼ˆåŒ…æ‹¬æ›å…‰é‡ã€é˜…è¯»é‡ã€ç‚¹èµé‡ç­‰ï¼‰ã€‚
    
    è¾“å…¥å‚æ•°ï¼š
    - promotion_target: æ¨å¹¿ç›®æ ‡ï¼ˆä¾‹å¦‚ï¼š'å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº'ï¼‰
    - max_pages: æœ€å¤§å¤„ç†é¡µæ•°ï¼ˆé»˜è®¤3é¡µï¼‰
    - output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤'output'ï¼‰
    
    è¾“å‡ºï¼šåŒ…å«ç¬”è®°æ•°æ®çš„ç»“æ„åŒ–ç»“æœï¼Œä¿å­˜ä¸ºå¤šç§æ ¼å¼ä¾¿äºåç»­å¤„ç†ã€‚
    """
    
    def _run(self, promotion_target: str, max_pages: int = 3, output_dir: str = "output") -> str:
        """
        åŒæ­¥è¿è¡Œå·¥å…·ï¼ˆCrewAIè¦æ±‚ï¼‰
        """
        try:
            # ç”±äºbrowser_useæ˜¯å¼‚æ­¥çš„ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œè¿è¡Œå¼‚æ­¥ä»£ç 
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self._async_run(promotion_target, max_pages, output_dir))
            loop.close()
            return result
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return json.dumps({
                "success": False,
                "error": str(e),
                "message": "çƒ­é—¨ç¬”è®°æŸ¥æ‰¾å·¥å…·æ‰§è¡Œå¤±è´¥"
            }, ensure_ascii=False)
    
    async def _async_run(self, promotion_target: str, max_pages: int = 3, output_dir: str = "output") -> str:
        """
        å¼‚æ­¥æ‰§è¡Œæ ¸å¿ƒé€»è¾‘
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œçƒ­é—¨ç¬”è®°æŸ¥æ‰¾ä»»åŠ¡")
        logger.info(f"ğŸ¯ æ¨å¹¿ç›®æ ‡: {promotion_target}")
        logger.info(f"ğŸ“„ æœ€å¤§é¡µæ•°: {max_pages}")
        
        # å¯åŠ¨å†…å­˜ç›‘æµ‹ä»»åŠ¡
        memory_monitor_task = None
        agent = None
        
        try:
            # å…ˆæ‰§è¡Œåˆå§‹EventBusæ¸…ç†
            await cleanup_eventbus()
            logger.info("ğŸ§¹ åˆå§‹EventBusæ¸…ç†å®Œæˆ")
            
            # å¯åŠ¨å†…å­˜ç›‘æµ‹ï¼ˆç¼©çŸ­é—´éš”åˆ°10ç§’è¿›è¡Œæµ‹è¯•ï¼‰
            memory_monitor_task = asyncio.create_task(monitor_eventbus_memory(10))
            logger.info("ğŸ“Š å†…å­˜ç›‘æµ‹ä»»åŠ¡å·²å¯åŠ¨")
            
            # åˆ›å»ºçŠ¶æ€ç®¡ç†å™¨
            action_state = ActionStateManager()
            
            # åˆ›å»ºä»£ç†
            agent = create_hot_note_finder_agent(promotion_target=promotion_target, max_pages=max_pages)
            logger.info("âœ… ä»£ç†åˆ›å»ºæˆåŠŸ")
            
            # æ¸…ç†ä¹‹å‰çš„çŠ¶æ€
            logger.info(f"ğŸ› DEBUG: HotNoteFinder._async_runä¸­æ¸…ç†å‰çš„çŠ¶æ€: {dict(action_state.state)}")
            logger.info(f"ğŸ› DEBUG: HotNoteFinder._async_runä¸­action_stateå®ä¾‹ID: {id(action_state)}")
            action_state.clear_data()
            logger.info(f"ğŸ› DEBUG: HotNoteFinder._async_runä¸­æ¸…ç†åçš„çŠ¶æ€: {dict(action_state.state)}")
            
            action_state.set_data("promotion_target", promotion_target, f"æ¨å¹¿æ ‡çš„: {promotion_target}")
            action_state.set_data("max_pages", max_pages, f"æœ€å¤§é¡µæ•°: {max_pages}")
            logger.info(f"ğŸ¯ å·¥å…·æ‰§è¡Œ: æœ€å¤§é¡µæ•°å·²è®¾ç½® = {max_pages}")
            
            try: 
                # è¿è¡Œä»»åŠ¡
                logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œé‡‡é›†ä»»åŠ¡...")
                history = await agent.run()
                
                logger.info(f"ğŸ“Š ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼ŒçŠ¶æ€: {history.is_done()}")
                
                # è¯¦ç»†è°ƒè¯•agentæ‰§è¡ŒçŠ¶æ€
                logger.info(f"ğŸ” DEBUG: Agentæ‰§è¡Œå†å²åˆ†æ:")
                logger.info(f"  - æ˜¯å¦å®Œæˆ: {history.is_done()}")
                logger.info(f"  - æ˜¯å¦æœ‰é”™è¯¯: {history.has_errors()}")
                logger.info(f"  - æ‰§è¡Œæ­¥æ•°: {len(history.messages) if hasattr(history, 'messages') else 'N/A'}")
                if hasattr(history, 'errors') and history.errors():
                    logger.error(f"  - é”™è¯¯åˆ—è¡¨: {history.errors()}")
                
                # å°è¯•å¤šç§æ–¹å¼è·å–ç»“æœæ•°æ®
                collected_notes_data = []
                data_source = "none"
                
                # ç­–ç•¥1: ä»final_resultè·å–
                if history.is_done() and not history.has_errors():
                    final_result = history.final_result()
                    logger.info(f"ğŸ” DEBUG: final_resultç±»å‹: {type(final_result)}")
                    logger.info(f"ğŸ” DEBUG: final_resultå†…å®¹: {repr(final_result)[:200]}...")
                    
                    if final_result:
                        try:
                            # å°è¯•è§£æagentçš„ç»“æœ
                            if isinstance(final_result, str):
                                if final_result.strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                                    result_data = json.loads(final_result)
                                    if "note_data_list" in result_data:
                                        collected_notes_data = result_data["note_data_list"]
                                        data_source = "final_result"
                                        logger.info(f"âœ… ä»final_resultæˆåŠŸè·å– {len(collected_notes_data)} æ¡æ•°æ®")
                                else:
                                    logger.warning("âš ï¸ final_resultæ˜¯ç©ºå­—ç¬¦ä¸²")
                            else:
                                result_data = final_result
                                if hasattr(result_data, 'get') and "note_data_list" in result_data:
                                    collected_notes_data = result_data["note_data_list"]
                                    data_source = "final_result_object"
                        except Exception as parse_error:
                            logger.warning(f"âš ï¸ è§£æfinal_resultå¤±è´¥: {parse_error}")
                
                # ç­–ç•¥2: ä»çŠ¶æ€ç®¡ç†å™¨è·å–å·²æ”¶é›†çš„æ•°æ®
                if not collected_notes_data:
                    logger.info("ğŸ” DEBUG: å°è¯•ä»ActionStateManagerè·å–æ•°æ®")
                    try:
                        state_collected_notes = action_state.get_data("collected_notes", [])
                        if state_collected_notes:
                            collected_notes_data = state_collected_notes
                            data_source = "state_manager"
                            logger.info(f"âœ… ä»çŠ¶æ€ç®¡ç†å™¨è·å– {len(collected_notes_data)} æ¡æ•°æ®")
                    except Exception as state_error:
                        logger.warning(f"âš ï¸ ä»çŠ¶æ€ç®¡ç†å™¨è·å–æ•°æ®å¤±è´¥: {state_error}")
                
                # ç­–ç•¥3: ä»æ‰§è¡Œå†å²ä¸­æå–æ•°æ® 
                if not collected_notes_data and hasattr(history, 'messages'):
                    logger.info("ğŸ” DEBUG: å°è¯•ä»æ‰§è¡Œå†å²ä¸­æå–æ•°æ®")
                    try:
                        for message in reversed(history.messages):  # ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹æŸ¥æ‰¾
                            if hasattr(message, 'content') and message.content:
                                content = str(message.content)
                                if '"note_data_list"' in content or '"success": true' in content:
                                    try:
                                        # å°è¯•ä»æ¶ˆæ¯å†…å®¹ä¸­æå–JSON
                                        import re
                                        json_match = re.search(r'\{.*"note_data_list".*\}', content, re.DOTALL)
                                        if json_match:
                                            result_data = json.loads(json_match.group())
                                            if "note_data_list" in result_data:
                                                collected_notes_data = result_data["note_data_list"]
                                                data_source = "history_extraction"
                                                logger.info(f"âœ… ä»æ‰§è¡Œå†å²æå– {len(collected_notes_data)} æ¡æ•°æ®")
                                                break
                                    except:
                                        continue
                    except Exception as history_error:
                        logger.warning(f"âš ï¸ ä»æ‰§è¡Œå†å²æå–æ•°æ®å¤±è´¥: {history_error}")
                
                logger.info(f"ğŸ“Š æ•°æ®è·å–ç»“æœ: æ¥æº={data_source}, æ•°é‡={len(collected_notes_data)}")
                
                # æ•°æ®éªŒè¯å’Œè½¬æ¢
                note_list = []
                if collected_notes_data:
                    logger.info(f"ğŸ” DEBUG: å¼€å§‹éªŒè¯å’Œè½¬æ¢ {len(collected_notes_data)} æ¡ç¬”è®°æ•°æ®")
                    
                    for i, note_data in enumerate(collected_notes_data):
                        try:
                            # éªŒè¯æ•°æ®ç»“æ„
                            if not isinstance(note_data, dict):
                                logger.warning(f"âš ï¸ ç¬”è®° {i+1} æ•°æ®æ ¼å¼é”™è¯¯: {type(note_data)}")
                                continue
                                
                            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                            required_fields = ['note_title', 'note_url']
                            missing_fields = [field for field in required_fields if field not in note_data]
                            if missing_fields:
                                logger.warning(f"âš ï¸ ç¬”è®° {i+1} ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                                continue
                                
                            # è®°å½•æ•°æ®è¯¦æƒ…ç”¨äºè°ƒè¯•
                            logger.debug(f"ğŸ“ ç¬”è®° {i+1}: {note_data.get('note_title', 'N/A')[:50]}...")
                            
                            # ä»URLæå–note_id
                            note_url = note_data.get("note_url", "")
                            note_id = ""
                            if note_url:
                                # ç®€å•çš„note_idæå–é€»è¾‘
                                if "/note/" in note_url:
                                    note_id = note_url.split("/note/")[-1].split("?")[0]
                                elif "/explore/" in note_url:
                                    note_id = note_url.split("/explore/")[-1].split("?")[0]
                            
                            note = NoteData(
                                note_id=note_id,
                                note_title=note_data.get("note_title", ""),
                                note_url=note_url,
                                impression=note_data.get("impression", 0),
                                click=note_data.get("click", 0),
                                like=note_data.get("like", 0),
                                collect=note_data.get("collect", 0),
                                comment=note_data.get("comment", 0),
                                engage=note_data.get("engage", 0)
                            )
                            note_list.append(note)
                            
                        except Exception as e:
                            logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆç¬”è®°æ•°æ® {i+1}: {e}")
                            continue
                    
                    logger.info(f"âœ… æ•°æ®éªŒè¯å®Œæˆï¼Œæœ‰æ•ˆç¬”è®°: {len(note_list)}/{len(collected_notes_data)}")
                else:
                    logger.warning("âš ï¸ æœªè·å–åˆ°ä»»ä½•ç¬”è®°æ•°æ®")
                
                if note_list:
                    # ä¿å­˜ç»“æœ
                    file_paths = await save_results_for_crewai_flows(note_list, output_dir)
                    
                    # æ„å»ºæˆåŠŸç»“æœ
                    result = ToolExecutionResult(
                        success=True,
                        data=NoteDataList(
                            note_data_list=note_list,
                            total_count=len(note_list),
                            collection_method="browser_automation_tool"
                        ),
                        message=f"æˆåŠŸé‡‡é›†åˆ° {len(note_list)} æ¡çƒ­é—¨ç¬”è®°æ•°æ®",
                        debug_info={
                            "promotion_target": promotion_target,
                            "processed_pages": min(max_pages, 10),  # å®é™…å¤„ç†çš„é¡µæ•°
                            "file_paths": file_paths,
                            "execution_summary": action_state.get_execution_summary()
                        }
                    )
                    
                    logger.info(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œé‡‡é›†åˆ° {len(note_list)} æ¡ç¬”è®°")
                    return json.dumps(result.model_dump(), ensure_ascii=False, indent=2)
                
                else:
                    # æ²¡æœ‰é‡‡é›†åˆ°æ•°æ®
                    result = ToolExecutionResult(
                        success=False,
                        data=NoteDataList(note_data_list=[], total_count=0),
                        message="æœªé‡‡é›†åˆ°ç›¸å…³ç¬”è®°æ•°æ®ï¼Œå¯èƒ½æ˜¯ç›®æ ‡å…³é”®è¯è¿‡äºå…·ä½“æˆ–ç½‘ç»œé—®é¢˜",
                        debug_info={
                            "promotion_target": promotion_target,
                            "agent_errors": history.errors() if history else [],
                            "execution_summary": action_state.get_execution_summary()
                        }
                    )
                    
                    logger.warning("âš ï¸ æœªé‡‡é›†åˆ°ç¬”è®°æ•°æ®")
                    return json.dumps(result.model_dump(), ensure_ascii=False, indent=2)
                    
            except Exception as e:
                logger.error(f"âš ï¸ Agentæ‰§è¡Œä¸­æ–­: {e}")
                
                # å³ä½¿agentæ‰§è¡Œå¤±è´¥ï¼Œä¹Ÿå°è¯•è¿”å›éƒ¨åˆ†ç»“æœ
                result = ToolExecutionResult(
                    success=False,
                    data=NoteDataList(note_data_list=[], total_count=0),
                    message=f"é‡‡é›†è¿‡ç¨‹ä¸­æ–­: {str(e)}",
                    debug_info={
                        "promotion_target": promotion_target,
                        "error": str(e),
                        "execution_summary": action_state.get_execution_summary()
                    }
                )
                
                return json.dumps(result.model_dump(), ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›é”™è¯¯ç»“æœ
            result = ToolExecutionResult(
                success=False,
                data=NoteDataList(note_data_list=[], total_count=0),
                message=f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}",
                debug_info={"error": str(e)}
            )
            
            return json.dumps(result.model_dump(), ensure_ascii=False, indent=2)
        
        finally:
            # æ£€æŸ¥å¹¶åœæ­¢å†…å­˜ç›‘æµ‹ä»»åŠ¡
            if memory_monitor_task:
                logger.info(f"ğŸ” DEBUG: å†…å­˜ç›‘æµ‹ä»»åŠ¡çŠ¶æ€ - done: {memory_monitor_task.done()}, cancelled: {memory_monitor_task.cancelled()}")
                if not memory_monitor_task.done():
                    logger.info("ğŸ›‘ æ­£åœ¨å–æ¶ˆå†…å­˜ç›‘æµ‹ä»»åŠ¡...")
                    memory_monitor_task.cancel()
                    try:
                        await memory_monitor_task
                    except asyncio.CancelledError:
                        logger.info("âœ… å†…å­˜ç›‘æµ‹ä»»åŠ¡å·²å–æ¶ˆ")
                    except Exception as cancel_error:
                        logger.warning(f"âš ï¸ å–æ¶ˆå†…å­˜ç›‘æµ‹ä»»åŠ¡æ—¶å‡ºé”™: {cancel_error}")
                else:
                    logger.info("ğŸ“Š å†…å­˜ç›‘æµ‹ä»»åŠ¡å·²è‡ªç„¶ç»“æŸ")
            
            # æ‰§è¡Œæœ€ç»ˆEventBusæ¸…ç†
            if agent:
                try:
                    await cleanup_eventbus(agent)
                    logger.info("âœ… æœ€ç»ˆEventBusæ¸…ç†å®Œæˆ")
                except Exception as cleanup_error:
                    logger.error(f"âš ï¸ æœ€ç»ˆEventBusæ¸…ç†å¤±è´¥: {cleanup_error}")
            else:
                logger.info("ğŸ§¹ æ‰§è¡Œå…¨å±€EventBusæ¸…ç†")
                try:
                    await cleanup_eventbus()
                    logger.info("âœ… å…¨å±€EventBusæ¸…ç†å®Œæˆ")
                except Exception as cleanup_error:
                    logger.error(f"âš ï¸ å…¨å±€EventBusæ¸…ç†å¤±è´¥: {cleanup_error}")
            
            logger.info("ğŸ”„ èµ„æºæ¸…ç†å®Œæˆ")

async def find_hot_notes(promotion_target: str, max_pages: int = 3, output_dir: str = "output") -> ToolExecutionResult:
    """
    å¯è¢«å¤–éƒ¨è°ƒç”¨çš„æ ¸å¿ƒå‡½æ•° - æ›¿ä»£åŸæ¥çš„main()å‡½æ•°
    
    Args:
        promotion_target: æ¨å¹¿ç›®æ ‡
        max_pages: æœ€å¤§å¤„ç†é¡µæ•°
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        ToolExecutionResult: æ‰§è¡Œç»“æœ
    """
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œçƒ­é—¨ç¬”è®°æŸ¥æ‰¾")
    logger.info(f"ğŸ¯ æ¨å¹¿ç›®æ ‡: {promotion_target}")
    
    try:
        # åˆ›å»ºå·¥å…·å®ä¾‹
        tool = HotNoteFinder()
        
        # æ‰§è¡Œå·¥å…·
        result_str = await tool._async_run(promotion_target, max_pages, output_dir)
        
        # è§£æç»“æœ
        result_data = json.loads(result_str)
        result = ToolExecutionResult(**result_data)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ find_hot_notesæ‰§è¡Œå¤±è´¥: {e}")
        return ToolExecutionResult(
            success=False,
            data=NoteDataList(note_data_list=[], total_count=0),
            message=f"æ‰§è¡Œå¤±è´¥: {str(e)}",
            debug_info={"error": str(e)}
        )

# ä¾¿äºç›´æ¥è°ƒç”¨çš„ç®€åŒ–å‡½æ•°
async def main(promotion_target: str = 'å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº', max_pages: int = 3):
    """
    ä¸»å‡½æ•° - å¯è¢«å¤–éƒ¨è°ƒç”¨ï¼Œæ›¿ä»£åŸæ¥çš„main()
    """
    result = await find_hot_notes(promotion_target, max_pages)
    
    if result.success:
        print(f"âœ… é‡‡é›†æˆåŠŸï¼å…±è·å¾— {result.data.total_count} æ¡ç¬”è®°æ•°æ®")
        print(f"ğŸ“„ è¯¦ç»†ä¿¡æ¯: {result.message}")
        
        # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®ä½œä¸ºç¤ºä¾‹
        for i, note in enumerate(result.data.note_data_list[:3], 1):
            print(f"\n{i}. {note.note_title}")
            print(f"   æ›å…‰: {note.impression:,} | é˜…è¯»: {note.click:,} | ç‚¹èµ: {note.like:,}")
            print(f"   é“¾æ¥: {note.note_url}")
    else:
        print(f"âŒ é‡‡é›†å¤±è´¥: {result.message}")
    
    return result

if __name__ == "__main__":
    # æ”¯æŒç›´æ¥è¿è¡Œ
    import sys
    
    promotion_target = sys.argv[1] if len(sys.argv) > 1 else 'å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº'
    max_pages = int(sys.argv[2]) if len(sys.argv) > 2 else 3
    
    asyncio.run(main(promotion_target, max_pages))