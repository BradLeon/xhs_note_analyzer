# å°çº¢ä¹¦ç¬”è®°åˆ†æå™¨ (XHS Note Analyzer)

åŸºäºCrewAI Flow + browser_use + MediaCrawlerçš„æ™ºèƒ½å†…å®¹åˆ†æå’Œç­–ç•¥åˆ¶å®šå·¥å…·ï¼Œå¸®åŠ©å†…å®¹åˆ›ä½œè€…é€šè¿‡åˆ†æä¼˜è´¨ç¬”è®°å¿«é€Ÿäº§å‡ºé«˜è´¨é‡å†…å®¹å¹¶åˆ¶å®šå®æˆ˜ç­–ç•¥ã€‚

## ğŸŒŸ åŠŸèƒ½ç‰¹æ€§

### ğŸš€ å››æ­¥éª¤æ™ºèƒ½åˆ†æä¸ç­–ç•¥æµç¨‹

æœ¬é¡¹ç›®é‡‡ç”¨CrewAI Flowæ¶æ„ï¼Œä¸²è¡Œæ‰§è¡Œå››ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼š

1. **ğŸ” ç¬”è®°å‘ç°** - ä½¿ç”¨browser_use agentè‡ªåŠ¨æŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°
2. **ğŸ“¥ å†…å®¹è·å–** - é€šè¿‡MediaCrawler APIè·å–ç¬”è®°è¯¦ç»†å†…å®¹  
3. **ğŸ§  å†…å®¹åˆ†æ** - ä¸‰ç»´åº¦æ·±åº¦åˆ†æï¼ˆç»“æ„ã€æƒ…æ„Ÿã€è§†è§‰ï¼‰
4. **ğŸ¯ ç­–ç•¥åˆ¶å®š** - åŸºäºåˆ†æç»“æœç”Ÿæˆå®æˆ˜ç­–ç•¥æŒ‡å¯¼

### ğŸ“Š æ ¸å¿ƒèƒ½åŠ›

- **è‡ªåŠ¨åŒ–ç¬”è®°å‘ç°**: åŸºäºä¸šåŠ¡ç›®æ ‡æ™ºèƒ½ç­›é€‰ç›¸å…³ä¼˜è´¨ç¬”è®°
- **å…¨é¢å†…å®¹è·å–**: è·å–æ–‡å­—ã€å›¾ç‰‡ã€è§†é¢‘ã€ä½œè€…ä¿¡æ¯ç­‰å®Œæ•´æ•°æ®
- **ä¸‰ç»´åº¦æ·±åº¦åˆ†æ**: ç»“æ„åˆ†æã€æƒ…æ„Ÿä»·å€¼åˆ†æã€è§†è§‰å…ƒç´ åˆ†æ
- **å®æˆ˜ç­–ç•¥åˆ¶å®š**: é€‰é¢˜ç­–ç•¥ã€TAç­–ç•¥ã€å†…å®¹åˆ›ä½œæŒ‡å¯¼
- **æ™ºèƒ½å»ºè®®è¾“å‡º**: æä¾›å¯ç›´æ¥æ‰§è¡Œçš„é€‰é¢˜ã€æ–‡æ¡ˆã€åˆ›æ„å»ºè®®

## ğŸ“‹ é¡¹ç›®æ¶æ„

```mermaid
graph TD
    A[å¼€å§‹åˆ†æ] --> B[Step 1: ç¬”è®°å‘ç°]
    B --> C[Step 2: å†…å®¹è·å–]
    C --> D[Step 3: ä¸‰ç»´åº¦åˆ†æ]
    D --> E[Step 4: ç­–ç•¥åˆ¶å®š]
    E --> F[è¾“å‡ºå®Œæ•´æŠ¥å‘Š]
    
    B1[browser_use Agent] --> B
    B --> B2[å°çº¢ä¹¦èšå…‰å¹³å°]
    B2 --> B3[ç›¸å…³ä¼˜è´¨ç¬”è®°åˆ—è¡¨]
    
    C1[MediaCrawler API] --> C
    C --> C2[Supabaseæ•°æ®åº“]
    C2 --> C3[è¯¦ç»†ç¬”è®°å†…å®¹]
    
    D1[å¤šæ¨¡æ€LLM] --> D
    D --> D2[ç»“æ„+æƒ…æ„Ÿ+è§†è§‰åˆ†æ]
    D2 --> D3[æˆåŠŸå…¬å¼æå–]
    
    E1[ç­–ç•¥åˆ¶å®šCrew] --> E
    E --> E2[é€‰é¢˜+TA+åˆ›ä½œç­–ç•¥]
    E2 --> E3[å®æˆ˜æŒ‡å¯¼æ–¹æ¡ˆ]
    
    F --> F1[åˆ†ææŠ¥å‘Š.md]
    F --> F2[ç­–ç•¥æŠ¥å‘Š.md]
    F --> F3[æ‰§è¡Œå»ºè®®.json]
```

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒç»„ä»¶

```
xhs_note_analyzer/
â”œâ”€â”€ main.py                          # ä¸»Flowæ§åˆ¶å™¨
â”œâ”€â”€ browser_agent/                   # ç¬¬ä¸€æ­¥ï¼šç¬”è®°å‘ç°
â”‚   â””â”€â”€ hot_related_note_finder.py   # browser_useè‡ªåŠ¨åŒ–ä»£ç†
â”œâ”€â”€ crews/                           # CrewAIå·¥ä½œç»„
â”‚   â”œâ”€â”€ content_analyzer_crew/       # ç¬¬ä¸‰æ­¥ï¼šä¸‰ç»´åº¦åˆ†æ
â”‚   â”‚   â”œâ”€â”€ content_analyzer_crew.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ config/
â”‚   â””â”€â”€ strategy_maker_crew/         # ç¬¬å››æ­¥ï¼šç­–ç•¥åˆ¶å®š
â”‚       â”œâ”€â”€ strategy_maker_crew.py
â”‚       â”œâ”€â”€ models.py
â”‚       â””â”€â”€ config/
â””â”€â”€ tools/                           # å·¥å…·é›†
    â”œâ”€â”€ hot_note_finder_tool.py      # ç¬”è®°å‘ç°å·¥å…·
    â”œâ”€â”€ mediacrawler_client.py       # MediaCrawler APIå®¢æˆ·ç«¯
    â””â”€â”€ custom_tool.py               # è‡ªå®šä¹‰å·¥å…·
```

### æ•°æ®æµ

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Flow as XHSContentAnalysisFlow
    participant Browser as browser_use Agent
    participant API as MediaCrawler API
    participant LLM as å¤šæ¨¡æ€LLM
    
    User->>Flow: å¯åŠ¨åˆ†æ(æ¨å¹¿ç›®æ ‡)
    
    Note over Flow: Step 1: ç¬”è®°å‘ç°
    Flow->>Browser: æŸ¥æ‰¾ç›¸å…³ä¼˜è´¨ç¬”è®°
    Browser->>Browser: ç™»å½•å°çº¢ä¹¦èšå…‰å¹³å°
    Browser->>Browser: æµè§ˆå†…å®¹çµæ„Ÿé¡µé¢
    Browser->>Browser: æ™ºèƒ½ç­›é€‰ç›¸å…³ç¬”è®°
    Browser-->>Flow: ç¬”è®°åŸºç¡€æ•°æ®åˆ—è¡¨
    
    Note over Flow: Step 2: å†…å®¹è·å–
    loop æ¯ä¸ªç¬”è®°URL
        Flow->>API: è·å–è¯¦ç»†å†…å®¹
        API->>API: çˆ¬å–ç¬”è®°æ•°æ®
        API-->>Flow: è¯¦ç»†å†…å®¹æ•°æ®
    end
    
    Note over Flow: Step 3: ä¸‰ç»´åº¦åˆ†æ
    loop æ¯ä¸ªè¯¦ç»†å†…å®¹
        Flow->>LLM: ä¸‰ç»´åº¦æ·±åº¦åˆ†æ
        LLM->>LLM: ç»“æ„+æƒ…æ„Ÿ+è§†è§‰åˆ†æ
        LLM-->>Flow: åˆ†æç»“æœå’Œè¯„åˆ†
    end
    
    Note over Flow: Step 4: ç­–ç•¥åˆ¶å®š
    Flow->>LLM: åŸºäºåˆ†æç»“æœåˆ¶å®šç­–ç•¥
    LLM->>LLM: é€‰é¢˜+TA+åˆ›ä½œç­–ç•¥
    LLM-->>Flow: å®Œæ•´å®æˆ˜ç­–ç•¥
    
    Flow->>Flow: ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    Flow-->>User: åˆ†æ+ç­–ç•¥åŒæŠ¥å‘Š
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

1. **å®‰è£…ä¾èµ–**
```bash
pip install crewai browser-use requests langchain-openai pydantic
```

2. **é…ç½®ç¯å¢ƒå˜é‡**
```bash
# OpenRouter API (ç”¨äºLLMè°ƒç”¨)
export OPENROUTER_API_KEY="your_openrouter_api_key"

# MediaCrawler APIæœåŠ¡å™¨
export MEDIACRAWLER_API_ENDPOINT="http://localhost:8000"
export MEDIACRAWLER_API_KEY="your_api_key"  # å¯é€‰

# å°çº¢ä¹¦èšå…‰å¹³å°è®¤è¯(browser_useéœ€è¦)
# è®¤è¯ä¿¡æ¯å·²ä¿å­˜åœ¨ xiaohongshu_auth.json
```

3. **å¯åŠ¨MediaCrawleræœåŠ¡å™¨**
```bash
# å…‹éš†MediaCrawler APIæœåŠ¡å™¨
git clone https://github.com/BradLeon/MediaCrawler-API-Server.git
cd MediaCrawler-API-Server
git checkout Api-server-branch

# å¯åŠ¨æœåŠ¡å™¨
python app/main.py
```

### è¿è¡Œåˆ†æ

```python
from xhs_note_analyzer.main import kickoff_content_analysis

# å¯åŠ¨å†…å®¹åˆ†ææµç¨‹
result = kickoff_content_analysis(
    promotion_target="å›½ä¼å¤®ä¼æ±‚èŒè¾…å¯¼å°ç¨‹åº",
    business_context="ä¸“æ³¨äºå›½ä¼å¤®ä¼æ±‚èŒåŸ¹è®­çš„æ•™è‚²æœºæ„"
)

print("ğŸ‰ åˆ†æå®Œæˆï¼æŸ¥çœ‹ output/ ç›®å½•è·å–è¯¦ç»†æŠ¥å‘Š")
```

### è¾“å‡ºç»“æœ

åˆ†æå®Œæˆåï¼Œå°†åœ¨`output/`ç›®å½•ç”Ÿæˆï¼š

**Step3 å†…å®¹åˆ†æç»“æœ**ï¼š
- `content_analysis_report.json` - è¯¦ç»†åˆ†ææ•°æ®
- `content_analysis_report.md` - Markdownåˆ†ææŠ¥å‘Š

**Step4 ç­–ç•¥åˆ¶å®šç»“æœ**ï¼š
- `strategy_report.json` - å®Œæ•´ç­–ç•¥æ•°æ®
- `strategy_report.md` - Markdownç­–ç•¥æŠ¥å‘Š
- `strategy_summary.txt` - ç­–ç•¥æ‰§è¡Œæ‘˜è¦

**ç»¼åˆç»“æœ**ï¼š
- `xhs_content_analysis_result.json` - å®Œæ•´æµç¨‹æ•°æ®
- `analysis_summary.txt` - ç»¼åˆåˆ†ææ‘˜è¦

## ğŸ“– è¯¦ç»†åŠŸèƒ½è¯´æ˜

### Step 1: ç¬”è®°å‘ç° (browser_use Agent)

ä½¿ç”¨browser_useæ¡†æ¶è‡ªåŠ¨åŒ–æ“ä½œå°çº¢ä¹¦èšå…‰å¹³å°ï¼š

- è‡ªåŠ¨ç™»å½•èšå…‰å¹³å°
- å¯¼èˆªåˆ°å†…å®¹çµæ„Ÿé¡µé¢
- åŸºäºè¯­ä¹‰ç›¸å…³æ€§æ™ºèƒ½ç­›é€‰ç¬”è®°
- æå–ç¬”è®°åŸºç¡€æ•°æ®ï¼ˆæ ‡é¢˜ã€URLã€äº’åŠ¨æ•°æ®ï¼‰

**ç‰¹è‰²åŠŸèƒ½**ï¼š
- ç²¾ç¡®å…ƒç´ å®šä½ (CSSé€‰æ‹©å™¨ + XPath)
- æ™ºèƒ½ç¿»é¡µå’Œæ‰¹é‡å¤„ç†
- çŠ¶æ€ç®¡ç†å’Œé”™è¯¯æ¢å¤

### Step 2: å†…å®¹è·å– (MediaCrawler API)

é€šè¿‡MediaCrawler APIæœåŠ¡å™¨è·å–å®Œæ•´ç¬”è®°å†…å®¹ï¼š

```python
# APIè°ƒç”¨ç¤ºä¾‹
client = MediaCrawlerClient()
content = client.crawl_note(note_url, fetch_comments=False)
```

**è·å–å†…å®¹åŒ…æ‹¬**ï¼š
- ç¬”è®°æ–‡å­—å†…å®¹
- å›¾ç‰‡å’Œè§†é¢‘URL
- ä½œè€…ä¿¡æ¯å’Œäº’åŠ¨æ•°æ®
- æ ‡ç­¾å’Œå‘å¸ƒæ—¶é—´

**æ•°æ®å­˜å‚¨**ï¼š
- å†…å®¹å­˜å‚¨åœ¨Supabaseæ•°æ®åº“
- æ”¯æŒæ‰¹é‡æŸ¥è¯¢å’Œæœç´¢
- æä¾›ç¼“å­˜æœºåˆ¶é¿å…é‡å¤çˆ¬å–

### Step 3: ä¸‰ç»´åº¦æ·±åº¦åˆ†æ (å¤šæ¨¡æ€LLM)

ä½¿ç”¨ContentAnalyzerCrewè¿›è¡Œä¸“ä¸šçš„ä¸‰ç»´åº¦åˆ†æï¼š

```python
# åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
analyzer = create_content_analyzer()
analysis_report = analyzer.analyze_multiple_notes(detailed_notes)
```

**ä¸‰ç»´åº¦åˆ†æè¯¦æƒ…**ï¼š

1. **å†…å®¹ç»“æ„åˆ†æ**ï¼š
   - æ ‡é¢˜æ¨¡å¼è¯†åˆ«
   - å¼€å¤´ç­–ç•¥åˆ†æ
   - å†…å®¹æ¡†æ¶æ¢³ç†
   - ç»“å°¾è®¾è®¡è§£è¯»

2. **æƒ…æ„Ÿä»·å€¼åˆ†æ**ï¼š
   - ç”¨æˆ·ç—›ç‚¹æŒ–æ˜
   - ä»·å€¼ä¸»å¼ æç‚¼
   - æƒ…æ„Ÿè§¦å‘ç‚¹è¯†åˆ«
   - å…±é¸£å…ƒç´ åˆ†æ

3. **è§†è§‰å…ƒç´ åˆ†æ**ï¼š
   - é…å›¾é£æ ¼ç‰¹ç‚¹
   - è‰²å½©æ­é…è§„å¾‹
   - æ’ç‰ˆè®¾è®¡äº®ç‚¹
   - è§†è§‰å¸å¼•åŠ›è¯„ä¼°

### Step 4: å®æˆ˜ç­–ç•¥åˆ¶å®š (StrategyMakerCrew)

åŸºäºStep3åˆ†æç»“æœï¼Œåˆ¶å®šä¸‰ç»´åº¦å®æˆ˜ç­–ç•¥ï¼š

```python
# åˆ†æç»´åº¦
analysis_dimensions = [
    "å†…å®¹ç»“æ„åˆ†æ",    # æ ‡é¢˜æ¨¡å¼ã€å¼€å¤´ç­–ç•¥ã€å†…å®¹æ¡†æ¶
    "æƒ…æ„Ÿä»·å€¼åˆ†æ",    # ç—›ç‚¹æŒ–æ˜ã€ä»·å€¼ä¸»å¼ ã€æƒ…æ„Ÿè§¦å‘
    "è§†è§‰å…ƒç´ åˆ†æ"     # é…å›¾é£æ ¼ã€è‰²å½©æ­é…ã€æ’ç‰ˆç‰¹ç‚¹
]
```

**Step3 è¾“å‡ºå†…å®¹**ï¼š
- ä¸‰ç»´åº¦è¯„åˆ†å’Œåˆ†ææŠ¥å‘Š
- æˆåŠŸå…¬å¼å’Œå…±åŒæ¨¡å¼æå–
- é«˜è´¨é‡æ¡ˆä¾‹çš„æ·±åº¦è§£è¯»
- Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š

**Step4 è¾“å‡ºç­–ç•¥**ï¼š
- é€‰é¢˜ç­–ç•¥ï¼ˆçƒ­é—¨è¯é¢˜ã€æ ‡é¢˜å…¬å¼ï¼‰
- TAç­–ç•¥ï¼ˆç”¨æˆ·ç”»åƒã€æ ¸å¿ƒéœ€æ±‚ï¼‰
- åˆ›ä½œæŒ‡å¯¼ï¼ˆæ–‡æ¡ˆã€é…å›¾ã€è§†é¢‘ï¼‰
- å®æˆ˜å»ºè®®å’Œå·®å¼‚åŒ–è¦ç‚¹

## ğŸ”§ é…ç½®è¯´æ˜

### browser_useé…ç½®

```python
# æµè§ˆå™¨é…ç½®
browser_session = BrowserSession(
    allowed_domains=['https://*.xiaohongshu.com'],
    storage_state='./xiaohongshu_auth.json',  # ç™»å½•çŠ¶æ€
    headless=False,  # å¯è§†åŒ–è°ƒè¯•
)
```

### MediaCrawler APIé›†æˆ

å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š
- [APIæ¥å£è§„èŒƒ](https://github.com/BradLeon/MediaCrawler-API-Server/blob/Api-server-branch/API%E6%8E%A5%E5%8F%A3%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3.md)
- [æ•°æ®API](https://github.com/BradLeon/MediaCrawler-API-Server/blob/Api-server-branch/app/api/data.py)

### LLMæ¨¡å‹é…ç½®

```python
# æ”¯æŒå¤šç§LLMæ¨¡å‹
llm_configs = {
    "analysis": "anthropic/claude-3.5-sonnet",    # å†…å®¹åˆ†æ
    "planning": "google/gemini-2.5-flash",       # è§„åˆ’ä»»åŠ¡
    "creativity": "openai/gpt-4-vision-preview"  # åˆ›æ„ç”Ÿæˆ
}
```

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ‰©å±•æ–°çš„åˆ†æç»´åº¦

1. åœ¨`ContentAnalyzerCrew`ä¸­æ·»åŠ æ–°çš„åˆ†æAgent
2. æ›´æ–°`config/agents.yaml`å’Œ`config/tasks.yaml`
3. åœ¨`models.py`ä¸­å®šä¹‰æ–°çš„åˆ†ææ¨¡å‹
4. ä¿®æ”¹åˆ†ææŠ¥å‘Šç”Ÿæˆé€»è¾‘

### é›†æˆæ–°çš„æ•°æ®æº

1. åœ¨`tools/`ç›®å½•åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯
2. å®ç°`BaseTool`æ¥å£
3. åœ¨ç›¸åº”çš„Crewä¸­æ³¨å†Œå·¥å…·

### è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘

ä¿®æ”¹`XHSContentAnalysisFlow`ä¸­çš„æ–¹æ³•ï¼š
- `_mock_find_notes()` - è‡ªå®šä¹‰ç¬”è®°ç­›é€‰é€»è¾‘
- `_generate_final_recommendations_from_analysis()` - åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
- `step4_strategy_making()` - å®šåˆ¶ç­–ç•¥åˆ¶å®šæµç¨‹
- `_save_analysis_results()` - è‡ªå®šä¹‰ç»“æœä¿å­˜æ ¼å¼

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æ‰§è¡Œæ—¥å¿—

æµç¨‹æ‰§è¡Œè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆè¯¦ç»†æ—¥å¿—ï¼š
- `output/debug/conversation/` - å®Œæ•´å¯¹è¯å†å²
- `output/debug/debug_execution.gif` - æ‰§è¡Œè¿‡ç¨‹å¯è§†åŒ–

### çŠ¶æ€è·Ÿè¸ª

```python
# æŸ¥çœ‹æµç¨‹çŠ¶æ€
flow = XHSContentAnalysisFlow()
status = flow.state

print(f"æ‰¾åˆ°ç¬”è®°: {len(status.found_notes)}")
print(f"è¯¦ç»†å†…å®¹: {len(status.detailed_notes)}")  
print(f"åˆ†æå»ºè®®: {len(status.content_analysis)}")
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
git clone https://github.com/your-repo/xhs_note_analyzer.git
cd xhs_note_analyzer
pip install -e .
```

### è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•MediaCrawlerå®¢æˆ·ç«¯
python src/xhs_note_analyzer/tools/mediacrawler_client.py

# æµ‹è¯•ä¸‰ç»´åº¦åˆ†æåŠŸèƒ½
python src/xhs_note_analyzer/crews/content_analyzer_crew/content_analyzer_crew.py

# æµ‹è¯•ç­–ç•¥åˆ¶å®šåŠŸèƒ½
python src/xhs_note_analyzer/crews/strategy_maker_crew/strategy_maker_crew.py

# è¿è¡Œå®Œæ•´æµç¨‹
python src/xhs_note_analyzer/main.py
```

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ”— ç›¸å…³é“¾æ¥

- [CrewAIå®˜æ–¹æ–‡æ¡£](https://docs.crewai.com/)
- [browser_useé¡¹ç›®](https://github.com/browser-use/browser-use)
- [MediaCrawler APIæœåŠ¡å™¨](https://github.com/BradLeon/MediaCrawler-API-Server)
- [OpenRouter API](https://openrouter.ai/)

---

**ğŸ’¡ æç¤º**: è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºé¡¹ç›®ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†å¤šä¸ªAIå·¥å…·å’ŒæœåŠ¡æ•´åˆåˆ°ä¸€ä¸ªå®Œæ•´çš„å·¥ä½œæµç¨‹ä¸­ã€‚å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´å’Œæ‰©å±•åŠŸèƒ½ã€‚
